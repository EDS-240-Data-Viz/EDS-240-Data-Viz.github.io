---
title: "Week 1 Discussion"
subtitle: "Data wrangling with the `{tidyverse}`"
description: "Tuesday January 7^th^, 2025"
---

## Background

By now, you may have heard / read something like, "Data scientists spend 80% of their time preparing their data for analysis and / or visualization." And while that may not be totally accurate for all data scientists or all projects, you *will* spend lots of time wrestling with data. [**You'll spend this week's discussion cleaning up a messy data set on hydraulic fracturing (aka [fracking](https://en.wikipedia.org/wiki/Fracking){target="_blank"}), with the goal of (re)familiarizing yourselves with some of commonly-used tidyverse functions.**]{.teal-text}

This week's data comes courtesy of Jeremy Singer-Vine's [Data is Plural](https://www.data-is-plural.com/){target="_blank"} weekly newsletter of useful / curious data sets (the [2023.09.27 edition](https://www.data-is-plural.com/archive/2023-09-27-edition/){target="_blank"}). Singer-Vine's description:

> Since [launching in 2011](https://www.fracfocus.org/learn/about-fracfocus){target="_blank"}, [FracFocus](https://fracfocus.org/){target="_blank"} has become the largest registry of [hydraulic fracturing](https://en.wikipedia.org/wiki/Fracking){target="_blank"} chemical disclosures in the US. The database, available to explore online and [download in bulk](https://fracfocus.org/data-download){target="_blank"}, contains 210,000+ such disclosures from fracking operators; it details the location, timing, and water volume of each fracking job, plus the names and amounts of chemicals used. The project is [managed](https://fracfocus.org/about-us){target="_blank"} by the [Ground Water Protection Council](https://www.gwpc.org/overview/){target="_blank"}, “a nonprofit 501(c)6 organization whose members consist of state ground water regulatory agencies”. As seen in: The latest [installment](https://www.nytimes.com/interactive/2023/09/25/climate/fracking-oil-gas-wells-water.html){target="_blank"} of the New York Times’ [Uncharted Water series](https://www.nytimes.com/series/uncharted-waters){target="_blank"}.

Interested in reading more about fracking? Check out [this communications piece](https://www.usgs.gov/news/national-news-release/water-used-hydraulic-fracturing-varies-widely-across-united-states){target="_blank"} from USGS to start.

## Exercise

*It's up to you to organize your own `week1-discussion.qmd` file (i.e. there is no template). You may (should) discuss and work through today's exercise with a partner (or two!).*

Your goal is to transform our raw fracking data into a cleaned / wrangled data frame that looks like this (only the first 6 rows are shown here):

```{r}
#| eval: true
#| echo: false
#| warning: false
#| message: false

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#..........................load packages.........................
library(tidyverse)
library(janitor)
library(usdata)

#......................import fracking data......................
fracking <- read_csv(here::here("course-materials", "discussion", "week1", "data", "fracking.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                        clean/wrangle fracking data                       ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

fracking_clean <- fracking |> 
  
  # clean column names ----
  janitor::clean_names() |> 
  
  # clean up dates ----
  mutate(job_start_date = str_remove(job_start_date, " AM")) |> # remove 'AM' from string
  mutate(datetime_start = mdy_hms(job_start_date)) |> # convert from string to date (save to new col)
  mutate(year = year(datetime_start)) |> # create 'year' col from date

  # select relevant cols ----
  select(datetime_start, year, state_name, county_name, well_name, total_base_water_volume) |> 
  
  # filter out non-state names ----
  filter(!state_name %in% c("Beaver", "Beckham", "Harper", "Hemphill", "Midland", "Red River", "Roosevelt", "Rusk", "State", "WARD")) |> 
  
  # make all words title case ----
  mutate(state_name = str_to_title(state_name)) |> 
  
  # fix misspelled state names ----
  mutate(state_name = case_when(
    state_name == "Colordao" ~ "Colorado",
    state_name == "Loiusiana" ~ "Louisiana",
    state_name == "Louisianna" ~ "Louisiana",
    state_name == "Lousiana" ~ "Louisiana",
    state_name == "New Mexcio" ~ "New Mexico",
    state_name == "Norh Dakota" ~ "North Dakota",
    state_name == "Norht Dakota" ~ "North Dakota",
    state_name == "North  Dakota" ~ "North Dakota",
    state_name == "North Dakata" ~ "North Dakota",
    state_name == "North Dakotta" ~ "North Dakota",
    state_name == "Noth Dakota" ~ "North Dakota",
    state_name == "Pennslvania" ~ "Pennsylvania",
    state_name == "Pennsylavania" ~ "Pennsylvania",
    state_name == "Pennsylvanya" ~ "Pennsylvania",
    state_name == "Penssylvania" ~ "Pennsylvania",
    state_name == "Texasa" ~ "Texas",
    state_name == "Texs" ~ "Texas", 
    state_name == "West Viginia" ~ "West Virginia",
    state_name == "Wyominng" ~ "Wyoming", 
    TRUE ~ state_name # copy over rest of state names from as-is
  )) |> 
  
  # remove rows that have a '?' mark ----
  filter(!str_detect(string = state_name, pattern = "\\?")) |> # `?` is a special chr; escape with `\\` prefix
  
  # make all uppercase (so that we can covert abbreviation to state names) ----
  mutate(state_name = str_to_upper(state_name)) |> 
  
  # mutate abbreviations to full state names ----
  mutate(state_name = ifelse(test = str_length(state_name) == 2, # if string in 'sn' col is 2 chrs long
                     yes = usdata::abbr2state(state_name), # replace abbreviation with full state name 
                     no = state_name)) |> # if string in 'sn' col is not 2 chrs long, keep state name as-is
  
  # make all words title case again ----
  mutate(state_name = str_to_title(state_name)) |> 
  
  # create a column of just state abbreviations ----
  mutate(state_abb = usdata::state2abbr(state_name)) |> 
  
  # rename 'total_base_water_volume' to 'total_base_water_volume_gal' for clarity ----
  rename(total_base_water_volume_gal = total_base_water_volume) |> 
  
  # move 'state_abb' col after state_name col ----
  relocate(state_abb, .after = state_name) |> 
  
  # remove obs that don't have a measurement for 'total_base_water_volume' (NA) ----
  drop_na(total_base_water_volume_gal)

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                           convert to kable table                         ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

fracking_clean |> 
  head() |> 
  gt::gt()
```

1. **Read in `fracking.csv` and perform some basic data exploration.** Use the `{here}` package to read in your data and check out things like the dimensions, structure, types of variables, unique observations, etc.

2. **Consider what data *cleaning* you might need to perform.** Discuss any curious data formatting (e.g. data types, inconsistent observation names, missing values, etc.) that you discovered during your data exploration step, above. What might you need to address in your next data wrangling steps?

3. ?

```{r}
#| eval: false
#| echo: true

fracking_clean <- fracking |> 
  
  # clean up column names (convert to snake_case) |> 
  # remove "AM" from `job_start_date` |> 
  # convert `job_start_date` from a chr to a date (and save as new column named `datetime_start`) |> 
  # create new `year` column |> 
  # get rid of any unnecessary columns (makes things a little less overwhelming!) |> 
  # remove any non-state names from the `state_name` column |> 
  # fix inconsistent naming in the `state_name` column (involves a few steps) |> 
  
  # clean up the inconsistent `state_name`s
    # convert to Title Case |> 
    # fix misspelled state names |> 
    # remove any observations that have a `?` in the state name (can't be certain where those data were collected) |> 

  # make all uppercase (so that we can covert abbreviation to state names) ----
  mutate(state_name = str_to_upper(state_name)) |> 
  
  # mutate abbreviations to full state names ----
  mutate(state_name = ifelse(test = str_length(state_name) == 2, # if string in 'state_name' col is 2 chrs long
                     yes = usdata::abbr2state(state_name), # replace abbreviation with full state name 
                     no = state_name)) |> # if string in 'state_name' col is not 2 chrs long, keep state name as-is
  
  # make all words title case again ----
  mutate(state_name = str_to_title(state_name)) |> 
  
  # create a column of just state abbreviations ----
  mutate(state_abb = usdata::state2abbr(state_name)) |> 
  
  # rename 'total_base_water_volume' to 'total_base_water_volume_gal' for clarity ----
  rename(total_base_water_volume_gal = total_base_water_volume) |> 
  
  # move 'state_abb' col after state_name col ----
  relocate(state_abb, .after = state_name) |> 
  
  # remove obs that don't have a measurement for 'total_base_water_volume' (NA) ----
  drop_na(total_base_water_volume_gal)
```

