---
title: "Week 1 Discussion: Exercise"
subtitle: "Data wrangling with the `{tidyverse}`"
description: "Tuesday January 7^th^, 2025"
---

## Background

By now, you may have heard / read something like, "Data scientists spend 80% of their time preparing their data for analysis and / or visualization." And while that may not be totally accurate for all data scientists or all projects, you *will* spend lots of time wrestling with data. [**You'll spend this week's discussion cleaning up a messy data set on hydraulic fracturing (aka [fracking](https://en.wikipedia.org/wiki/Fracking){target="_blank"}), with the goal of (re)familiarizing yourselves with some commonly-used tidyverse functions.**]{.teal-text}

This week's data comes courtesy of Jeremy Singer-Vine's [Data is Plural](https://www.data-is-plural.com/){target="_blank"} weekly newsletter of useful / curious data sets (the [2023.09.27 edition](https://www.data-is-plural.com/archive/2023-09-27-edition/){target="_blank"}). Singer-Vine's description:

> Since [launching in 2011](https://www.fracfocus.org/learn/about-fracfocus){target="_blank"}, [FracFocus](https://fracfocus.org/){target="_blank"} has become the largest registry of [hydraulic fracturing](https://en.wikipedia.org/wiki/Fracking){target="_blank"} chemical disclosures in the US. The database, available to explore online and [download in bulk](https://fracfocus.org/data-download){target="_blank"}, contains 210,000+ such disclosures from fracking operators; it details the location, timing, and water volume of each fracking job, plus the names and amounts of chemicals used. The project is [managed](https://fracfocus.org/about-us){target="_blank"} by the [Ground Water Protection Council](https://www.gwpc.org/overview/){target="_blank"}, “a nonprofit 501(c)6 organization whose members consist of state ground water regulatory agencies”. As seen in: The latest [installment](https://www.nytimes.com/interactive/2023/09/25/climate/fracking-oil-gas-wells-water.html){target="_blank"} of the New York Times’ [Uncharted Water series](https://www.nytimes.com/series/uncharted-waters){target="_blank"}.

Interested in reading more about fracking? Check out [this communications piece](https://www.usgs.gov/news/national-news-release/water-used-hydraulic-fracturing-varies-widely-across-united-states){target="_blank"} from USGS to start.

## Exercise

::: {.callout-note}
It's up to you to organize your own `week1-discussion.qmd` file (i.e. there is no template). You may (should) discuss and work through today's exercise with a partner (or two!).
:::

[**Your goal is to transform our raw fracking data into a cleaned / wrangled data frame that looks like this (only the first 6 rows are shown here):**]{.teal-text}

```{r}
#| eval: true
#| echo: false
#| warning: false
#| message: false

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#..........................load packages.........................
library(tidyverse)
library(janitor)
library(usdata)

#......................import fracking data......................
fracking <- read_csv(here::here("course-materials", "discussion", "week1", "data", "registryupload_1.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                        clean/wrangle fracking data                       ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

fracking_clean <- fracking |> 
  
  # clean column names ----
  janitor::clean_names() |> 
  
  # clean up dates ----
  mutate(job_start_date = str_remove(job_start_date, " AM")) |> # remove 'AM' from string
  mutate(datetime_start = mdy_hms(job_start_date)) |> # convert from string to date (save to new col)
  mutate(year = year(datetime_start)) |> # create 'year' col from date

  # select relevant cols ----
  select(datetime_start, year, state_name, well_name, total_base_water_volume) |> 
  
  # filter out non-state names ----
  filter(!state_name %in% c("Beaver", "Beckham", "Harper", "Hemphill", "Midland", "Red River", "Roosevelt", "Rusk", "State", "WARD")) |> 
  
  # make all words title case ----
  mutate(state_name = str_to_title(state_name)) |> 
  
  # fix misspelled state names ----
  mutate(state_name = case_when(
    state_name == "Colordao" ~ "Colorado",
    state_name == "Loiusiana" ~ "Louisiana",
    state_name == "Louisianna" ~ "Louisiana",
    state_name == "Lousiana" ~ "Louisiana",
    state_name == "New Mexcio" ~ "New Mexico",
    state_name == "Norh Dakota" ~ "North Dakota",
    state_name == "Norht Dakota" ~ "North Dakota",
    state_name == "North  Dakota" ~ "North Dakota",
    state_name == "North Dakata" ~ "North Dakota",
    state_name == "North Dakotta" ~ "North Dakota",
    state_name == "Noth Dakota" ~ "North Dakota",
    state_name == "Pennslvania" ~ "Pennsylvania",
    state_name == "Pennsylavania" ~ "Pennsylvania",
    state_name == "Pennsylvanya" ~ "Pennsylvania",
    state_name == "Penssylvania" ~ "Pennsylvania",
    state_name == "Texasa" ~ "Texas",
    state_name == "Texs" ~ "Texas", 
    state_name == "West Viginia" ~ "West Virginia",
    state_name == "Wyominng" ~ "Wyoming", 
    TRUE ~ state_name # copy over rest of state names from as-is
  )) |> 
  
  # remove rows that have a '?' mark ----
  filter(!str_detect(string = state_name, pattern = "\\?")) |> # `?` is a special chr; escape with `\\` prefix
  
  # mutate abbreviations to full state names ----
  mutate(state_name = ifelse(test = str_length(state_name) == 2, # if string in 'sn' col is 2 chrs long
                     yes = usdata::abbr2state(state_name), # replace abbreviation with full state name 
                     no = state_name)) |> # if string in 'sn' col is not 2 chrs long, keep state name as-is
  
  # create a column of just state abbreviations ----
  mutate(state_abb = usdata::state2abbr(state_name)) |> 
  
  # move 'state_abb' col after state_name col ----
  relocate(state_abb, .after = state_name) |> 
  
  # rename 'total_base_water_volume' to 'total_base_water_volume_gal' for clarity ----
  rename(total_base_water_volume_gal = total_base_water_volume) |> 

  # remove obs that don't have a measurement for 'total_base_water_volume' (NA) ----
  drop_na(total_base_water_volume_gal) |> 
  
  # reorder rows from earliest to most recent `datetime_start` value ----
  arrange(datetime_start) |> 
  
  head()

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                           convert to kable table                         ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

DT::datatable(fracking_clean)
```


<br>

1. [**Load the `{tidyverse}`, `{janitor}`, and `{usdata}`, read in `registryupload_1.csv`, and perform some basic data exploration.**]{.teal-text} Use the `{here}` package to read in your data and check out things like the dimensions, structure, types of variables, unique observations, etc. Read through the [metadata](https://drive.google.com/file/d/1n-eiTKPzMo8di4cjG1A94vhkMLMqFY62/view?usp=sharing), which accompanied our `registryupload_1.csv` file when downloaded from FracFocus.

2. [**Consider what data *cleaning* you might need to perform.**]{.teal-text} Discuss any curious data formatting (e.g. data types, inconsistent observation names, missing values, etc.) that you discovered during your data exploration step, above. What might you need to address in your next data wrangling steps?

::: {.callout-important}
## Pause for class discussion
Take a moment to share some of your findings with the rest of the class!
:::

3. [**Clean / wrangle the data!**]{.teal-text} Using the packages loaded in step 1, perform the following operations (***NOTE:** Each step below corresponds to a single line of code*):
    a. convert all column names from CamelCase to snake_case (for ease of readability and to adhere to the [Tidyverse style guide](https://style.tidyverse.org/syntax.html#object-names) recommendation)
    b. remove `"AM"` from the `job_start_date` column observations
    c. convert observations in the `job_start_date` column from character strings to datetime objects and save them to a new column named `datetime_start`
    d. add a column named `year` that contains only the year from `datetime_start`
    e. keep only the necessary columns (`datetime_start`, `year`, `state_name`, `well_name`, `total_base_water_volume`)
    f. convert all observations in the `state_name` column to Title Case
    g. remove any rows where the state name ends in `?` 
    h. convert any state abbreviations to full names in the `state_name` column (**Hint:** use a combination of the `mutate()`, `ifelse()` & `usdata::abbr2state()` functions)
    i. correct any misspelled state names in the `state_name` column (**Note:** figure out how to update the names of a few misspelled states, the feel free to copy the complete code for this step from the expandable section, below)
    j. remove any rows that do not have a true US state name in the `state_name` column
    k. add a column named `state_abb` with just US state abbreviations
    l. move the `state_abb` column so that it sits immediately after the `state_name` column
    m. rename `total_base_water_volume` as `total_base_water_volume_gal` for clarity
    n. remove any observations that don't have a measurement for `total_base_water_volume_gal` (i.e. NA)
    o. reorder rows from earliest to most recent `datetime_start` values
  
::: {.callout-tip collapse=true}
## Expand for code to fix misspelled state names
```{r}
#| eval: false
#| echo: true
mutate(state_name = case_when(
    state_name == "Colordao" ~ "Colorado",
    state_name == "Loiusiana" ~ "Louisiana",
    state_name == "Louisianna" ~ "Louisiana",
    state_name == "Lousiana" ~ "Louisiana",
    state_name == "New Mexcio" ~ "New Mexico",
    state_name == "Norh Dakota" ~ "North Dakota",
    state_name == "Norht Dakota" ~ "North Dakota",
    state_name == "North  Dakota" ~ "North Dakota",
    state_name == "North Dakata" ~ "North Dakota",
    state_name == "North Dakotta" ~ "North Dakota",
    state_name == "Noth Dakota" ~ "North Dakota",
    state_name == "Pennslvania" ~ "Pennsylvania",
    state_name == "Pennsylavania" ~ "Pennsylvania",
    state_name == "Pennsylvanya" ~ "Pennsylvania",
    state_name == "Penssylvania" ~ "Pennsylvania",
    state_name == "Texasa" ~ "Texas",
    state_name == "Texs" ~ "Texas", 
    state_name == "West Viginia" ~ "West Virginia",
    state_name == "Wyominng" ~ "Wyoming", 
    TRUE ~ state_name # copy over rest of state names from as-is
  ))
```
:::



