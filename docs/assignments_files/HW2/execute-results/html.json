{
  "hash": "b63ae013b954d0ecf2e3f9b7b4b3c55c",
  "result": {
    "markdown": "---\ntitle: \"Assignment #2 (HW #2)\"\nsubtitle: \"Assigned Mon 01/22/2024 | Due Sat 02/03/2024\"\ntitle-block-banner: true\ntoc: true\n---\n\n\n# [Part I: Building a basic ggplot]{.pink-text}\n\n## Learning Outcomes \n\n- identify which types of visualizations are most appropriate for your data and your audience\n- prepare (e.g. clean, explore, wrangle) data so that itâ€™s appropriately formatted for building data visualizations\n\n## Description \n\nIn class, we discussed a [five-step workflow](https://ucsb-meds.github.io/ggplot2-workflow/) for breaking down the process of transforming data into a visualization. The five steps are listed below:\n\n1. Determine data type(s)\n2. Determine appropriate visualization type(s)\n3. Create a basic plot\n4. Improve clarity & take home message\n5. Final touches / polishing\n\nHere, you will apply this workflow to visualize lobster size data across multiple rocky reef sites along the Santa Barbara coastline.\n\n::: {.callout-note}\n## Understanding the data\n\n#### About SBC LTER\nThe [Santa Barbara Coastal Long Term Ecological Research](https://sbclter.msi.ucsb.edu/) (SBC LTER) site was established in 2000 as part of the [LTER Network](https://lternet.edu/) to understand the ecology of coastal kelp forest ecosystems. Research and long-term ecological and environmental monitoring data is collected within a 10,000 square kilometer area of the northern portion of the Southern California Bight, which includes the Santa Barbara Channel, coastal watersheds, small estuaries, and sandy beaches that border the Channel. You can explore the full [data catalog](https://sbclter.msi.ucsb.edu/data/catalog/).\n\n#### About the data set\n\nThere are five coastal rocky reef research sites at which the SBC LTER collects long-term monitoring data:\n\n- Naples Reef (NAPL)\n- Isla Vista Reef (IVEE)\n- Arroyo Quemado Reef (AQUE)\n- Mohawk Reef (MOHK)\n- Carpinteria Reef (CARP)\n\nIn January 2012, [Naples Reef](https://wildlife.ca.gov/Conservation/Marine/MPAs/Naples) and [Isla Vista Reef](https://wildlife.ca.gov/Conservation/Marine/MPAs/Campus-Point) were [designated as Marine Protected Areas](https://www.parks.ca.gov/?page_id=27928) (MPAs), prohibiting any future take of lobsters (along with other living marine resources). Since then, the SBC LTER has conducted annual (late summer) benthic surveys at each of the above five sites, where SCUBA divers record lobster abundance and sizes. Explore the [metadata](https://sbclter.msi.ucsb.edu/data/catalog/package/?package=knb-lter-sbc.77) for more information.  \n\n#### Data citation\n\nReed, D, R. Miller. 2023. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (*Panulirus interruptus*), ongoing since 2012 ver 9. Environmental Data Initiative. <https://doi.org/10.6073/pasta/3595322687af94cd532620ad9db94c77>. \n\n#### Finding this data set\n\n*Knowing how to search for data can be tricky! Here's how I accessed this particular data set, should you want to search for LTER data yourself, in the future:*\n\n1. **Filter the [SBC LTER Data Catalog](https://sbclter.msi.ucsb.edu/data/catalog/)** for data sets related to **Reef/Kelp Forest** habitats (check the box next to the habitat type of interest, or filter by measurement type or LTER Core Research Area). This produces a table of data collections, descriptions, and links to individual data and metadata records.\n2. **Choose a data set of interest.** I was interested in the *SBC LTER: Spiny lobster in California* Collection, which includes three different data sets. I specifically chose, [Lobster abundace, size, and fishing pressure](https://sbclter.msi.ucsb.edu/data/catalog/package/?package=knb-lter-sbc.77) -- here, you'll find lots of metadata, including people and organizations involved in this data collection, temporal, geographic, and taxonomic coverage, methods and protocols, and links to data files. Additionally, you'll see a link to the [EDI Data Portal](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-sbc&identifier=77) (top right corner), which is the data repository that maintains all data and metadata produced by the LTER. EDI assigns a DOI (Digital Object Identifier) to each version of a data package (data package = data + metadata; SBC LTER updates this data set each year when new data is collected -- each update receives a new DOI).\n3. **Download or import the data.** You can download the data file from either the [SBC LTER Data Catalog](https://sbclter.msi.ucsb.edu/data/catalog/package/?package=knb-lter-sbc.77) *or* the [EDI Data Package](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-sbc&identifier=77). *However* I prefer reading in the data directly from online (that way, I don't need to worry about storing large data files). I recommend doing this from the [EDI Data Package](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-sbc&identifier=77) (rather than the SBC LTER Data Catalog), since the DOI ensures you can re-reference the exact same version, even after the data set is updated with new data (SBC LTER Data Catalog only has a download link for the most up-to-date version of the data). To do so, right click on the *Download Data* button, then select *Copy Link Address*.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](../images/download-lob-data.png){fig-align='center' width=50%}\n:::\n:::\n\n\nUse this url inside `read_csv()` to import the data into your script or Qmd/Rmd file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobster_data <- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.77.9&entityid=f32823fba432f58f66c06b589b7efac6\")\n```\n:::\n\n\n:::\n\nGiven the above data set, apply the five-step workflow to create a data visualization that explores how lobster size differs across each of the five coastal rocky reef SBC LTER sites for the years 2012 (the IVEE and NAPL were established as MPAs) and 2022 (10 years later).\n\n[**You must complete steps 1 - 3**]{.teal-text} (you may need to do some Googling or reference documentation to determine what `geom_*` to use when creating your basic plot). \n\n- [ ] **(step 1)** write out, in words, the data types of the variables from the above data set (you only need to do this for the variables used in creating your plot) [**(1-2 sentences)**]{.peach-text}\n- [ ] **(step 2)** write out, in words, the appropriate visualization types you considered given these data types *(hint: revisit [from Data to Viz](https://www.data-to-viz.com/) for a helpful decision tree)* [**(1-2 sentences)**]{.peach-text}\n- [ ] **(step 3)** write ggplot code to create a basic plot to visualize these data (this will first require some data wrangling)\n\n[**Physically coding steps 4 & 5 is optional -- instead, you may explain, in writing and/or by sketching out on paper, the following:**]{.teal-text} \n\n- [ ] **(representing step 4)** how you would improve plot clarity/the take home message(s) (consider the following prompts)? [**(2-3 sentences total)**]{.peach-text}\n    - [ ] Do you see any trends that you may want to explore further and/or highlight?\n    - [ ] How might you use colors and/or shapes to highlight important site groupings and/or years?\n- [ ] **(representing step 5)** some design choices you might make as you polish off your data visualization (consider the following prompts) [**(2-3 sentences total)**]{.peach-text}\n    - [ ] What plot elements should you update to really polish up this visualization?\n    - [ ] What text might you include?\n\n**Note:** Steps 4 and 5, above, are thought exercises -- it's okay if you don't yet know exactly how to approach answering these (we'll be spending time during these first few weeks of class talking about data communication and design theory), but do your best to write down a few things that you think would help to improve both the clarity and overall design of your data visualization .\n\n## Rubric (specifications)\n\nYou must complete the following, as detailed below, to receive a \"Satisfactory\" mark for Assignment #1, Part II:\n\n- [ ] all responses and code are written in `filename.qmd`, arranged according to the template \n- [ ] complete steps 1 & 2 (as detailed above in the Description), adhering to the length requirements specified at the end of each writing prompt\n- [ ] complete step 3 (as detailed above in the Description); use the checklist below to ensure you receive full marks:\n    - [ ] import the data\n    - [ ] wrangle the data so that it's in the correct format for plotting \n    - [ ] build a basic visualization, which should include the following two lines of code:\n        - [ ] a line of code to initialize your ggplot object\n        - [ ] a line of code to specify the appropriate `geom_*`\n    - [ ] code is annotated\n    - [ ] all code runs \n\n<br>\n\n::: {.center-text .large-fa-icon .teal-text}\n\n{{< fa chart-line title=\"A simple line chart\" >}} End Part II {{< fa chart-line title=\"A simple line chart\" >}}\n\n\n:::\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}