[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Recommended reading & materials",
    "section": "",
    "text": "Fundamentals of Data Visualization, by Claus O. Wilke – a primer on making informative and compelling figures\nR for Data Science (2e), by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund – an excellent primer on all things R for data wrangling, exploration, visualizing, and communicating, largely focused on using the {tidyverse}\nggplot2: Elegant Graphics for Data Analysis (3e), by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen – helpful for understanding the underlying theory of ggplot2 graphics (NOTE: this is currently (as of November 2023) a work-in-progress, and as the authors put it, “a dumping ground for ideas…we don’t recommend reading it” – it’s still worth noting its existence so that you can return to it in the future!)\nData Visualization: A practical introduction, by Kieran Healy – a hands-on intro to the principles and practice of looking at and presenting data using R and ggplot.\nHands-On Data Visualization, by Jack Dougherty and Ilya Ilyankou – learn how to tell stories with your data using drag-and-drop tools (e.g. Google Sheets, Datawrapper, Tableau Public)\nThe Truthful Art: Data, Charts, and Maps for Communication, by Albert Cairo – a guide to understanding information graphics and visualization (I have a hard copy in my office if you’d like to borrow it!)\nA ggplot2 Tutorial for Beautiful Plotting in R, by Cédric Scherer – a blog post that might as well be a book; an excellent introduction to many different ggplot options, ideas, and extension packages"
  },
  {
    "objectID": "resources.html#books",
    "href": "resources.html#books",
    "title": "Recommended reading & materials",
    "section": "",
    "text": "Fundamentals of Data Visualization, by Claus O. Wilke – a primer on making informative and compelling figures\nR for Data Science (2e), by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund – an excellent primer on all things R for data wrangling, exploration, visualizing, and communicating, largely focused on using the {tidyverse}\nggplot2: Elegant Graphics for Data Analysis (3e), by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen – helpful for understanding the underlying theory of ggplot2 graphics (NOTE: this is currently (as of November 2023) a work-in-progress, and as the authors put it, “a dumping ground for ideas…we don’t recommend reading it” – it’s still worth noting its existence so that you can return to it in the future!)\nData Visualization: A practical introduction, by Kieran Healy – a hands-on intro to the principles and practice of looking at and presenting data using R and ggplot.\nHands-On Data Visualization, by Jack Dougherty and Ilya Ilyankou – learn how to tell stories with your data using drag-and-drop tools (e.g. Google Sheets, Datawrapper, Tableau Public)\nThe Truthful Art: Data, Charts, and Maps for Communication, by Albert Cairo – a guide to understanding information graphics and visualization (I have a hard copy in my office if you’d like to borrow it!)\nA ggplot2 Tutorial for Beautiful Plotting in R, by Cédric Scherer – a blog post that might as well be a book; an excellent introduction to many different ggplot options, ideas, and extension packages"
  },
  {
    "objectID": "resources.html#chart-types",
    "href": "resources.html#chart-types",
    "title": "Recommended reading & materials",
    "section": "Chart types",
    "text": "Chart types\n\nFrom Data to Viz, by Yan Holtz & Conor Healy – a decision tree for deciding which chart type is most appropriate for your data\nChart Suggestions – A Thought-Starter, by A. Abela – a single pdf decision tree, which uses the four main chart types to guide users towards selecting an appropriate visualization\nData Viz Project, by Ferdio (an infographic and data visualization agency in Copenhagen) – 100 different visualizations from one simple dataset"
  },
  {
    "objectID": "resources.html#colors",
    "href": "resources.html#colors",
    "title": "Recommended reading & materials",
    "section": "Colors",
    "text": "Colors\n\ncolor theory & rules for data visualization\n\nYour Friendly Guide to Colors in Data Visualization, by Lisa Charlotte Muth – a blog post on useful tools for deciding data viz color palettes\nWhat to consider when choosing colors for data visualization, by Lisa Charlotte Muth – a blog post with explanations and examples\nPicking the right colors, by Mike Cisneros – blog post on important considerations for choosing colors for your data visualization\n5 pitfalls to avoid when working with color in data visualization, by Vanessa Fillis, Mafe Callejón and Simona Tselova – common pitfalls in choosing colors for data viz and how to avoid them\nColors and Emotions in Data Visualization, by Cédric Scherer – how colors influence our emotional response to data visualizations\nSubtleties of Color, by Robert Simmon – a 6 part blog post series from NASA Earth Observatory about the use of color to map Earth observation data\n\n\n\ncolor pickers & palette generators\n\n{paletteer}: provides common functions for accessing a near comprehensive list of palettes; be sure to also check out the R Color Palettes website, which includes previews of all palettes (clicking on one will reveal the {paletteer} code for using it or the associated HEX codes, along with example visualizations)\nGoogle color picker – a color picker\nhtmlcolorcodes.com – a color picker for HTML color codes, Hex color codes, RGB and HSL values\ncoolors.co – a super fast color palette generator, that also includes lots of pre-built palettes to draw inspiration from, an image picker to extract colors from your uploaded images, and a color contrast checker\nPalette Generator, by Learn UI Design – supply a starting color(s) and this tool will generate a palette, single hue, or divergent color scheme\nViz Palette, by Elijah Meeks and Susie Lu – a tool that shows you how well your chosen colors work for tiny lines and big areas, warns if you have colors sharing the same name (which can make it more challenging to talk about your designs, say, in a presentation), and can simulate color vision deficiencies\nShade Generator – a tool for generating shade scales\n\n\n\naccessibility & colors\n\nColorblind Safe Color Schemes, by the NCEAS Science Communication Resource Center – tips and examples of colorblind-friendly color palettes\nLet’s get color blind – Google Chrome extension for simulating color deficiencies in the web browser\nColor review, by Anton Robsarve – for understanding foreground and background contrasts\nColor Contrast Checker, by Userway: check your color contrast ratio, and view WCAG Compliance Results for different element types\nColor Contrast Checker, by coolors: check your color contrast ratio, and use their enhancement tool to improve your colors"
  },
  {
    "objectID": "resources.html#typography",
    "href": "resources.html#typography",
    "title": "Recommended reading & materials",
    "section": "Typography",
    "text": "Typography\n\nGoogle Fonts – catalog of open-source fonts and icons, which can be imported for use with {ggplot2}; check out this collection of short articles on choosing type\nfontpair: free fonts and font pairings\nWhich fonts to use for your charts and tables, by Lisa Charlotte Muth\nChoosing Fonts for Your Data Visualization, by Tiffany France\nWake up & smell the fonts, by Sarah Hyndman – a great 14min-long TEDx talk about how fonts turn words into stories that have the power to influence audience perceptions"
  },
  {
    "objectID": "resources.html#alternative-alt-text",
    "href": "resources.html#alternative-alt-text",
    "title": "Recommended reading & materials",
    "section": "Alternative (alt) text",
    "text": "Alternative (alt) text\n\nHow to write good alternative descriptions for your data visualization, by Amy Cesal – great instructions (and examples) on how to construct informative alt text for data visualizations\nWriting Alt Text for Data Visualization, also by Amy Cesal – more great example of alt text for data viz!\n#TidyTuesday alt text instructions – a simple formula for writing alt text for data visualizations, as recommended for #TidyTuesday participants"
  },
  {
    "objectID": "resources.html#dei-in-data-visualization",
    "href": "resources.html#dei-in-data-visualization",
    "title": "Recommended reading & materials",
    "section": "DEI in data visualization",
    "text": "DEI in data visualization\n\nDo No Harm Guide: Applying Equity Awareness in Data Visualization, by Jonathan Schwabish and Alice Feng – a guide for for approaching data work (and particularly visualizations) through a lens of diversity, equity, and inclusion\nRacial Equity GIS Hub, by ESRI – an ongoing, continuously expanding resource hub to assist organizations working to address racial inequities; it includes data layers, maps, applications, training resources, articles on best practices, solutions, and examples of how Esri users from around the world are leveraging GIS to address racial inequities\nNorthstar in GIS – a nonprofit organization that magnifies the work and talent of Black professionals in GIS, geography, and STEM careers; showcases technology advancing racial justice and promotes belonging and collaboration for Black GIS students, educators, entrepreneurs, professionals, and allies"
  },
  {
    "objectID": "resources.html#a-mix-of-a-cool-miscellaneous-resources",
    "href": "resources.html#a-mix-of-a-cool-miscellaneous-resources",
    "title": "Recommended reading & materials",
    "section": "A mix of a cool miscellaneous resources",
    "text": "A mix of a cool miscellaneous resources\n\npodcasts\n\nData Stories, hosted by Enrico Bertini and Moritz Stefaner – a podcast on data visualization; be sure to check out episode 056: Amanda Cox on Working With R, NYT Projects, Favorite Data (Amanda Cox was, for many years, the New York Times data editor)!\nTidy Tuesday, hosted by Jon Harmon – a weekly (very short, ~5min-long) podcast that reviews a visualization (or a few) produced by community members using the latest published data set; Jon describes the visualization and describes a couple key geoms and / or functions the author used to create it\nData is Plural, hosted by Jeremy Singer-Vine – a new podcast from the long-running newsletter, Data Is Plural, where each episode distills an expert interview into a crisp 15 minutes, taking you behind the scenes of another surprising data set\n\n\n\njournals / articles\n\nNightingale: Journal of the Data Visualization Society – focuses on data visualization from personal stories to exploratory research to interviews with leaders in the community, data ethics, and best practices\nGrainger S, Mao F, Buytaert W (2016) Environmental data visualisation for non-scientific contexts: Literature review and design framework. Environmental Modelling & Software. 85:299-318. https://doi.org/10.1016/j.envsoft.2016.09.004\nRougier NP, Droettboom M, Bourne PE (2014) Ten Simple Rules for Better Figures. PLOS Computational Biology. 10(9): e1003833. https://doi.org/10.1371/journal.pcbi.1003833\n\n\n\nnews / reporting outlets\n\nThe Upshot, by The New York Times – analysis that explains politics, policy and everyday life, with an emphasis on data and charts\nGraphic Detail, by The Economist – a collection of graphics published by The Economist\n\n\n\nvideos\n\nThe Data Digest – a YouTube channel with super helpful, short videos on stats / data viz in R\nAlbert Rapp – Albert’s YouTube channel, with tons of great coding tutorials (including lots of ggplot)\nTED Topics: Visualizations – a collection of TED talks (and more) on the topic of Visualizations\n\n\n\nblogs / blog posts\n\nClimate Viz, by Datawrapper – a collection of blog posts on data visualizations created with Datawrapper that help us (and hopefully you) to understand global warming and what humanity can do against it\nJazz up your ggplots!, by Elmera Azadpour, Althea Archer, Hayler Corson-Dosch & Cee Nell at USGS – an awesome blog post with example USGS viz + code; stay up-to-date with cool data happenings at USGS in their Water Data For The Nation Blog\n\n\n\ncurated lists\n\nawesome-ggplot2, by Erik Gahner Larsen – a curated list of awesome ggplot2 tutorials, packages etc."
  },
  {
    "objectID": "resources.html#inspirational-data-visualization-creators",
    "href": "resources.html#inspirational-data-visualization-creators",
    "title": "Recommended reading & materials",
    "section": "Inspirational data visualization creators",
    "text": "Inspirational data visualization creators\n\n{ggplot2} creators\n(In my honest opinion) One of the best ways to learn how to build exciting ggplots is to look at code that others have written. Here are just a few folks doing really incredible work (along with their repos where they often showcase their creations):\n\n\n\nCreator\n Data Viz Repository (and other online materials)\n\n\n\n\nIjeamaka Anyene\ntidytuesday\n\n\nElmera Azadpour\nElmera (MESM 2022) is a Data Visualization Specialist at USGS and builds amazing viz; check out her GitHub profile for many cool repos\n\n\nAman Bhargava\ntidytuesday (Aman using a variety of different tools & languages for his TidyTuesday creations)\n\n\nMeghan Hall\ncheck out Meghan’s awesome blog posts, which cover a number of {ggplot2} topics\n\n\nRyan Hart\nTidyTuesday\n\n\nGeorgios Karamanis\ntidytuesday\n\n\nJake Kaupp\ntidytuesdays\n\n\nDanielle Navarro\ngenerative art outputs from multiple repos can be found on Danielle’s website’s Gallery\n\n\nCristophe Nicault\ntidytuesday\n\n\nDan Oehm\ntidytues\n\n\nAlbert Rapp\nPublicTidyTuesday, but also check out his YouTube channel & blog\n\n\nNicola Rennie\ntidytuesday (Nicola also records nearly all of her work using the {camcorder} package)\n\n\nCédric Scherer\nTidyTuesday\n\n\nTanya Shapiro\ntanya-data-viz\n\n\nCara Thompson\ntidytuesdays\n\n\n\n\n\nOther seriously amazing data visualizationists\nDefinitely don’t limit yourself to just {ggplot2} creators! There are so many incredible data story-tellers and information designers to draw inspiration and learn from. Just a few:\n\nNadieh Bremer\nMona Chalabi\nSonja Kuijpers\nLisa Charlotte Muth\nGiorgia Lupi (check out this great short interview)\nSimon Scarr\nKinga Stryszowska-Hill (who does use R / {ggplot2}, among other data visualization tools)"
  },
  {
    "objectID": "resources.html#data-sources",
    "href": "resources.html#data-sources",
    "title": "Recommended reading & materials",
    "section": "Data sources",
    "text": "Data sources\nData are everywhere, but that doesn’t mean they’re necessarily easy to track down. Here are some of the places I’ve found and used data from (or at least considered using data from). If you’ve found a cool data source (particularly if it’s a source of environmental data), I would love to know! It can help me build out teaching materials with new / different examples, and also help your peers who may be searching for similar data. Please consider contributing data sources using this Google Form.\n\ndata repositories\n\nDataOne – a repository of data repositories! Search across all member repositories (including repositories like EDI Data Portal, Arctic Data Center, KNB, etc.) for environmental data (along with curated metadata records)\nEDI Data Portal – contains environmental and ecological data and metadata derived from publicly funded research contributed by a number of participating organizations (e.g. EDI is the main repository for all Long Term Ecological Research (LTER) data)\n\n\n\nnewsletters / data collections\n\nESIIL Data Library – The Environmental Data Science Innovation and Inclusion Lab (ESIIL) Data Library, which features a diverse range of datasets, each with its own dedicated web page\nData is Plural – a weekly newsletter (and seasonal podcast) of useful / curious data sets, published by Jeremy Singer-Vine\ntidytuesday – a weekly social data project that shares minimally-cleaned data sets covering a variety of topics for the R4DS community to visualize; organizers share links to the original data sources, as well as the scripts used to clean them prior to publishing\nawesome-public-datasets – a repository containing a list of high quality, topic-centric public data sources\nInformation is Beautiful – Founded by David McCandless, Information is Beautiful is dedicated to making sense of the world with graphics & data-visuals. We set out to explain, distill and clarify. All our visualizations are based on facts and data: constantly updated, revised and revisioned.\nKaggle Datasets – Kaggle is an online community for data scientists and machine learning practitioners to find and publish data, as well as enter competitions to solve data science challenges\n\n\n\ngovernment agencies\n\nCenters for Disease Control and Prevention (CDC) – there are tons of data sets buried in the pages of this website (you’ll likely have to do a bit of digging)\nData.gov – view data sets by the federal agency, state, city, or county that publishes them\nEPA’s National Emissions Inventory (NEI) Data Retrieval Tool – read more about NEI Data on the EPA’s website\nNOAA’s National Centers for Environmental Information – specifically, check out their Climate Monitoring Products (I used the County Mapping interface to download precipitation data featured in Lecture 5.3’s choropleth map)\n{tidycensus} package – tooling that allows R users to more easily interface with a select number of the US Census Bureau’s data APIs and return tidyverse-ready data frames"
  },
  {
    "objectID": "resources.html#learning-communities",
    "href": "resources.html#learning-communities",
    "title": "Recommended reading & materials",
    "section": "Learning communities",
    "text": "Learning communities\n\nonline communities\n\nTidyTuesday, by the R4DS Online Learning Community – a weekly data project in R, and an excellent (dare I say, the best) way to practice your data wrangling & visualization skills\n\n\n\nlocal communities\nThe following Santa Barbara-based groups hold regular meetups, workshops, networking events, and more:\n\nEcoDataScience – an environmental data science community based at the University of California Santa Barbara (UCSB), open to anyone who is interested in joining the journey of learning, advancing and applying data science skills in the environmental and ecological field\nR-Ladies Santa Barbara – a local chapter of R-Ladies Global, which exists to promote diversity in the R community\nCentral Coast R Users Group – a local group that brings Central Coast R users together to exchange information and ideas about R, data science, other open source languages, etc., and to build the R community throughout the Central Coast area\nSanta Barbara Women in STEM – a local network of professionals with a common goal to promote and encourage women in fields related to science, technology, engineering, and math\n\n\n\n\n\n\n\n\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "course-materials/discussion/week3/CA-drought.html",
    "href": "course-materials/discussion/week3/CA-drought.html",
    "title": "EDS 240",
    "section": "",
    "text": "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\ntuesdata &lt;- tidytuesdayR::tt_load('2021-07-20')\ndrought &lt;- tuesdata$drought\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            wrangle drought data                          ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean &lt;- drought |&gt;\n\n  # select cols of interest & update names as needed ----\n  select(date = valid_start, state_abb, drought_lvl, area_pct) |&gt; \n\n  # add year, month & day cols using {lubridate} fxns ----\n  # NOTE: this step isn't necessary for our plot, but I'm including as examples of how to extract different date elements from a object of class Date using {lubridate}~ ----\n  mutate(year = year(date),\n         month = month(date, label = TRUE, abbr = TRUE),\n         day = day(date)) |&gt;\n\n  # add drought level conditions names ----\n  mutate(drought_lvl_long = factor(drought_lvl,\n                            levels = c(\"D4\", \"D3\", \"D2\", \"D1\",\"D0\", \"None\"),\n                            labels = c(\"(D4) Exceptional\", \"(D3) Extreme\",\n                                       \"(D2) Severe\", \"(D1) Moderate\", \"(D0) Abnormally Dry\", \n                                       \"No Drought\"))) |&gt;\n  \n  # reorder cols ----\n  select(date, year, month, day, state_abb, drought_lvl, drought_lvl_long, area_pct)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##       create stacked area plot of CA drought conditions through time     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean |&gt; \n  \n  # remove drought_lvl \"None\" & filter for just CA ----\n  filter(drought_lvl != \"None\",\n         state_abb == \"CA\") |&gt; \n  \n  # create ggplot ----\n  ggplot(mapping = aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  \n  # reverse order of groups so level D4 is closest to x-axis ----\n  geom_area(position = position_stack(reverse = TRUE)) +\n  \n  # update colors to match US Drought Monitor (colors selected using ColorPick Eyedropper from original USDM data viz) ----\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\")) +\n  \n  # set x-axis breaks & remove padding between data and x-axis ----\n  scale_x_date(breaks = scales::breaks_pretty(n = 10),\n               expand = c(0, 0)) +\n\n  # set y-axis breaks & convert values to percentages & & remove padding between data and y-axis----\n  scale_y_continuous(breaks = seq(0, 100, by = 10),\n                     labels = scales::label_percent(scale = 1),\n                     expand = c(0, 0)) +\n  \n  # add title ----\n  labs(title = \"Drought area in California\") \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##            BONUS: using {geofacet} to plot data for all states           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# NOTE 2024-01-24: The following code works for Sam, but apparently no one else! I'll keep digging into this and update folks when I have a solution\n\n#......remove HI & AK (no data) and also DC from preset grid.....\nmygrid &lt;- geofacet::us_state_grid1 |&gt;\n  filter(!code %in% c(\"DC\", \"HI\", \"AK\"))\n\n#..............................plot..............................\n\n# NOTE: this takes a minute to render!\n\ndrought_clean |&gt; \n  filter(drought_lvl != \"None\") |&gt; \n  ggplot(aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  geom_area(position = position_stack(reverse = TRUE)) +\n  geofacet::facet_geo(~state_abb, grid = mygrid) +\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\"))"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#title-slide",
    "href": "course-materials/discussion/week2/week2-alt-text.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Discussion 2\nAlt Text\n\nWeek 2 | January 17th, 2024"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#what-is-alt-text",
    "href": "course-materials/discussion/week2/week2-alt-text.html#what-is-alt-text",
    "title": "EDS 240",
    "section": "",
    "text": "What is alt text?\n\n \nWebAIM defines alternative text, aka alt text, as:\n\n\n…a textual substitute for non-text content in web pages.\n\n\n\nIn other words, alt text is a written description that conveys the meaning / messaging of visual elements (e.g. photos / images, media, data visualizations)."
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#why-alt-text",
    "href": "course-materials/discussion/week2/week2-alt-text.html#why-alt-text",
    "title": "EDS 240",
    "section": "",
    "text": "Alt text serves many different communities and functions\n\n\nJust a few examples:\n\n\nAlt text is read aloud by assistive technologies, like screen readers, helping users with visual or certain cognitive disabilities to perceive the content and function of visual elements on web pages\nAlt text will appear in place of visual elements for those who are using a slow internet connection, or who have limited or expensive bandwidth\nAlt text may serve those with “situational limitations,” such as viewing a computer screen in bright sunlight\nAlt text provides more accurate image descriptions / context to search engine crawlers, which improves their assessment of a page’s purpose and content\n\n\n\nBecause of this, it’s important that we include good alt text with any data visualizations we publish online!"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#alt-text-formula",
    "href": "course-materials/discussion/week2/week2-alt-text.html#alt-text-formula",
    "title": "EDS 240",
    "section": "",
    "text": "A formula for writing alt text\n\nData viz designer and instructor, Amy Cesal, suggests this rule of thumb for writing alt text for data visualizations: alt=“Chart type of type of data where reason for including chart.\n\n\n\n\n\n\n\n\n\n\n\nalt=“Colored stripes of chronologically ordered temperatures where they increase in red to show the warming global temperature”\n\nExample from Amy Cesal’s article, Writing Alt Text for Data Visualization"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#example-milk",
    "href": "course-materials/discussion/week2/week2-alt-text.html#example-milk",
    "title": "EDS 240",
    "section": "",
    "text": "Another example\n\n\n\nalt=“A split bars chart of different types of milk’s (dairy and plant-based) environmental impact, where cow’s milk scores significantly worst in carbon emissions, land use, and water use than the other milk alternatives. Cow’s milk produces two times more carbon emissions, uses nine times more land, and twice the water that rice milk uses. Rice milk is the second most contaminating type of milk in terms of carbon emissions.”\n\nExample from Datawrapper"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#example-penguins",
    "href": "course-materials/discussion/week2/week2-alt-text.html#example-penguins",
    "title": "EDS 240",
    "section": "",
    "text": "Another example\n\n\nalt=“A boxplot of penguin flipper lengths where Gentoo penguins have flipper lengths that are about 12% larger than Adelie or Chinstrap penguins.”"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#alt-vs-cap",
    "href": "course-materials/discussion/week2/week2-alt-text.html#alt-vs-cap",
    "title": "EDS 240",
    "section": "",
    "text": "Include both a figure caption & alt text\n\n\nA figure caption is text that is displayed on the screen (typically beneath the data visualization it’s associated with) and is used to provide additional information and context.\nAlt text is not rendered on screen, but is identified and read aloud by screen readers. It’s used to describe the main takeaway(s) of a data visualization.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure caption: “Warming Stripes”, by Ed Hawkins, depicts the average annual global temperature from 1850-2022. Data Source: HadCRUT5. To learn more about this visualization, visit showyourstripes.info.\nAlt text: Colored stripes of chronologically ordered temperatures where they increase in red to show the warming global temperature"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#tips",
    "href": "course-materials/discussion/week2/week2-alt-text.html#tips",
    "title": "EDS 240",
    "section": "",
    "text": "Additional tips for writing alt text for data visualizations\n\n\nIn addition to the formula presented on the last couple slides, consider the following tips:\n\n\n\nwrite in sentence case, but keep it short (alt text is read linearly by screen readers, which means that people can’t go back a word if they missed something)\ncarefully consider the use of special characters (this article details “safe” vs. “unread” characters)\nlink to the data or source (not in your alt text, but somewhere in the surrounding text or figure caption)"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#practice1",
    "href": "course-materials/discussion/week2/week2-alt-text.html#practice1",
    "title": "EDS 240",
    "section": "",
    "text": "Practice writing alt text:\n\n\n\nImage source: Verisk Maplecroft | To enlarge: right click on image &gt; Open Image in New Tab\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#practice2",
    "href": "course-materials/discussion/week2/week2-alt-text.html#practice2",
    "title": "EDS 240",
    "section": "",
    "text": "Practice writing alt text:\n\n\n\nFig 3A from Ingeman et al. 2019\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#practice3",
    "href": "course-materials/discussion/week2/week2-alt-text.html#practice3",
    "title": "EDS 240",
    "section": "",
    "text": "Practice writing alt text:\n\n\n\nImage source: Milken Institute School of Public Health | To enlarge: right click on image &gt; Open Image in New Tab\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#adding-alt-text",
    "href": "course-materials/discussion/week2/week2-alt-text.html#adding-alt-text",
    "title": "EDS 240",
    "section": "",
    "text": "Adding alt text\n\nInclude alt text with your data visualizations, no matter how you choose to embed them:\n\nIf you’re rendering ggplot (or other data visualization) code within a .qmd file, add the fig-alt code chunk option:\n\n#| eval: true\n#| echo: false\n#| fig-cap: \"Figure caption text goes here\"\n#| fig-alt: \"Alt text goes here\"\nggplot(...) +\n  geom_*()\n\n\nIf you’ve save your data visualization as an image file, you can embed it in a .qmd file using either markdown or html syntax:\n\n\n\n\nMarkdown\n\n\n![Figure caption goes here](file/path/to/image){fig-alt=\"Alt text goes here\"}\n\n\n\nHTML\n\n\n&lt;img src=\"file/path/to/image\" alt=\"Alt text goes here\"&gt;"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#adding-alt-text-ggplot",
    "href": "course-materials/discussion/week2/week2-alt-text.html#adding-alt-text-ggplot",
    "title": "EDS 240",
    "section": "",
    "text": "Adding alt text (ggplot example)\n\n#| eval: true\n#| echo: true\n#| fig-cap: \"A boxplot of penguin flipper lengths\"\n#| fig-alt: \"A boxplot of penguin flipper lengths where Gentoo penguins have flipper lengths that are about 12% larger than Adelie or Chinstrap penguins.\"\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = species, y = flipper_length_mm)) +\n  geom_boxplot(aes(color = species), width = 0.3, show.legend = FALSE) +\n  geom_jitter(aes(color = species), alpha = 0.5, show.legend = FALSE, position = position_jitter(width = 0.2, seed = 0)) +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  theme_minimal()\n\nBoxplot of penguin flipper lengths"
  },
  {
    "objectID": "course-materials/discussion/week2/week2-alt-text.html#checking-alt-text",
    "href": "course-materials/discussion/week2/week2-alt-text.html#checking-alt-text",
    "title": "EDS 240",
    "section": "",
    "text": "Check to make sure your alt text was applied\n\n(In Chrome) Right click on an image &gt; Inspect to look at the underlying HTML of a webpage. You should see alt=\"Your alt text.\". For example, right clicking on the image on slide 4 should reveal something that looks like this:"
  },
  {
    "objectID": "course-materials/week5.html#pre-class-prep",
    "href": "course-materials/week5.html#pre-class-prep",
    "title": "Enhancing visualizations (part I)",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nPlease be sure to complete the following before class:\n\nInstall required packages\n\ninstall.packages(\"paletteer\") # a comprehensive collection of color palettes in R using a common interface\ninstall.packages(\"viridis\") # Colorblind-Friendly Color Maps for R\ninstall.packages(\"RColorBrewer\") # ColorBrewer Palettes\ninstall.packages(\"tigris\") # for downloading and using Census TIGER/Line shapefiles in R\n\n\n\nDownload data\n\nCounty-level precipitation data (Jan 2019 - Dec 2023) for the contiguous U.S, made available by NOAA National Centers for Environmental Information (NCEI) (the download buttons are located just beneath the rendered map – choose the CSV option)\n\nrename the data file as county-jan19-dec23-precip.csv and save it to your class repo at the file path: EDS-240-class-examples/week5/data/county-jan19-dec23-precip.csv\n\n\n\n\nInstall Google Chrome extensions (optional, but recommended)\nI’ll be using both of these (really wonderful and easy-to-use) tools during lecture and encourage you to install them!\n\nLet’s get color blind: simulates different color deficiencies in the browser\nGrayscale the Web: turn specific sites or tabs grayscale\nColorPick Eyedropper: a browser-based color chooser tool (I recommended that you install this for week 3 discussion, so you may already have it!)"
  },
  {
    "objectID": "course-materials/week5.html#lecture-materials",
    "href": "course-materials/week5.html#lecture-materials",
    "title": "Enhancing visualizations (part I)",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nWeek 5 instruction is broken down into three lessons:\n\n\n\nWhat makes a good viz?\n lecture 5.1 slides\n\n\n\n\nColors\n lecture 5.2 slides\n\n\n\n\nColors & Choropleths\n lecture 5.3 slides"
  },
  {
    "objectID": "course-materials/week5.html#discussion-materials",
    "href": "course-materials/week5.html#discussion-materials",
    "title": "Enhancing visualizations (part I)",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nThis week, you’ll be prepping a data visualization using the data you found / wrangled as part of your final project (HW #4). This does not need to be a polished viz, but should focus on clarity of message. You’ll be discussing each others’ visualizations and commenting on what the main takeaways are (ideally, you’ll walk away with the same message as intended by the plot-creator!). Please complete the following ahead of section:\n\nchoose a well-thought out question that you’d like to answer with your selected data set(s)\nhand-draw a plot that you want to create (this can be an important first step before even touching any code)\nturn your hand-drawn plot into a ggplot in R!\nsend both your hand-drawn plot and your resulting ggplot to Sevan via DM (Slack) by Tuesday (2/6) evening"
  },
  {
    "objectID": "course-materials/week5.html#assignment-reminders",
    "href": "course-materials/week5.html#assignment-reminders",
    "title": "Enhancing visualizations (part I)",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 5)\nMon 02/05/2024\nMon 02/05/2024, 11:55pm PT\n\n\nSR\nMid-course reflection (SR #2)\nMon 02/05/2024\nSat 02/10/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week6.html#pre-class-prep",
    "href": "course-materials/week6.html#pre-class-prep",
    "title": "Enhancing visualizations (part II)",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nPlease be sure to complete the following before class:\n\nInstall required packages\n\ninstall.packages(\"monochromeR\") # a package for creating monochrome color palettes and easily converting rgba values to hex codes (and also some other useful functions)\ninstall.packages(\"showtext\") # for using fonts more easily in R graphs\ninstall.packages(\"ggtext\") # improved text rendering support for ggplot2\ninstall.packages(\"ggrepel\") # ggplot2 extension to repel overlapping labels\ninstall.packages(\"googlesheets4\") # provides an R interface to Google Sheets via the Sheets API v4"
  },
  {
    "objectID": "course-materials/week6.html#download-data",
    "href": "course-materials/week6.html#download-data",
    "title": "Enhancing visualizations (part II)",
    "section": "Download Data",
    "text": "Download Data\nIn case we have trouble with the {googlesheets4} API, you can download and read in the following data files as normal (i.e. using readr::read_csv()):\n\nmetabolism-foraging-data.csv\nmono.csv\n\nIf you choose (or need) to download and read in these files, be sure to save them to your class repo at ~/week6/data/.\n\nDownload Font Awesome fonts\nIn addition to using Google Fonts in our ggplots, we will also be using some Font Awesome icons! To do so, you’ll need to download the Font Awesome font files and save them to your class repo. Do so by following these steps:\n\nDownload Font Awesome fonts: Go to https://fontawesome.com/download and download the latest release available. Choose the Free For Desktop option.\nUnzip the downloaded file: You should see a folder inside called otfs/ – this contains three .otf files (aka OpenType font format files)\nCopy the three .otf files to your class repo: I recommend creating a fonts/ folder inside your root directory, and dropping all three of them in there (e.g. ~/fonts/*.otf)"
  },
  {
    "objectID": "course-materials/week6.html#lecture-materials",
    "href": "course-materials/week6.html#lecture-materials",
    "title": "Enhancing visualizations (part II)",
    "section": "Lecture Materials",
    "text": "Lecture Materials\n\n\n\nTypography\n lecture 6.1 slides\n\n\n\n\nAnnotations\n lecture 6.2 slides"
  },
  {
    "objectID": "course-materials/week6.html#discussion-materials",
    "href": "course-materials/week6.html#discussion-materials",
    "title": "Enhancing visualizations (part II)",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nThis week, you’ll move beyond the fundamental graphic forms that we covered in lecture and discuss some advanced chart types. These are great options to keep in mind as you continue working on your final project (HW #4)!\n\n Week 6 discussion slides"
  },
  {
    "objectID": "course-materials/week6.html#assignment-reminders",
    "href": "course-materials/week6.html#assignment-reminders",
    "title": "Enhancing visualizations (part II)",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 6)\nMon 02/12/2024\nMon 02/12/2024, 11:55pm PT\n\n\nHW\nHomework Assignment #3\nMon 02/12/2024\nSat 02/24/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week3.html#pre-class-prep",
    "href": "course-materials/week3.html#pre-class-prep",
    "title": "Choosing a graphic form, Fundamental chart types (part I)",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nBefore coming to class, you’ll need to install some packages, download data, and request a US Census Bureau API key. For step-by-step instructions, unfold the following note (collapsed to save space):\n\n\n\n\n\n\nStep-by-step pre-class prep instructions\n\n\n\n\n\n\nInstall required packages\n\ninstall.packages(\"chron\") # for working with dates / times\ninstall.packages(\"naniar\") # tools for exploring & handing missing data\ninstall.packages(\"tidytuesdayR\") # used to download TidyTuesday data\ninstall.packages(\"tidycensus\") # an R package that allows users to interface with a select number of the US Census Bureau’s data APIs and return tidyverse-ready data frames\ninstall.packages(\"ggridges\") # {ggplot2} extension for creating ridgeline plots\ninstall.packages(\"gghighlight\") # {ggplot2} extension for highlighting geoms\ninstall.packages(\"ggbeeswarm\") # {ggplot2} extension for creating categorical scatter (violin point) plots\ninstall.packages(\"see\") # {ggplot2} extension for model visualization (we'll be using it for it's geom, geom_violindot())\ninstall.packages(\"scales\") # provides the internal scaling infrastructure used by ggplot2, and gives you tools to override the default breaks, labels, transformations and palettes (installed automatically with {ggplot2} or {tidyverse})\n\n\n\nDownload data\n\nCounty-level Lyme disease data from 2001-2020, made available by the CDC (read more on this CDC web page)\n\nsave the downloaded data (LD-Case-Counts-by-County-01-20.csv) to your class repo at the file path: EDS-240-class-examples/week3/data/LD-Case-Counts-by-County-01-20.csv\n\n\n\n\nRequest a US Census Bureau API key\n\nTo use the {tidycensus} package to access US Census Bureau data, you’ll first need to request and activate an API key. Do so by following these steps:\n\nRequest an API key at http://api.census.gov/data/key_signup.html\nAfter a short period of time, you should receive an email with your key (it may be helpful to star/bookmark that email), and click the included link to activate your key (Note: if you get an error when activating your key, close your browser window and try clicking the activation link again)\n\nFor security purposes, you should never push any API keys to GitHub. To prevent us from accidentally pushing our key(s), we can save it to a separate file which we’ll add to our .gitignore. Do so by following these steps:\n\n\nCreate a week3/ folder in the root directory of your class repo\nAdd a file to your week3/ folder called KEYS.R, and save your API key to an object name like this:\n\n\n\n\n~/week3/KEYS.R\n\ncensusKEY &lt;- \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n\n\nAdd KEYS.R to your .gitignore\n\n\n\n\n.gitignore\n\n/week3/KEYS.R\n\n\n\nSave .gitignore (once saved, you should see the newly added KEYS.R file disappear from your Git pane in RStudio, and a modified .gitignore appear). Stage/add, commit, and push this .gitignore file to GitHub\n\nIn class, we’ll source our key (by running source(here::here(\"week3\", \"KEYS.R\"))) into any scripts / Qmd files, where required."
  },
  {
    "objectID": "course-materials/week3.html#lecture-materials",
    "href": "course-materials/week3.html#lecture-materials",
    "title": "Choosing a graphic form, Fundamental chart types (part I)",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nWeek 3 instruction is broken down into three lessons:\n\n\n\nChoosing graphic forms\n lecture 3.1 slides\n\n\n\n\nVisualizing distributions\n lecture 3.2 slides\n\n\n\n\nVisualizing evolution\n lecture 3.3 slides\n\n\n\n\nToday’s lectures are inspired by and draw largely on materials created by a number of other educators, including Albert Cairo and his book The Truthful Art, Meghan Hall and her course, CMU 36-315: Statistical Graphics & Visualization, as well as information curated by Yan Holtz & Conor Healy as part of their From Data to Viz project."
  },
  {
    "objectID": "course-materials/week3.html#discussion-materials",
    "href": "course-materials/week3.html#discussion-materials",
    "title": "Choosing a graphic form, Fundamental chart types (part I)",
    "section": "Discussion Materials",
    "text": "Discussion Materials\n\nPre-discussion Prep\nBefore coming to section, please be sure to:\n\nInstall the following packages:\n\n\ninstall.packages(\"geofacet\") # facet data for different geographical regions using panels arranged in shapes that mimic geographic topology\n\n\n(Optional) Install the ColorPick Eyedropper Google Chrome extension, which makes it easy to select color values from webpages.\n\n\n\nBackground\nThe U.S. Drought Monitor (USDM) is a collection of measures that allows experts to assess droughts in the United States. It is produced through a partnership between the National Drought Mitigation Center at the University of Nebraska-Lincoln, the United States Department of Agriculture and the National Oceanic and Atmospheric Administration. You can download and explore comprehensive statistics through their data portal.\nThe TidyTuesday community wrangled and visualized USDM data back in 2021 (2021-07-20, week 30), so we’ll use the {tidytuesdayR} package to import some minimally-tidied data (TidyTuesday always provides the cleaning script that the organizers used to pre-process any of the data provided – these data comprise three separate data sets, which were converted from wide to long format, joined together, and had some columns renamed).\nOver the course of the next two discussion sections (week 3 & week 4), you’ll be recreating the following data visualization produced by U.S. Drought Monitor, which you can find on the Droughts in California Wikipedia page:\n\n\n\n\n\n\n\n\n\n\n\nThis week, we’ll focus on the data layer, geometric layer, and scales. Next week, we’ll work on tweaking the theme (all non-data elements) to get it to look just like the U.S. Drought Monitor’s version.\n\n\nSolution\n\n\n\nYou’ll get the most out of discussion section if you physically type out the code yourself (rather than copying / pasting)!\n\n\n\n\n\n\n\n\n\n\nComplete code for week 3 discussion\n\n\n\n\n\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\ntuesdata &lt;- tidytuesdayR::tt_load('2021-07-20')\ndrought &lt;- tuesdata$drought\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            wrangle drought data                          ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean &lt;- drought |&gt;\n\n  # select cols of interest & update names as needed ----\n  select(date = valid_start, state_abb, drought_lvl, area_pct) |&gt; \n\n  # add year, month & day cols using {lubridate} fxns ----\n  # NOTE: this step isn't necessary for our plot, but I'm including as examples of how to extract different date elements from a object of class Date using {lubridate}~ ----\n  mutate(year = year(date),\n         month = month(date, label = TRUE, abbr = TRUE),\n         day = day(date)) |&gt;\n\n  # add drought level conditions names ----\n  mutate(drought_lvl_long = factor(drought_lvl,\n                            levels = c(\"D4\", \"D3\", \"D2\", \"D1\",\"D0\", \"None\"),\n                            labels = c(\"(D4) Exceptional\", \"(D3) Extreme\",\n                                       \"(D2) Severe\", \"(D1) Moderate\", \"(D0) Abnormally Dry\", \n                                       \"No Drought\"))) |&gt;\n  \n  # reorder cols ----\n  select(date, year, month, day, state_abb, drought_lvl, drought_lvl_long, area_pct)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##       create stacked area plot of CA drought conditions through time     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean |&gt; \n  \n  # remove drought_lvl \"None\" & filter for just CA ----\n  filter(drought_lvl != \"None\",\n         state_abb == \"CA\") |&gt; \n  \n  # create ggplot ----\n  ggplot(mapping = aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  \n  # reverse order of groups so level D4 is closest to x-axis ----\n  geom_area(position = position_stack(reverse = TRUE)) +\n  \n  # update colors to match US Drought Monitor (colors selected using ColorPick Eyedropper from original USDM data viz) ----\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\")) +\n  \n  # set x-axis breaks & remove padding between data and x-axis ----\n  scale_x_date(breaks = scales::breaks_pretty(n = 10),\n               expand = c(0, 0)) +\n\n  # set y-axis breaks & convert values to percentages & & remove padding between data and y-axis----\n  scale_y_continuous(breaks = seq(0, 100, by = 10),\n                     labels = scales::label_percent(scale = 1),\n                     expand = c(0, 0)) +\n  \n  # add title ----\n  labs(title = \"Drought area in California\") \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##            BONUS: using {geofacet} to plot data for all states           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# NOTE 2024-01-24: The following code works for Sam, but apparently no one else! I'll keep digging into this and update folks when I have a solution\n\n#......remove HI & AK (no data) and also DC from preset grid.....\nmygrid &lt;- geofacet::us_state_grid1 |&gt;\n  filter(!code %in% c(\"DC\", \"HI\", \"AK\"))\n\n#..............................plot..............................\n\n# NOTE: this takes a minute to render!\n\ndrought_clean |&gt; \n  filter(drought_lvl != \"None\") |&gt; \n  ggplot(aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  geom_area(position = position_stack(reverse = TRUE)) +\n  geofacet::facet_geo(~state_abb, grid = mygrid) +\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\"))"
  },
  {
    "objectID": "course-materials/week3.html#assignment-reminders",
    "href": "course-materials/week3.html#assignment-reminders",
    "title": "Choosing a graphic form, Fundamental chart types (part I)",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 3)\nMon 01/22/2024\nMon 01/22/2024, 11:55pm PT\n\n\nHW\nHomework Assignment #2\nMon 01/22/2024\nSat 02/03/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week1.html#pre-class-prep",
    "href": "course-materials/week1.html#pre-class-prep",
    "title": "Course logistics, Intro, {ggplot2} review",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nPlease be sure to complete the following before class:\n\nInstall required packages\n\ninstall.packages(\"palmerpenguins\") # a package containing the `penguins` data set, which we'll use for plotting practice\ninstall.packages(\"tidyverse\") # a collection of packages used for data wrangling / manipulation and visualization (including {ggplot2})\n\n\n\nCreate your EDS-240-class-examples repository\nWe’ll be coding together quite a bit throughout this course. To stay organized, we’ll complete all of our in-class examples in one repository (repo). Create and clone a GitHub repository named EDS-240-class-examples. For step-by-step instructions, unfold the following note (collapsed to save space):\n\n\n\n\n\n\nStep-by-step instructions for creating and cloning a GitHub repo:\n\n\n\n\n\nCreate a remote (GitHub) repo:\n\nNavigate to your GitHub profile and click on Repositories (top menu bar)\nClick on the green New button in the upper right-hand corner\nGive it the name EDS-240-class-examples, and optionally, a short description. Select the radio button for Public repository (it should be selected by default). Initialize this repository with a README by checking the box and Add a .gitignore (select R from the .gitignore template drop down menu) boxes. Click Create repository.\nFrom your repo’s main page, click the green Code button and copy the URL to your clipboard\n\nClone your repo:\n\nOpen up RStudio\nClick on the drop down menu next to the R project icon (top right corner)\nClick New Project… &gt; Version Control &gt; Git &gt; paste your repo’s URL in the Repository URL: box and press Tab to auto fill the Project directory name field (it should automatically be named the same as your GitHub repo). Browse to select where on your computer you’d like your repo to be saved.\nClick Create Project"
  },
  {
    "objectID": "course-materials/week1.html#lecture-materials",
    "href": "course-materials/week1.html#lecture-materials",
    "title": "Course logistics, Intro, {ggplot2} review",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nWeek 1 instruction is broken down into three lessons:\n\n\n\nCourse logistics & syllabus\n lecture 1.1 slides\n\n\n\n\nIntro to data visualization\n lecture 1.2 slides\n\n\n\n\n{ggplot2} review\n lecture 1.3 slides"
  },
  {
    "objectID": "course-materials/week1.html#discussion-materials",
    "href": "course-materials/week1.html#discussion-materials",
    "title": "Course logistics, Intro, {ggplot2} review",
    "section": "Discussion Materials",
    "text": "Discussion Materials\n\nPre-discussion Prep\nBefore coming to section, you’ll need to install some packages and download data. For step-by-step instructions, unfold the following note (collapsed to save space):\n\n\n\n\n\n\nStep-by-step pre-discussion prep instructions\n\n\n\n\n\n\nInstall the following packages:\n\n\ninstall.packages(\"janitor\") # tools for cleaning dirty data\ninstall.packages(\"usdata\") # demographic data on the United States at the county and state levels spanning multiple years.\n\n\nDownload the data (fracking.csv) from Google Drive and save it to your class repo in the following location: EDS-240-class-examples/week1/data/fracking.csv (NOTE: data were originally downloaded as a zip file from FracFocus in November 2023. Since then, FracFocus has published a cleaner version of these data, which defeats some of this purpose of this exercise. As such, we’ll be working with this saved version of the data, rather than downloading directly from FracFocus’s data download page.)\nWe don’t want to push any data in our repo to GitHub (GitHub enforces file size limits, and you’ll run into some serious headaches when you try to push a file that’s too big) – to avoid doing this, we can add our data files to our .gitignore file, which, as the name implies, is a collection of files that we want Git to ignore. Open up your .gitignore file and add the following line (anywhere is fine, but it makes sense to add it beneath the last line):\n\n\n\n\n.gitignore\n\n# ignore any folder named `data/` within folders named `week__` (* acts as a wildcard)\n/week*/data/\n\n\nNotice that when you Save your modified .gitignore file, untracked data files at the specified file path disappear from your Git tab in RStudio, and a modified .gitignore file appears in it’s place (this is what we want!). Stage/add, commit, and push .gitignore.\n\n\n\n\n\n\n\n\n\n\nAn example repo with three folders: week1/, week2/, and other-stuff/. Each of those folders has a subfolder named data/, and each data/ folder contains a .csv file. Adding the line, /week*/data/ to the .gitignore tells Git to ignore folders (and their contents) named data/ that are within a parent folder named week__ (the * acts as a wildcard). If we wanted to ignore all three data/ folders (including other-stuff/data/), we can instead include /*/data/ to our .gitignore.\n\n\n\n\n\n\nBackground\n\n\n\n\n\n\n\nBy now, you may have heard / read something like, “Data scientists spend 80% of their time preparing their data for analysis and / or visualization.” And while that may not be totally accurate for all data scientists or all projects, you will spend lots of time wrestling with data. You’ll spend this week’s discussion cleaning up a messy data set on hydraulic fracturing (aka fracking), with the goal of (re)familiarizing yourselves with some of commonly-used tidyverse functions.\nThis week’s data comes courtesy of Jeremy Singer-Vine’s Data is Plural weekly newsletter of useful / curious data sets (the 2023.09.27 edition). Singer-Vine’s description:\n\nSince launching in 2011, FracFocus has become the largest registry of hydraulic fracturing chemical disclosures in the US. The database, available to explore online and download in bulk, contains 210,000+ such disclosures from fracking operators; it details the location, timing, and water volume of each fracking job, plus the names and amounts of chemicals used. The project is managed by the Ground Water Protection Council, “a nonprofit 501(c)6 organization whose members consist of state ground water regulatory agencies”. As seen in: The latest installment of the New York Times’ Uncharted Water series.\n\nInterested in reading more about fracking? Check out this communications piece from USGS to start.\n\n Week 1 discussion slides\n\n\n\nSolution\n\n\n\n\n\n\n\nYou’ll get the most out of discussion section if you physically type out the code yourself (rather than copying / pasting)!\nNote: Some of the wrangling in the solution (collapsed, below) may seem a bit superfluous – we’ve included lots of steps to (re)introduce as many of the common wrangling functions as possible, given our data set.\n\n\n\n\n\n\nComplete code for week 1 discussion (fracking)\n\n\n\n\n\n\n\n\n\n\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(usdata)\n\n#......................import fracking data......................\nfracking &lt;- read_csv(here::here(\"week1\", \"data\", \"fracking.csv\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                        clean/wrangle fracking data                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nfracking_clean &lt;- fracking |&gt; \n  \n  # clean column names ----\n  janitor::clean_names() |&gt; \n  \n  # clean up dates ----\n  mutate(job_start_date = str_remove(job_start_date, \" AM\")) |&gt; # remove 'AM' from string\n  mutate(datetime_start = mdy_hms(job_start_date)) |&gt; # convert from string to date (save to new col)\n  mutate(year = year(datetime_start)) |&gt; # create 'year' col from date\n\n  # select relevant cols ----\n  select(datetime_start, year, state_name, county_name, well_name, total_base_water_volume) |&gt; \n  \n  # filter out non-state names ----\n  filter(!state_name %in% c(\"Beaver\", \"Beckham\", \"Harper\", \"Hemphill\", \"Midland\", \"Red River\", \"Roosevelt\", \"Rusk\", \"State\", \"WARD\")) |&gt; \n  \n  # rename state_name to something shorter for typing out when using case_when (not necessary) ----\n  rename(sn = state_name) |&gt; \n  \n  # make all words title case ----\n  mutate(sn = str_to_title(sn)) |&gt; \n  \n  # fix misspelled state names ----\n  mutate(sn = case_when(\n    sn == \"Colordao\" ~ \"Colorado\",\n    sn == \"Loiusiana\" ~ \"Louisiana\",\n    sn == \"Louisianna\" ~ \"Louisiana\",\n    sn == \"Lousiana\" ~ \"Louisiana\",\n    sn == \"New Mexcio\" ~ \"New Mexico\",\n    sn == \"Norh Dakota\" ~ \"North Dakota\",\n    sn == \"Norht Dakota\" ~ \"North Dakota\",\n    sn == \"North  Dakota\" ~ \"North Dakota\",\n    sn == \"North Dakata\" ~ \"North Dakota\",\n    sn == \"North Dakotta\" ~ \"North Dakota\",\n    sn == \"Noth Dakota\" ~ \"North Dakota\",\n    sn == \"Pennslvania\" ~ \"Pennsylvania\",\n    sn == \"Pennsylavania\" ~ \"Pennsylvania\",\n    sn == \"Pennsylvanya\" ~ \"Pennsylvania\",\n    sn == \"Penssylvania\" ~ \"Pennsylvania\",\n    sn == \"Texasa\" ~ \"Texas\",\n    sn == \"Texs\" ~ \"Texas\", \n    sn == \"West Viginia\" ~ \"West Virginia\",\n    sn == \"Wyominng\" ~ \"Wyoming\", \n    TRUE ~ sn # copy over rest of state names from as-is\n  )) |&gt; \n  \n  # remove rows that have a '?' mark ----\n  filter(!str_detect(string = sn, pattern = \"\\\\?\")) |&gt; # `?` is a special chr; escape with `\\\\` prefix\n  \n  # make all uppercase (so that we can covert abbreviation to state names) ----\n  mutate(sn = str_to_upper(sn)) |&gt; \n  \n  # mutate abbreviations to full state names ----\n  mutate(sn = ifelse(test = str_length(sn) == 2, # if string in 'sn' col is 2 chrs long\n                     yes = usdata::abbr2state(sn), # replace abbreviation with full state name \n                     no = sn)) |&gt; # if string in 'sn' col is not 2 chrs long, keep state name as-is\n  \n  # make all words title case again ----\n  mutate(sn = str_to_title(sn)) |&gt; \n  \n  # create a column of just state abbreviations ----\n  mutate(state_abb = usdata::state2abbr(sn)) |&gt; \n  \n  # rename 'sn' to 'state_name' again for clarity ----\n  rename(state_name = sn, total_base_water_volume_gal = total_base_water_volume) |&gt; \n  \n  # move 'state_abb' col after state_name col ----\n  relocate(state_abb, .after = state_name) |&gt; \n  \n  # convert 'state_name' & 'state_abb' from string to factor ----\n  mutate(state_name = as.factor(state_name),\n         state_abb = as.factor(state_abb)) |&gt; \n  \n  # remove obs that don't have a measurement for 'total_base_water_volume' (NA) ----\n  drop_na(total_base_water_volume_gal)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##          some exploratory data viz + a few plot mods for practice        ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nfracking_clean |&gt; \n  filter(state_name %in% c(\"Texas\", \"Colorado\", \"North Dakota\")) |&gt; \n  filter(year == 2015) |&gt; \n  group_by(state_name) |&gt; # pipe directly into ggplot\n  ggplot(aes(x = fct_rev(fct_infreq(state_name)), y = total_base_water_volume_gal)) + # need to reverse fct order for coord_flip() (plots lowest freq at top by default)\n  geom_jitter(width = 0.3, alpha = 0.5, color = \"gray15\") +\n  geom_violin(color = \"red4\", alpha = 0.3) +\n  scale_y_continuous(labels = scales::label_comma()) +\n  labs(y = \"Total base water volumn (gal)\") +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank()\n    )"
  },
  {
    "objectID": "course-materials/week1.html#assignment-reminders",
    "href": "course-materials/week1.html#assignment-reminders",
    "title": "Course logistics, Intro, {ggplot2} review",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEnd-of-class survey (week 1)\nMon 01/08/2024\nMon 01/08/2024, 11:55pm PT\n\n\nSR\nPre-course reflection (SR #1)\nMon 01/08/2024\nSat 01/13/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #1\nMon 01/08/2024\nSat 01/20/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week8.html#pre-class-prep",
    "href": "course-materials/week8.html#pre-class-prep",
    "title": "Data storytelling, People as data",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nNo pre-class prep necessary this week!"
  },
  {
    "objectID": "course-materials/week8.html#lecture-materials",
    "href": "course-materials/week8.html#lecture-materials",
    "title": "Data storytelling, People as data",
    "section": "Lecture Materials",
    "text": "Lecture Materials\n\n\n\nData storytelling\n lecture 8.1 slides\n\n\n\n\nPeople as data\n lecture 8.2 slides"
  },
  {
    "objectID": "course-materials/week8.html#discussion-materials",
    "href": "course-materials/week8.html#discussion-materials",
    "title": "Data storytelling, People as data",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nSimilar to last week’s section, we’ll be discussing progress on our data visualizations and providing constructive feedback to one another. Please plan to bring the following to discussion:\n\none of your two remaining visualizations (i.e. not the one you brought to section last week)\nthe question that you’re trying to answer\n\nAdd your visualization and your question to the appropriate Google slide deck (each slide is labeled with a name) before section begins:\n\n10am section slides\n11am section slides\n\nYou should be prepared to discuss your design choices and receive constructive feedback from your peers. Be sure to review the tips on how to give, receive, and implement feedback."
  },
  {
    "objectID": "course-materials/week8.html#assignment-reminders",
    "href": "course-materials/week8.html#assignment-reminders",
    "title": "Data storytelling, People as data",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 8)\nMon 02/26/2024\nMon 02/26/2024, 11:55pm PT\n\n\nHW\nHomework Assignment #4\nMon 02/26/2024\nSat 03/09/2024, 11:59pm PT"
  },
  {
    "objectID": "clean-code-guide.html",
    "href": "clean-code-guide.html",
    "title": "Writing clean code",
    "section": "",
    "text": "Writing clean, easily readable, and reproducible code is just as important as understanding any of the data visualization tools you’ll learn in this class. Now is the time to practice this skill so that you can take your beautiful code and styling skills with you into the workforce!"
  },
  {
    "objectID": "clean-code-guide.html#general-conventions",
    "href": "clean-code-guide.html#general-conventions",
    "title": "Writing clean code",
    "section": "General conventions",
    "text": "General conventions\nStick to these standards (as suggested by The tidyverse style guide) whenever possible:\n\nNaming conventions:\n\nSnake case for variable names – for example, my_data\nKebab case for file names – for example, my-script.R\n\n\n\n\n\n\n\n\n\n\n\nArt by Allison Horst\n\n\n\nWhitespace conventions:\n\nSpace around any infix operators (==, +, -, &lt;-, etc) – for example:\n\n\nmy_data_clean &lt;- my_data |&gt; \n  filter(x == 2023)\n\n\nNo space around operators with high precedence (::, :::, $, @, [, [[, ^, unary -, unary +, and :) – for example:\n\n\nsqrt(x^2 + y^2)\ndf$z\nx &lt;- 1:10\n\n\nSpace before a pipe, |&gt; or %&gt;%, and (most often) a new line after – for example:\n\n\nmy_data |&gt; \n  filter(...)\n\n\nSpace before a ggplot +, and a new line after – for example:\n\n\nggplot(data, aes(x = x, y = y)) +\n  geom_point()\n\n\nSpace between arguments, commas, and operators, but no space between a parentheses and the following or proceeding argument/value – for example:\n\n\nggplot(data, aes(x = x, y = y, color = z)) +\n  geom_point(alpha = 0.8)\n\n\nOnly one level of indentation when piping into a ggplot – for example:\n\n\ndata |&gt; \n  filter(...) |&gt; \n  ggplot(aes(x = x, y = y, fill = z)) +\n  geom_point()\n\n\nIf arguments to a ggplot layer don’t all fit on one line, put each argument on it’s own line and indent – for example:\n\n\nggplot(data, aes(x = x, y = y, color = z)) +\n  geom_point() + \n  labs(\n    x = \"My x-axis label\",\n    y = \"My y-axis label\",\n    title = \"My plot title\",\n    caption = \"My plot caption\"\n  )"
  },
  {
    "objectID": "clean-code-guide.html#annotating-code",
    "href": "clean-code-guide.html#annotating-code",
    "title": "Writing clean code",
    "section": "Annotating code",
    "text": "Annotating code\nThe {ARTofR} package is wonderful for creating clean titles, dividers, and block comments for your code. Install the RStudio Addin, or call {ARTofR} functions in your console to generate comments, copy to your clipboard, and paste into your scripts.\nI’ve always opted for the console approach:\n\nLoading the package (library(ARTofR)) in your console (rather than in your script/qmd file)\nType your preferred divider (see the package README for options) and message, also in the console\nThe resulting divider is automatically copied to your clipboard\nPaste into your script\n\nA couple dividers that I use often:\n\nFor major section dividers, xxx_title2(\"text here\") renders as:\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                  text here                               ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\nFor subsection dividers, xxx_divider1(\"text here\") renders as:\n\n\n#............................text here...........................\n\n\nFor line-level annotations, I also often use (not created using {ARTofR}):\n\n\n# text here ---- \n\nHere’s a short example script demonstrating how I like to use these dividers:\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    Setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#.........................load libraries.........................\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n#..........................import data...........................\n# ~ if you're reading in data, this is a great place to do it ~\n  \n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          Data wrangling / cleaning                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\npenguins_wrangled &lt;- penguins |&gt; \n  \n  # select relevant cols ----\n  select(species, bill_length_mm, bill_depth_mm, year) |&gt; \n  \n  # filter for year of interest ----\n  filter(year == 2009)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                             Data visualization                           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# histogram of penguin bill lengths in the year 2009 ----\nggplot(penguins, aes(x = bill_length_m, fill = species)) +\n  geom_histogram()\n\n# scatterplot of penguin bill lengths by bill depths in the year 2009 ----\nggplot(penguins_wrangled, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point()"
  },
  {
    "objectID": "clean-code-guide.html#style-guides",
    "href": "clean-code-guide.html#style-guides",
    "title": "Writing clean code",
    "section": "Style guides",
    "text": "Style guides\n\nTidyverse style guide, by Hadley Wickham – a book that describes the style used throughout the {tidyverse}\nTidy design principles, by Hadley Wickham – a book to help you write better R code (currently under development)"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#title-slide",
    "href": "slides/week5.1-good-viz-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 5.1\nWhat makes a good data viz?\n\nWeek 5 | February 5th, 2024"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#looking-forward",
    "href": "slides/week5.1-good-viz-slides.html#looking-forward",
    "title": "EDS 240",
    "section": "",
    "text": "Looking forward . . .\n\n\n\nChoosing the right graphic form is just the first step! It’s important to consider how you can enhance your visualization by:\n\n\n\n applying pre-made and custom color palettes\n\n\n\n\n updating fonts\n\n\n\n\n adding annotations\n\n\n\n\n fine-tuning themes\n\n\n\n\n centering our primary message\n\n\n\n\n\nWe’ll start by familiarizing ourselves with a general set of rules and best practices for making “good” data viz."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#good-design1",
    "href": "slides/week5.1-good-viz-slides.html#good-design1",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)\n\n\n\n\nThe above should always be considered in your design process, but may not always be necessary"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#good-design2",
    "href": "slides/week5.1-good-viz-slides.html#good-design2",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)\n\n\nWe’re going to talk about these first few points, to start."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#data-ink-eyes",
    "href": "slides/week5.1-good-viz-slides.html#data-ink-eyes",
    "title": "EDS 240",
    "section": "",
    "text": "Simplify plots to reduce eye movement & improve readability / interpretability"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#data-ink-ratio",
    "href": "slides/week5.1-good-viz-slides.html#data-ink-ratio",
    "title": "EDS 240",
    "section": "",
    "text": "Data-Ink ratio: remove non-data ink\n\nThe Data-Ink ratio was introduced by Edward Tufte (1983) and argues that non-data-ink (i.e. ink used for for everything except the presentation of data itself) should be removed wherever possible.\n\\[\n\\text{Data-ink ratio} = \\frac{\\text{Data-ink}}{\\text{Total ink used to print the graphic}}\n\\]\n\n\nDo so by starting with a complete theme (e.g. theme_classic(), theme_void()) and add / remove elements using theme().\n\n\n\n\nLow Data-Ink ratio\n\n\n\n\n\n\n\n\nHigh Data-Ink ratio"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#data-ink-ratio-criticism",
    "href": "slides/week5.1-good-viz-slides.html#data-ink-ratio-criticism",
    "title": "EDS 240",
    "section": "",
    "text": "Maximizing the Data-Ink ratio isn’t always best\n\n\n\n\nEliminating lots of non-data ink may render visualizations difficult to read\n\nInbar et al. (2007) found that students preferred a more maximalist visualization design over the minimalist version proposed by Tufte\n\n\n\n\n\nDesign choices depend on audience and purpose – how you choose to maximize your data-ink ratio will depend largely on who your visualization is for and the purpose it’s meant to serve (e.g. a scientific publication may have specific requirements for the design / aesthetics of a visualization, while an infographic-style visualization may leave space for more creative liberties)\n\n\n\n\n\nA general rule of thumb: aim to maximize the data-ink ratio while not sacrificing overall readability, design, aesthetics."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#remove-redundant-legend",
    "href": "slides/week5.1-good-viz-slides.html#remove-redundant-legend",
    "title": "EDS 240",
    "section": "",
    "text": "Remove redundant legend information\n\nAsk yourself, “Does this legend provide additional information that I can’t get elsewhere?”. If not, remove a legend using:\n\nplot +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoing so increases the data-ink ratio and reduces overall eye movement."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#labels-rotated-text",
    "href": "slides/week5.1-good-viz-slides.html#labels-rotated-text",
    "title": "EDS 240",
    "section": "",
    "text": "Add direct labels & minimize rotated text\n\nWe can use a combination of coord_flip(), geom_text(), labs(), and theme() to further eliminate non-data ink and reduce overall eye movement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf course, a visualization like this wouldn’t be appropriate for all audiences / contexts (e.g. scientific journal). But, despite the removal of axes / text / legend, a reader could still walk away with the same type of information.\n\nSee the third visualization in this BBC article for an “in the wild” example."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#move-legend-position",
    "href": "slides/week5.1-good-viz-slides.html#move-legend-position",
    "title": "EDS 240",
    "section": "",
    "text": "Move the legend (positioning)\n\nReduce eye movement by updating the legend position (e.g. move it onto the plot panel):\n\nplot + \n  theme(\n    legend.position = c(0.85, 0.15) # you'll need to adjust these values for your plot!\n  )\n\n\n\n\nOriginal plot:\n\n\n\n\n\n\n\n\nUpdated legend position:\n\n\n\n\n\n\n\n\nAlso note the redundant species mapping (color and shape) – sometime redundancy is important for accessibility!"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#legend-ggtext",
    "href": "slides/week5.1-good-viz-slides.html#legend-ggtext",
    "title": "EDS 240",
    "section": "",
    "text": "Move the legend (incorporate into title text)\n\nReduce eye movement and excess ink by including legend info in the plot (sub)title (here, using the {ggtext} package; minimal code example, below):\n\nplot +\n  labs(subtitle = \"Some subtitle text where &lt;span style='color:red;'&gt;**these words**&lt;/span&gt; are bolded and red\") +\n  theme(plot.subtitle = ggtext::element_markdown())\n\n\n\n\n\nOriginal plot:\n\n\n\n\n\n\n\n\n\n\n\n\nLegend as styled title text:"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#add-direct-labels",
    "href": "slides/week5.1-good-viz-slides.html#add-direct-labels",
    "title": "EDS 240",
    "section": "",
    "text": "Move the legend (use direct labels)\n\nReduce eye movement and excess ink by including legend info as direct labels on the plot (here, using the {geomtextpath} package; minimal code example, below):\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) +\n  geom_point(size = 3, alpha = 0.8) +\n  geomtextpath::geom_labelsmooth(aes(label = species), method = \"lm\", size = 5)\n\n\n\n\n\nOriginal plot:\n\n\n\n\n\n\n\n\n\n\n\n\nLegend as direct labels:"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#use-annotations-neil",
    "href": "slides/week5.1-good-viz-slides.html#use-annotations-neil",
    "title": "EDS 240",
    "section": "",
    "text": "Use annotations to improve readability / interpretability\n\nIs the y-axis necessary for this plot? What’s the author’s goal? How do annotations help achieve that goal?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs white space always your friend?, by Neil Richards\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#use-annotations-covid",
    "href": "slides/week5.1-good-viz-slides.html#use-annotations-covid",
    "title": "EDS 240",
    "section": "",
    "text": "Use annotations to improve readability / interpretability\n\n\n“The key thing we do is to add a title to the chart, as an entry point and to explain what is going on. Text and other annotations add enourmous value for non-chart people.”\n\n\n-John Burn-Murdoch, Financial Times\n\n\n\n\n\nVaccines and Omicron mean Covid now less deadly than flu in England, by John Burn-Murdoch"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#put-in-context",
    "href": "slides/week5.1-good-viz-slides.html#put-in-context",
    "title": "EDS 240",
    "section": "",
    "text": "Consider ways to provide additional context for your data"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#wilke-context",
    "href": "slides/week5.1-good-viz-slides.html#wilke-context",
    "title": "EDS 240",
    "section": "",
    "text": "Plot groups against the whole when faceting\n\nFacets (aka small multiples) allow us to more easily view individual groups. Here, the author plots individual groups (male vs. female passenger distributions on the Titanic) against the data set total (distribution of all passengers):\n\n\n\n\nThe area under each curve corresponds to the total number of male and female passengers with known age (468 (M) and 288 (F)).\n\n\n\n\n\n\n\n\n\n\n\n\nThe colored areas show the density estimates of the ages of M and F passengers, and the gray areas show the overall passenger age distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from Fundamentals of Data Visualization, by Claus Wilke. For an example with code, check out this slide from Lecture 3.2"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#benchmark-values",
    "href": "slides/week5.1-good-viz-slides.html#benchmark-values",
    "title": "EDS 240",
    "section": "",
    "text": "Add benchmark values\n\nAdd vertical (geom_vline()) or horizontal (geom_hline()) lines at important values:\n\n\n\n\n\n\n\n\n\n\n\n\n\nA minimal code example:\n\nplot + \n  geom_vline(xintercept = 11) +\n  geom_vline(xintercept = 16) +\n  geom_vline(xintercept = 21) \n\n\n\nFig cap: Temporal Variation in Bottom Temperature. Monthly bottom (4.5 m depth) temperatures at Mohawk Reef (34.396290, -119.731297) in Santa Barbara, CA compiled from 2005-2017. Vertical dashed lines represent three of four treatment temperatures (11, 16, 21°C). Data Source: Santa Barbara Coastal Long-Term Ecological Research group (adapted from Csik et al. 2023)"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#1-1-line",
    "href": "slides/week5.1-good-viz-slides.html#1-1-line",
    "title": "EDS 240",
    "section": "",
    "text": "Add 1:1 line, if relevant\n\nFor data where the relevant comparison is the x = y line (e.g. scatter plots of paired data), plot the 1:1 line.\nBelow, the author compares gene expression levels in a mutant virus to the non-mutated (wild-type) variant. He presents three (increasingly better) versions of the same plot:\n\n\n\n\nBad\n\n\n\n\n\n\n\n\n\n\n\n\nBetter\n\n\n\n\n\n\n\n\n\n\n\n\nBest\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#draw-attention",
    "href": "slides/week5.1-good-viz-slides.html#draw-attention",
    "title": "EDS 240",
    "section": "",
    "text": "Draw attention to important information / values"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#color-groups",
    "href": "slides/week5.1-good-viz-slides.html#color-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Use color to highlight groups / values\n\nHighlight data by coloring groups of interest either manually or by using helpful packages, like {gghighlight} (we saw an example of this in lecture 3.3):"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#ggforce",
    "href": "slides/week5.1-good-viz-slides.html#ggforce",
    "title": "EDS 240",
    "section": "",
    "text": "Use annotations to highlight groups / values\n\nOr add annotations to your plots to call attention to data of interest (here, shown using the {ggforce} package; minimal code example, below):\n\nplot + \n  ggforce::geom_mark_ellipse(aes(filter = species == \"Gentoo\", label = \"Gentoo penguins\", \n                                 description = \"This species tends to have...\"))"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#avoid",
    "href": "slides/week5.1-good-viz-slides.html#avoid",
    "title": "EDS 240",
    "section": "",
    "text": "What doesn’t work so well in data visualization?"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#bad-data-viz",
    "href": "slides/week5.1-good-viz-slides.html#bad-data-viz",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design generally avoids…\n\n\n\n\ninformation overload (e.g. too many colors / shapes / fonts, groups, variables)\ndual axes (can easily mislead audiences)\npie charts (really hard for humans to effectively compare the size of angles)\n3D plots (distort perception and are generally distracting)\n\n\n\n\n\nOur job is to make it as easy as possible for our readers to understand our data without having to do mental gymnastics. The chart types above (more often than not) ask too much of our readers in their quest to understand the information being presented.\n\n\n\n  \n\nThere may be circumstances where the above are executed well…but more often than not, you’re safest avoiding them."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#info-overload-map",
    "href": "slides/week5.1-good-viz-slides.html#info-overload-map",
    "title": "EDS 240",
    "section": "",
    "text": "Information overload is no fun . . .\n\nIt can be nearly impossible to easily process many different variables, colors, shapes, etc. on the same visualization (and realistically, most people won’t want to take the time to even try):\n\n\nSource: Stack Exchange"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#info-overload-scatter",
    "href": "slides/week5.1-good-viz-slides.html#info-overload-scatter",
    "title": "EDS 240",
    "section": "",
    "text": "Information overload is no fun . . .\n\nIt can be nearly impossible to easily process many different variables, colors, shapes, etc. on the same visualization (and realistically, most people won’t want to take the time to even try):\n\n\nSource: Unknown, but borrowed from Allison Horst’s lecture"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#info-overload-parallel",
    "href": "slides/week5.1-good-viz-slides.html#info-overload-parallel",
    "title": "EDS 240",
    "section": "",
    "text": "Information overload is no fun . . .\n\nIt can be nearly impossible to easily process many different variables, colors, shapes, etc. on the same visualization (and realistically, most people won’t want to take the time to even try):\n\n\nSource: Unknown, but borrowed from Allison Horst’s lecture"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#info-overload-fixes",
    "href": "slides/week5.1-good-viz-slides.html#info-overload-fixes",
    "title": "EDS 240",
    "section": "",
    "text": "Reduce information overload whenever possible\n\n\nConsider some of the approaches we’ve already discussed:\n\nhighlighting the most important groups / values\nfaceting (small multiples)\ncreating separate visualizations\ncohesive and intuitive color scheme (more on colors next week)\n\n\n\nOr some that we haven’t covered:\n\ncreate interactive tables and / or visualizations using htmlwidgets (e.g. leaflet maps, plotly, charts, DT data tables)\ncreate reactive outputs using tools like {shiny}\n\ncheck out the EDS 430 (Intro to Shiny) materials as a starting point!"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes1",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes1",
    "title": "EDS 240",
    "section": "",
    "text": "Dual y-axes can deliberately mislead readers\n\nThe scales of dual axis charts are arbitrary and therefore can (deliberately) mislead readers about the relationship between the two data series. Let’s take this example using real Worldbank data for the German GDP and the global GDP between 2004 and 2016:\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes2",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes2",
    "title": "EDS 240",
    "section": "",
    "text": "Dual y-axes can deliberately mislead readers\n\nThe scales of dual axis charts are arbitrary and therefore can (deliberately) mislead readers about the relationship between the two data series. Let’s take this example using real Worldbank data for the German GDP and the global GDP between 2004 and 2016:\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile both GDPs may appear to increase at the about same rate, they actually don’t – global GDP increased by 80% until 2014, while the German GDP increased by 40%.\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth\n\n\nThe proportions of the two scales are often different from each other in dual axis charts. If the left axis would go down to zero, the chart would be twice as long. If the right axis would go down to zero, the chart would be almost three times as long. This is how both axes look like when we extend them to zero.\nSo while the chart looks like the German GDP and the global GDP go up at roughly the same rate (at least until 2014), they don’t. The global GDP increased by 80% until 2014; the GDP of Germany by 40%."
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes-alt-two-charts",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes-alt-two-charts",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatives to dual y-axes: side-by-side charts\n\nSeparate your data series into side-by-side charts – this allows us to create two different axes for two different charts.\n\n\n\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes-alt-indexed",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes-alt-indexed",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatives to dual y-axes: indexed charts\n\nIndexed charts show the relative change (percentage increase or decrease) of a data series over time. Consider adding labels or tooltips (e.g. using {plotly}) to include important absolute numbers.\n\n\n\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes-alt-prioritize",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes-alt-prioritize",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatives to dual y-axes: prioritize & label\n\nConsider prioritizing and plotting the more important of the two data series. Then use annotations to add information about the omitted variable. This option may not work well for all data sets, but can be effective for dual-axis charts that present both absolute and relative numbers of the same measure.\n\n\n\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#dual-axes-alt-connected-scatter",
    "href": "slides/week5.1-good-viz-slides.html#dual-axes-alt-connected-scatter",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatives to dual y-axes: connected scatterplot\n\nA connected scatterplot places one variable on the y-axis and the other on the x-axis (here, replacing time). Be mindful that these plots are generally less inutitive for a reader and may take more time to decipher patterns.\n\n\n\n\nExample from Why not to use two axes, and what to use instead, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#pie-charts1",
    "href": "slides/week5.1-good-viz-slides.html#pie-charts1",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with pie charts . . .\n\n\n. . . is actually a problem with humans – we’re not so great at comparing angles. We’re bad at comparing angles within a single pie chart if they’re all similar:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples from Allison Horst, who adapted from From Data to Viz"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#pie-charts2",
    "href": "slides/week5.1-good-viz-slides.html#pie-charts2",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with pie charts . . .\n\n\n. . . is actually a problem with humans – we’re not so great at comparing angles. We’re bad at comparing angles within a single pie chart if they’re all similar:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples from Allison Horst, who adapted from From Data to Viz"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#pie-charts3",
    "href": "slides/week5.1-good-viz-slides.html#pie-charts3",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with pie charts . . .\n\n\n. . . is actually a problem with humans – we’re not so great at comparing angles. And we’re even worse at comparing angles across multiple pie charts:\n\n\n\nExamples from Allison Horst, who adapted from From Data to Viz"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#good-pie",
    "href": "slides/week5.1-good-viz-slides.html#good-pie",
    "title": "EDS 240",
    "section": "",
    "text": "Sometimes, pie charts can be a good option\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nABC Enterprise Sales. Source: How to Use Charts and Graphs Effectively, by MindTools\n\n\nIF you decide a pie chart is the right option, consider:\n\n\nare the main takeaways clear (e.g. proportions different enough)?\navoiding lots of wedges\naggregating if there are many tiny ones\nemphasizing most important wedge\nlabeling directly on the chart\ncomparing to a bar chart version to see which is a better version\n\n\n\n\n\n\nExamples from Allison Horst, who adapted from From Data to Viz"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#treemap",
    "href": "slides/week5.1-good-viz-slides.html#treemap",
    "title": "EDS 240",
    "section": "",
    "text": "Pie chart alternative: treemap\n\n\nAs an alternative to a pie chart, consider treemaps. Treemaps display hierarchical data as a set of nested rectangles – simpler versions can be used to display parts of a whole using rectangles (which are easier for us to estimate than angles).\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: From Data to Viz\n\n\n\n\n\n\n\n\n\n\n\n\nSource: {treemapify} pkgdown site"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#3d-charts-occlusion",
    "href": "slides/week5.1-good-viz-slides.html#3d-charts-occlusion",
    "title": "EDS 240",
    "section": "",
    "text": "3D charts distort perspective\n\nOcclusion: When we see one object occlude (aka obstruct) another on a 2D surface, our brain perceives the object being hidden as farther away:\n\n\n\n\nSource: Data Visualization: Why 3D charts are a terrible idea"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#3d-charts-pers-dist",
    "href": "slides/week5.1-good-viz-slides.html#3d-charts-pers-dist",
    "title": "EDS 240",
    "section": "",
    "text": "3D charts distort perspective\n\nPerspective distortion: When we view objects in 3D, the objects farther away appear smaller, but our brain perceives them to be of larger size than in the picture:\n\n\n\n\nSource: Data Visualization: Why 3D charts are a terrible idea"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#gratuitous-3d",
    "href": "slides/week5.1-good-viz-slides.html#gratuitous-3d",
    "title": "EDS 240",
    "section": "",
    "text": "Avoid gratuitous 3D\n\nConsider how gray and blue areas visually compare in the 3D version? What about gray and orange? Now how do your interpretations change when inspecting the 2D version?\n\n\n\nThe pie chart on the right is an example of using 3D purely for decorative purposes. Here, the third dimension doesn’t actually convey any additional data. Claus Wilke calls this gratuitous 3D, and you should always avoid it.\n\nSource: Data Visualization: Why 3D charts are a terrible idea"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#3d-position-scales",
    "href": "slides/week5.1-good-viz-slides.html#3d-position-scales",
    "title": "EDS 240",
    "section": "",
    "text": "Avoid 3D position scales\n\nA plot with three genuine position scales (x, y, and z) to represent mtcars data (viewed from four different perspectives:\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#3d-position-scales-alt1",
    "href": "slides/week5.1-good-viz-slides.html#3d-position-scales-alt1",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative (a) to 3D position scales\n\nIf we primarily care about fuel efficiency as the response variable, plot it twice (once against displacement and once against power):\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#3d-position-scales-alt2",
    "href": "slides/week5.1-good-viz-slides.html#3d-position-scales-alt2",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative (b) to 3D position scales\n\nIf we are more interested in how displacement and power relate to each other, with fuel efficiency as a secondary variable of interest, create a bubble chart (plot power vs. displacement and map fuel efficiency onto the size of the dots). Be mindful that three variables (even in a 2D space) are still challenging for readers to quickly comprehend.\n\n\n\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#break-rules",
    "href": "slides/week5.1-good-viz-slides.html#break-rules",
    "title": "EDS 240",
    "section": "",
    "text": "Are there ever opportunties to bend / break the rules & guidelines for creating “good” data viz?"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#ok-break-rules",
    "href": "slides/week5.1-good-viz-slides.html#ok-break-rules",
    "title": "EDS 240",
    "section": "",
    "text": "Breaking the rules is sometimes okay\n\n\nData visualization is both a science and an art. Following these rules / best practices can help us avoid common pitfalls and avoid creating objectively difficult-to-interpret data visualizations.\n\nHowever, there are arguments for bending (or breaking) the rules every now and again. Consider the following posts:\n\n\nWhy you sometimes need to break the rules in data viz, by Rosamund Pearce\nMaster the rules - then break them, by Dieuwertje van Dijk\nDoes Data Visualization Have Rules? Or Is It All Just “It Depends”?, by Nick Desbarats"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#iraq-war",
    "href": "slides/week5.1-good-viz-slides.html#iraq-war",
    "title": "EDS 240",
    "section": "",
    "text": "Breaking the rules is sometimes okay\n\n\n\nAward-winning data visualization by Simon Scarr (left), and a copy / remake of that visualization which follows the rules, created by Andy Cotgreave (right).\nImage & caption source: Master the rules - then break them"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#examples",
    "href": "slides/week5.1-good-viz-slides.html#examples",
    "title": "EDS 240",
    "section": "",
    "text": "Let’s consider some example data visualizations together"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#co2-1",
    "href": "slides/week5.1-good-viz-slides.html#co2-1",
    "title": "EDS 240",
    "section": "",
    "text": "CO2 in conference rooms\n\n\n\n\n\n\n\n\n\n\n\n\n\nClearing the Air, by Christopher Ingraham, writing for The Washington Post\n\n\n \nTake some time to discuss the following:\n\nwhere are your eyes drawn first, second, etc.?\nwhat are the main messages / takeaways?\nwhere has the author chosen to simplify this visualization (i.e. reduce extraneous elements)? does it make it easier / more challenging to interpret?\nwhat would you change about this visualization?\n\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#co2-2",
    "href": "slides/week5.1-good-viz-slides.html#co2-2",
    "title": "EDS 240",
    "section": "",
    "text": "Annotations adapted from @chezVoila"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#penguins",
    "href": "slides/week5.1-good-viz-slides.html#penguins",
    "title": "EDS 240",
    "section": "",
    "text": "Palmer penguin classification\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerfectly Proportional Penguins, by Cara Thompson as part of TidyTuesday (code)\n\n\n \nTake some time to discuss the following:\n\nwhere are your eyes drawn first, second, etc.?\nwhat are the main messages / takeaways?\nwhere has the author chosen to simplify this visualization (i.e. reduce extraneous elements)? does it make it easier / more challenging to interpret?\nwhat would you change about this visualization?\n\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#glimmers",
    "href": "slides/week5.1-good-viz-slides.html#glimmers",
    "title": "EDS 240",
    "section": "",
    "text": "Glimmers of hope in large carnivore recovery\n\n\n\n\n\n\n\n\n\n\n\n\n\nFig. 3, by Ingeman et al. 2022: Glimmers of hope and critical cases. Distribution of large carnivore species across categories of current IUCN status (x-axis) and population trend (y-axis). Improvements in status are indicated by gold and declines by blue, with bubble size indicating the number of status category changes. The majority of species have not undergone any changes in status (shown in light gray). Note: No change in status may indicate lack of recent assessment, insufficient data, or, in the case of species designated Least Concern, effective conservation efforts.\n\n\n \nTake some time to discuss the following:\n\nwhere are your eyes drawn first, second, etc.?\nwhat are the main messages / takeaways?\nwhere has the author chosen to simplify this visualization (i.e. reduce extraneous elements)? does it make it easier / more challenging to interpret?\nwhat would you change about this visualization?\n\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.1-good-viz-slides.html#end-break",
    "href": "slides/week5.1-good-viz-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 3) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#title-slide",
    "href": "slides/week3.3-evolution-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 3.3\nVisualizing evolution\n\nWeek 3 | January 22nd, 2024"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#viz-evolution",
    "href": "slides/week3.3-evolution-slides.html#viz-evolution",
    "title": "EDS 240",
    "section": "",
    "text": "Visualizing data evolution?\n\n \n\n\nVisualizing the change in a numeric variable over some unit of time."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#roadmap1",
    "href": "slides/week3.3-evolution-slides.html#roadmap1",
    "title": "EDS 240",
    "section": "",
    "text": "Roadmap\n\n\nIn this lesson, we’ll be exploring two primary chart types:\n\n1. line graphs\n2. area charts"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#roadmap2",
    "href": "slides/week3.3-evolution-slides.html#roadmap2",
    "title": "EDS 240",
    "section": "",
    "text": "Roadmap\n\n\nIn this lesson, we’ll be exploring two primary chart types:\n\n1. line graphs\n\navoiding spaghetti plots\ncutting the y-axis\naspect ratio\n\n2. area charts\n\n1 vs. multiple groups\nhow to interpret them\nstacked vs. proportional stacked area chart\nconsiderations"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#lyme-data",
    "href": "slides/week3.3-evolution-slides.html#lyme-data",
    "title": "EDS 240",
    "section": "",
    "text": "The data: Lyme disease\n\nLyme disease has been a nationally notifiable condition in the United States since 1991. Reports of Lyme disease are collected and verified by local and state health departments, anonymized by the National Notifiable Diseases Surveillance System (NNDSS), then shared with Centers for Disease Control and Prevention (CDC). The CDC has developed a public use data set for download to facilitate the public health and research community’s access to NNDSS data on Lyme disease.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\nUsing the publicly-available CDC data on Lyme disease and population estimates from the US Census Bureau (via the {tidycensus} package), we’ll explore changes in Lyme disease incidence (cases/100k people) over time, by state.\n\nNNDSS is a nationwide collaboration that enables all levels of public health to share health information to monitor, control, and prevent the occurrence and spread of state-reportable and nationally notifiable infectious (and some noninfectious) diseases and conditions."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#tidycensus",
    "href": "slides/week3.3-evolution-slides.html#tidycensus",
    "title": "EDS 240",
    "section": "",
    "text": "{tidycensus} for accessing US population data\n\n\n\n  \nThe {tidycensus} package allows users to interface with a select number of the US Census Bureau’s data APIs and return tidyverse-ready data frames.\n\nUsing {tidycensus} requires that you first have an API key. Be sure to follow the Pre-Course setup instructions for requesting and activating your key before proceeding."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#lyme-wrangling",
    "href": "slides/week3.3-evolution-slides.html#lyme-wrangling",
    "title": "EDS 240",
    "section": "",
    "text": "Data wrangling\n\n\nSee the online documentation for more information on downloading and parsing population data using the {tidycensus} package.\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#.........................load libraries.........................\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(gghighlight)\n\n#.........................source API key.........................\nsource(here::here(\"week3\", \"KEYS.R\"))\ncensus_api_key(censusKEY)\n\n#..........................import data...........................\nlyme &lt;- read_csv(here::here(\"week3\", \"data\", \"LD-Case-Counts-by-County-01-20.csv\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          wrangle lyme disease data                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#............wide to long (plus some other wrangling)............\nlyme_clean &lt;- lyme |&gt; \n  \n  # make col names snake_case ----\n  janitor::clean_names() |&gt; \n  \n  # rename columns ----\n  rename(city = ctyname, state = stname, status = ststatus) |&gt; \n  \n  # wide to long (tidy) years\n  pivot_longer(cols = 6:25, names_to = \"city_year\", values_to = \"reported_cases\") |&gt; \n  \n  # remove \"cases\" from the year & coerce year from chr to factor ----\n  mutate(year = str_remove(city_year, pattern = \"cases\"),\n         year = as.factor(year)) |&gt; \n  \n  # select necessary cols ----\n  select(year, city, state, status, reported_cases)\n\n#................calculate total cases per state.................\nlyme_by_state &lt;- lyme_clean |&gt; \n  group_by(year, state) |&gt; \n  summarize(total_cases = sum(reported_cases)) \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                      request / wrangle population data                   ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#...................get pop estimates by state...................\nus_state_pop &lt;- get_estimates(geography = \"state\", \n                              product = \"population\",\n                              state = NULL, \n                              year = 2019) |&gt; \n  filter(variable == \"POP\") |&gt; \n  select(state = NAME, population = value) \n\n#........................write data to csv.......................\n# optional, but recommended in case you want to work offline, the API is down, etc. (you can then read in your saved data file rather than run the above code)\n# write_csv(us_state_pop, file = here::here(\"week3\", \"data\", \"us_state_pop.csv\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            join lyme & pop dfs                           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nlyme_pop &lt;- left_join(lyme_by_state, us_state_pop) |&gt; \n  \n  # add col with num of 100k people per state ----\n  mutate(pop100k = population/100000) |&gt; \n  \n  # calculate num cases per 100k people (common way of reporting disease incidence) ----\n  mutate(cases_per100k = total_cases/pop100k)"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#basic-line-plot1",
    "href": "slides/week3.3-evolution-slides.html#basic-line-plot1",
    "title": "EDS 240",
    "section": "",
    "text": "Line plots show the evolution of 1+ numeric variables\n\nLine graphs display the evolution of one or several numeric variables. They are similar to scatter plots, but the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. They are often used to visualize a trend in data over intervals of time. For example, changes in Lyme disease incidence (# cases / 100k people) from 2010 - 2020, by state:\n\n\n\nA basic line graph using geom_line()\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) + \n  geom_line()"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#basic-line-plot2",
    "href": "slides/week3.3-evolution-slides.html#basic-line-plot2",
    "title": "EDS 240",
    "section": "",
    "text": "Line plots show the evolution of 1+ numeric variables\n\nLine graphs display the evolution of one or several numeric variables. They are similar to scatter plots, but the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. They are often used to visualize a trend in data over intervals of time. For example, changes in Lyme disease incidence (# cases / 100k people) from 2010 - 2020, by state:\n\n\n\nA basic line graph using geom_line()\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) + \n  geom_line()\n\n\n\n\n\n\nA line + scatter plot created by layering geom_line() & geom_point()\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) + \n  geom_line() +\n  geom_point()"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#spaghetti-plot",
    "href": "slides/week3.3-evolution-slides.html#spaghetti-plot",
    "title": "EDS 240",
    "section": "",
    "text": "“Spaghetti plots” are hard to read\n\nA line plot with many lines displayed together can be hard to read / overwhelming to interpret. Consider highlighting a group(s) of interest (the {gghighlight} package comes in handy):\n\n\n\nE.g. I’m interested in how Lyme disease in New Jersey compares to other states.\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line() +\n  gghighlight::gghighlight(state == \"New Jersey\") \n\n\n\n\n\n\n\n\n\n\nE.g. I’m interested in states where Lyme disease incidence is (or at one point was) &gt; 100 cases / 100k people.\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, color = state)) +\n  geom_line() +\n  gghighlight::gghighlight(max(cases_per100k) &gt; 100)"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#cut-y",
    "href": "slides/week3.3-evolution-slides.html#cut-y",
    "title": "EDS 240",
    "section": "",
    "text": "It’s okay to cut the y-axis of line graphs\n\nLine graphs encode data by position and not length (e.g. as in the height of a bar graph), therefore, you can choose to include the 0 origin only if it makes sense.\n\n\n\nLyme disease incidence from 2013 - 2019\n(cut y-axis = default)\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2013:2019)) |&gt; \n  filter(state == \"Vermont\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nLyme disease incidence from 2013 - 2019\n(force y-axis origin at 0)\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2013:2019)) |&gt; \n  filter(state == \"Vermont\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line() +\n  scale_y_continuous(limits = c(0, NA))"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#cut-y-dow",
    "href": "slides/week3.3-evolution-slides.html#cut-y-dow",
    "title": "EDS 240",
    "section": "",
    "text": "It’s okay to cut the y-axis of line graphs\n\nDo not start the y-axis at 0 if the range of data is small but the distance from the bottom of the range to zero is large. For example:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from Meghan Hall’s Statistical Graphics & Visualization course Lecture 5 slides."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#cut-y-temps",
    "href": "slides/week3.3-evolution-slides.html#cut-y-temps",
    "title": "EDS 240",
    "section": "",
    "text": "It’s okay to cut the y-axis of line graphs\n\nDo not start the y-axis at 0 if the relationship to zero is insignificant. For example:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from Meghan Hall’s Statistical Graphics & Visualization course Lecture 5 slides."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#aspect-ratio",
    "href": "slides/week3.3-evolution-slides.html#aspect-ratio",
    "title": "EDS 240",
    "section": "",
    "text": "Aspect ratio affects perception of slope\n\nThe aspect ratio is the height:width ratio of a graph. The larger the aspect ratio, the steeper changes appear, which may cause readers to interpret changes as more important. The smaller the aspect ratio, the flatter the line which may cause readers to interpret changes as small / insignificant.\n\n\nImage source: Graph workflow\n\nThere’s no exact rule for what aspect ratio to use for a given graphic (but see Cleveland et al. 1988 to read about the “banking to 45 degrees” rule) – it depends on the nature of the variable and your goal with the visualization. However it’s important to keep mind that manipulating the aspect ratio can mislead readers, and so you should do so carefully."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#aspect-ratio-sunspots-default",
    "href": "slides/week3.3-evolution-slides.html#aspect-ratio-sunspots-default",
    "title": "EDS 240",
    "section": "",
    "text": "Aspect ratio affects perception of slope\n\nConsider this line graph of sunspot activity from 1700 - 2015. It was created using Stata’s default aspect ratio. Can you easily identify where in time sunspot activity rises more quickly / sharply than others?\n\n\nImage source: Graph workflow"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#aspect-ratio-sunspots-wide",
    "href": "slides/week3.3-evolution-slides.html#aspect-ratio-sunspots-wide",
    "title": "EDS 240",
    "section": "",
    "text": "Aspect ratio affects perception of slope\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: The bottom plot is the same as the top, but with the x-axis split into panels / rows, by decade.\nWith a wider aspect ratio, we can more clearly see the differences in rates of change (slopes) in sunspot activity through time.\n\n\n\nImage source: Graph workflow"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#ggplot-default-ar",
    "href": "slides/week3.3-evolution-slides.html#ggplot-default-ar",
    "title": "EDS 240",
    "section": "",
    "text": "ggplot with a default aspect ratio\n\nLet’s first look at Lyme disease incidence for Vermont from 2010 - 2020 without adjusting the aspect ratio:\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state == \"Vermont\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line()"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#ggplot-default-ar-ticks",
    "href": "slides/week3.3-evolution-slides.html#ggplot-default-ar-ticks",
    "title": "EDS 240",
    "section": "",
    "text": "ggplot with a default aspect ratio\n\nWe have 10 units on our x-axis (year ranges from 2010 - 2020), and ~175 units (case_per100k ranges from 0 to ~175) on our y-axis. By default, ggplot adjusts the space between each x-axis unit so that they are wider apart than each y-axis unit, making the plot easier to read. Below, we’ve added in tick marks for each y-axis unit to better highlight this (a single tick already existed for each of our 10 x-axis units).\n\n\nNote: This plot doesn’t render well on these slides or in the RStudio plot pane. I recommend running the code in RStudio, then clicking the Zoom button in the Plot pane for best viewing.\n\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state == \"Vermont\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line() +\n  scale_y_continuous(breaks = seq(0, 190, by = 1))"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#aspect-ratio-ggplot-equal",
    "href": "slides/week3.3-evolution-slides.html#aspect-ratio-ggplot-equal",
    "title": "EDS 240",
    "section": "",
    "text": "Adjust the aspect ratio using coord_fixed()\n\nWe can use coord_fixed() to fix the aspect ratio of our plot. The ratio argument controls the aspect ratio, which is expressed as y / x and by default is set to 1. This means that the height of one y-unit is equal to the width of one x-unit (paying attention to the grid lines and tick marks here can be helpful). Because we have 175 y-axis units and only 10 x-axis units, fixing our aspect ratio at 1:1 means our plot gets taller and squished.\n\n\nNote: This plot doesn’t render well in thse slides or in the RStudio plot pane. I recommend running the code in RStudio, then clicking the Zoom button in the Plot pane for best viewing.\n\n\n\nlyme_pop |&gt; \n  filter(state == \"Vermont\") |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line() +\n  scale_y_continuous(breaks = seq(0, 190, by = 1)) +\n  coord_fixed(ratio = 1)"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#aspect-ratio-ggplot-update",
    "href": "slides/week3.3-evolution-slides.html#aspect-ratio-ggplot-update",
    "title": "EDS 240",
    "section": "",
    "text": "Adjust the aspect ratio using coord_fixed()\n\nRatios &gt; 1 will make units on the y-axis longer than units on the x-axis (resulting in steeper slopes). Ratios &lt; 1 will make units on the x-axis longer than units on the y-axis (resulting in shallower slopes). If we want to make our graph wider, we’ll need to update ratio so that it’s &lt; 1. For example:\n\nlyme_pop |&gt; \n  filter(state == \"Vermont\") |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_line() + \n  coord_fixed(ratio = 1/50)\n\n\n\nPlaying around with the ratio value yourself is the best way to get a sense for how the aspect ratio of a given ggplot will change."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#area-chart",
    "href": "slides/week3.3-evolution-slides.html#area-chart",
    "title": "EDS 240",
    "section": "",
    "text": "Area chart is similar to a line graph, just filled in\n\nInstead of just a line or scatter plot to indicate the change in a numeric variable through time, the space between the line and the x-axis is colored or shaded in. Area plots are sometimes criticized for violating the data-ink ratio rule, which argues that any non-data-ink should be omitted wherever possible. If the number of observations is low (as in this example) a connected scatter plot may more clearly show when each observation was made.\n\n\n\nA basic area plot (New Jersey)\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state == \"New Jersey\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state)) +\n  geom_area() \n\n\n\n\n\n\n\n\n\n\nUpdate the fill color\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state == \"New Jersey\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +\n  geom_area() +\n  scale_fill_manual(values = c(\"#047C90\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nExpand area to panel margins\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state == \"New Jersey\") |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +\n  geom_area() +\n  scale_fill_manual(values = c(\"#047C90\")) +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#stacked-area-chart",
    "href": "slides/week3.3-evolution-slides.html#stacked-area-chart",
    "title": "EDS 240",
    "section": "",
    "text": "Stacked area charts show the evolution of a whole + the relative contribution of each group\n\nStacked area charts are useful for showing the evolution of a whole and the relative proportions of each group that make up the whole. For example, the top of the colored area shows the total Lyme disease incidence (# cases / 100k people) across all groups (notice the difference in y-axis values), while the individual colors are the relative contributions of the top 4 states with the highest lyme disease incidence:\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state %in% c(\"Maine\", \"Rhode Island\", \"New Hampshire\", \"Vermont\")) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +\n  geom_area()"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#proportional-stacked-area",
    "href": "slides/week3.3-evolution-slides.html#proportional-stacked-area",
    "title": "EDS 240",
    "section": "",
    "text": "A variant: proportional stacked area charts\n\nProportional stacked area charts plot percentage contribution instead of absolute numbers on the y-axis. The focus of this version is the proportion of contribution made by each category rather than absolute numbers.\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state %in% c(\"Maine\", \"Rhode Island\", \"New Hampshire\", \"Vermont\")) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +\n  geom_area(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 100))"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#stacked-area-group-order",
    "href": "slides/week3.3-evolution-slides.html#stacked-area-group-order",
    "title": "EDS 240",
    "section": "",
    "text": "Group order matters!\n\nGroup order (from bottom to top) can have an influence – oftentimes, you’ll want to put the most important group on the bottom (closest to the x-axis), since your audience will have an easier time reading values for that group. For example, US Drought Monitor likely wanted to draw attention to what percentage of land area in CA experienced the highest-severity drought level (D4, Exceptional). By plotting that group on the bottom of the graph below, we can more easily identify that ~60% of CA experienced the worst level of drought in 2014-2015.\n\n\n\n\n\n\n\n\n\n\n\n\n \n You’ll be recreating this graph (original source US Drought Monitor, via Wikipedia) in discussion section this week!\n\n\nThis article by Info River nicely outlines situations where using a stacked area chart is great, when not to use them, and important considerations."
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#stacked-area-chart-challenge",
    "href": "slides/week3.3-evolution-slides.html#stacked-area-chart-challenge",
    "title": "EDS 240",
    "section": "",
    "text": "Stacked area charts are not good for studying the evolution of individual groups\n\nIt is super challenging to subtract the height of groups from one another at any / each given point in time. For example, both of the charts below show the same data (Lyme disease incidence (# cases / 100k people) for Maine, New Hampshire, Rhode Island, and Vermont):\n\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state %in% c(\"Maine\", \"Rhode Island\", \"New Hampshire\", \"Vermont\")) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +\n  geom_area()\n\n\n\n\n\n\n\n\n\n\nlyme_pop |&gt; \n  filter(year %in% c(2010:2020)) |&gt; \n  filter(state %in% c(\"Maine\", \"Rhode Island\", \"New Hampshire\", \"Vermont\")) |&gt; \n  ggplot(aes(x = year, y = cases_per100k, group = state, color = state)) +\n  geom_line() +\n  facet_wrap(~state)"
  },
  {
    "objectID": "slides/week3.3-evolution-slides.html#end",
    "href": "slides/week3.3-evolution-slides.html#end",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 3 (of 3) ~"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#title-slide",
    "href": "slides/week4.2-relationships-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 4.2\nVisualizing numerical relationships\n\nWeek 4 | January 29th, 2024"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#numerical-relationships",
    "href": "slides/week4.2-relationships-slides.html#numerical-relationships",
    "title": "EDS 240",
    "section": "",
    "text": "Visualizing numerical relationships?\n\n\n\nFor visualizing the relationship between (typically) two numeric variables.\n\n\n\n\nLine graphs (from week 3) are similar to scatter plots, except the x-axis variable is ordered chronologically and points are connected by lines to emphasize trends."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#roadmap1",
    "href": "slides/week4.2-relationships-slides.html#roadmap1",
    "title": "EDS 240",
    "section": "",
    "text": "Roadmap\n\n\nIn this lesson, we’ll be exploring two main primary chart types:\n\n1. scatter plots\n2. 2d density plots"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#roadmap",
    "href": "slides/week4.2-relationships-slides.html#roadmap",
    "title": "EDS 240",
    "section": "",
    "text": "Roadmap\n\n\nIn this lesson, we’ll be exploring two main primary chart types:\n\n1. scatter plots\n\nadding rug or marginal density plots to visualize distribution\nadding trend lines\nadding a third numeric variable (challenges & considerations)\n\n2. 2d density plots\n\nstrategies for dealing with overplotting"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#stream-data",
    "href": "slides/week4.2-relationships-slides.html#stream-data",
    "title": "EDS 240",
    "section": "",
    "text": "The data: Hubbard Brook Watershed stream chemistry\n\nThe Hubbard Brook Experimenatal Forest is a 8,700-acre hardwood research forest in the White Mountains of New Hampshire and home to a series of small watersheds occupying the valley’s north- and south-facing slopes.\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hubbard Brook Experimental Forest, downloaded from the Hubbard Brook Ecosystem Study Photo Galleries\n\n\n\nSince 1963, researchers have collected and analyzed weekly stream and precipitation data from the forest’s watersheds. Read about these long term data on DataOne.\nThese long-term data have contributed to important research, including the discovery of acid rain in North America.\nIn this lesson, we’ll explore the effects of various compounds on stream water pH (a lower pH = more acidic).\n\n\n\nI admittedly don’t know much about water chemistry, but have skimmed a number of helpful resources throughout the creation of this lesson. They’ll be linked as referenced."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#data-wrangling",
    "href": "slides/week4.2-relationships-slides.html#data-wrangling",
    "title": "EDS 240",
    "section": "",
    "text": "Data wrangling\n\nOur data don’t require much wrangling, though we will practice using the {metajam} package for downloading and reading in data from repositories in the DataOne network.\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(metajam) \nlibrary(tidyverse)\n\n#...................download data from DataOne...................\ndownload_d1_data(\"https://cn.dataone.org/cn/v2/resolve/https%3A%2F%2Fpasta.lternet.edu%2Fpackage%2Fdata%2Feml%2Fknb-lter-hbr%2F208%2F9%2F3b3cf7ea447cb875d7c7d68ebdfd24c7\",\n                 path = here::here(\"week4\")) \n\n#  ~ NOTE: I recommend renaming the downloaded folder to 'data/' so that it's ignored by .gitignore! ~\n\n#....................read in downloaded files....................\nstream_chem_all &lt;- read_d1_files(here::here(\"week4\", \"data\"))\n\n#........................get the data file.......................\nstream_chem_data &lt;- stream_chem_all$data"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#basic-scatter",
    "href": "slides/week4.2-relationships-slides.html#basic-scatter",
    "title": "EDS 240",
    "section": "",
    "text": "Basic scatter plot\n\nThe pH of surface water and topsoil may be lower in the presence of dissolved organic matter (e.g. see Erlandsson et al. 2010 & Zhou et al. 2019.)). To start, let’s look at the effects of DOC on pH for just the most recent water year (2021):\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5)"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#rug-plot",
    "href": "slides/week4.2-relationships-slides.html#rug-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Rug plots help to visualize the distribution of data\n\nRug plots add distribution marks (one narrow line for each data point) along the x and y axes of your plot:\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5) +\n  geom_rug()"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#ggMarginal",
    "href": "slides/week4.2-relationships-slides.html#ggMarginal",
    "title": "EDS 240",
    "section": "",
    "text": "Try marginal plots as an alternative to geom_rug()\n\nThe {ggExtra} package can be used to add marginal histograms / boxplots / density plots to ggplot scatter plots:\n\n\n\np1 &lt;- stream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5)\n\nggExtra::ggMarginal(p1, type = \"histogram\")\n\n\n\n\n\n\n\n\n\n\np1 &lt;- stream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5)\n\nggExtra::ggMarginal(p1, type = \"density\")\n\n\n\n\n\n\n\n\n\n\np1 &lt;- stream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5)\n\nggExtra::ggMarginal(p1, type = \"boxplot\")\n\n\n\n\n\n\n\n\n\n\nExplore a variety of other parameters to adjust the appearance of your marginal plots (e.g. col, fill, binwidth, etc.). You can add marginal plots on just a single axis (e.g. margins = \"x\" for just a marginal plot along the x-axis), or separately adjust the appearance of marginal plots (e.g. xparams = list(fill = \"red\"))"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#ggMarginal-groups",
    "href": "slides/week4.2-relationships-slides.html#ggMarginal-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Marginal plots also work with groups\n\nHere, we color points by site. It can be helpful to move the legend above or below the plot so that the marginal plot sit cleanly against the right-hand side of graph:\n\np2 &lt;- stream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = site)) + \n  geom_point(alpha = 0.5) +\n  theme(legend.position = \"bottom\")\n\nggExtra::ggMarginal(p2, type = \"density\", groupFill = TRUE, groupColour = TRUE)"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#trend-lines1",
    "href": "slides/week4.2-relationships-slides.html#trend-lines1",
    "title": "EDS 240",
    "section": "",
    "text": "Adding trend lines – default behavior\n\nYou may consider adding a best fit line to help you readers more easily identify trends in your data. Let’s do that for a subset of our data (site W8, year 2021).\n\nIf you have &lt;1000 data points, geom_smooth() defaults to using a method called “LOESS” (locally estimated scatter plot smoothing), which draws a line that’s similar to a moving average. It will also include a confidence interval ribbon:\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  filter(site == \"W8\") |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5) +\n  geom_smooth()"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#trend-lines2",
    "href": "slides/week4.2-relationships-slides.html#trend-lines2",
    "title": "EDS 240",
    "section": "",
    "text": "Update method & remove CI\n\nOftentimes, you’ll want a line of best fit. Specify a linear model using the method argument.\nIt’s also best to remove the confidence interval band – it can make it a bit clearer to your audience that this is just a trend line and not a properly analyzed linear model (e.g. we haven’t checked for equal variances, normality of residuals).\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  filter(site == \"W8\") |&gt; \n  ggplot(aes(x = DOC, y = pH)) + \n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nCheck out chapter 5.2 & chapter 6.3 in An Introduction to R, by Alex Douglas, Deon Roos, Francesca Mancini, Ana Couto & David Lusseau, for a great (re)introduction to geom_smooth() and simple linear modeling."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#third-var",
    "href": "slides/week4.2-relationships-slides.html#third-var",
    "title": "EDS 240",
    "section": "",
    "text": "Bubble charts for visualizing a third numeric variable\n\nLow pH levels can increase the solubility of heavy metals, like aluminum (Al). High levels of Al can limit the growth and reproduction of aquatic species.\nWe can use a bubble chart to represent this third numeric variable (Al) through the size of our scatter plot points. Here, we also update our x-axis and legend titles:\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = site, size = Al_ICP)) + \n  geom_point(alpha = 0.5) +\n  labs(x = \"DOC (mg/L)\", size = \"Al (mg/L)\", color = \"Site\")"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#third-var-difficult",
    "href": "slides/week4.2-relationships-slides.html#third-var-difficult",
    "title": "EDS 240",
    "section": "",
    "text": "Use size to represent a third numeric variable cautiously\n\n\nBubble charts encode values based on both position (within the Cartesian coordinate system) and size. Some challenges with this:\n\n\nwe (humans) generally have an easier time perceiving differences in position rather than size – the relationship between your x- and y-axis variables will be the primary focus\nit can be hard to compare the strengths of different associations – is there an alternative (e.g. 2+ separate scatter plots) way of presenting your data to better highlight this?\nit’s difficult to see small differences in size – if the range of values mapped to size is small, your bubbles will look indistinguishable from one another\nit can be difficult to match a bubble’s size to the scale of difference in the legend – consider adjusting the size range of your scale"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#bub-size",
    "href": "slides/week4.2-relationships-slides.html#bub-size",
    "title": "EDS 240",
    "section": "",
    "text": "Adjust the size range of bubbles\n\nUse scale_size() to adjust the area range of the bubbles:\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = site, size = Al_ICP)) + \n  geom_point(alpha = 0.5) +\n  scale_size(range = c(1, 10)) +\n  labs(x = \"DOC (mg/L)\", size = \"Al (mg/L)\", color = \"Site\")\n\n\nAlternatively, using scale_size_area() ensures that the value of 0 is mapped to a size of 0."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#bub-size-area",
    "href": "slides/week4.2-relationships-slides.html#bub-size-area",
    "title": "EDS 240",
    "section": "",
    "text": "Always scale bubble area by value\n\nBy default, ggplot scales bubble area by value, rather than radius or diameter. Scaling the radius or diameter by value can be deceiving – a point with 2x the value of another point would end up having 4x the area, making it’s value appear larger than warranted:\n\n\n\nScaling size by area using scale_size()\n\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = site, size = Al_ICP)) + \n  geom_point(alpha = 0.5) +\n  scale_size(range = c(1, 10)) +\n  labs(x = \"DOC (mg/L)\", size = \"Al (mg/L)\", color = \"Site\")\n\n\n\n\n\n\n\n\n\n\nScaling size by radius using scale_radius()\n\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = site, size = Al_ICP)) + \n  geom_point(alpha = 0.5) +\n  scale_radius(range = c(1, 10)) +\n  labs(x = \"DOC (mg/L)\", size = \"Al (mg/L)\", color = \"Site\")"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#2-scatter-plots",
    "href": "slides/week4.2-relationships-slides.html#2-scatter-plots",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatively, just use 2 separate scatter plots\n\n\nRather than mapping a third numeric variable to point size, consider if just creating two separate scatter plots may help to more effectively visualize the relationships:\n\n\n\n\nVisualizing the effect of DOC on pH\n\n\n\n\n\n\n\n\nVisualizing the effect of Al_ICP on pH"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#scale-by-color",
    "href": "slides/week4.2-relationships-slides.html#scale-by-color",
    "title": "EDS 240",
    "section": "",
    "text": "Visualizing a third numeric variable using color\n\nRather than coloring points by site, we can map color to them based on our third continuous numeric variable, Al_ICP. We’ll also apply the viridis color map:\n\nstream_chem_data |&gt; \n  filter(waterYr == 2021) |&gt; \n  ggplot(aes(x = DOC, y = pH, color = Al_ICP)) + \n  geom_point(alpha = 0.5, size = 2) +\n  scale_color_viridis_c() +\n  labs(x = \"DOC (mg/L)\", color = \"Al (mg/L)\")"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#overplotting",
    "href": "slides/week4.2-relationships-slides.html#overplotting",
    "title": "EDS 240",
    "section": "",
    "text": "Overplotting can disguise trends\n\nSometimes, we just have too many data points for a traditional scatter plot to be effective. For example, what if we want to plot all data (not just the 2021 water year subset)? Here, we plot sulfate concentration (SO4) against pH:\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) + \n  geom_point()"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#initial-strategies",
    "href": "slides/week4.2-relationships-slides.html#initial-strategies",
    "title": "EDS 240",
    "section": "",
    "text": "Some initial strategies\n\nDepending on how many points you have and the message you want to convey, you may consider the following:\n\n\n\n\nSmaller points and / or transparency\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) + \n  geom_point(size = 0.5, alpha = 0.3) \n\n\n\n\n\n\n\n\n\n\nAdd a rug plot\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) + \n  geom_point(size = 0.5, alpha = 0.3) +\n  geom_rug()\n\n\n\n\n\n\n\n\n\n\nColor by group\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH, color = site)) + \n  geom_point(size = 0.5, alpha = 0.3) \n\n\n\n\n\n\n\n\n\n\n\n\nBut with a really large number of points, these strategies may not make interpretation much easier…"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#heatmaps",
    "href": "slides/week4.2-relationships-slides.html#heatmaps",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatively, try a heatmap\n\nYou might imagine that you’re looking down on a histogram, where lighter areas indicate a higher density of points.\n\n\n\nheatmap of 2d bin counts\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  geom_bin2d() +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\nhexagonal heatmap of 2d bin counts\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  geom_hex() +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\nSimilar to a histogram, you can update the number of bins or binwidth."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#cont-legend",
    "href": "slides/week4.2-relationships-slides.html#cont-legend",
    "title": "EDS 240",
    "section": "",
    "text": "Adjust legend appearance using guides()\n\nCheck out the guides() function for tweaking the appearance of your legend (e.g. increasing the height can help readers more easily read the continuous color scale):\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  geom_hex() +\n  scale_fill_viridis_c() + \n  guides(fill = guide_colourbar(title = \"Count\", \n                                barwidth = 1, barheight = 15))"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#2d-density",
    "href": "slides/week4.2-relationships-slides.html#2d-density",
    "title": "EDS 240",
    "section": "",
    "text": "Another option: 2d density / contour plots\n\nThese are the 2d equivalents to creating a density plot using geom_density() (see week 3 materials).\n\n\n\ncontours of a 2d density estimate\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  geom_density_2d() # include `aes(color = ..level..)` if you want to color contours by level of density\n\n\n\n\n\n\n\n\n\n\nfilled in contours\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  geom_density_2d_filled()\n\n\n\n\n\n\n\n\n\n\n\n\nThese can be a bit confusing to read / interpret"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#2d-density-interpretation",
    "href": "slides/week4.2-relationships-slides.html#2d-density-interpretation",
    "title": "EDS 240",
    "section": "",
    "text": "What’s up with that legend?\n\nThe legend provides us with an estimate of the proportion of data points fall within a colored region. The density of the distribution of points sums to 1.\n\nIn this example, 0-2% of of points fall within a 1x1 square in the darkest blue region, while 26-28% fall within a 1x1 square in the brightest yellow region."
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#ggdensity",
    "href": "slides/week4.2-relationships-slides.html#ggdensity",
    "title": "EDS 240",
    "section": "",
    "text": "Consider using the {ggdensity} equivalent geoms\n\nThe {ggdensity} package provides alternative functions, geom_hdr_lines() and geom_hdr(), as drop-in replacements for geom_density_2d() and geom_density_2d_filled() (respectively).\n\n\n\n\ncontour lines using geom_hdr_lines()\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  ggdensity::geom_hdr_lines()\n\n\n\n\n\n\n\n\n\n\nfilled contours using geom_hdr()\n\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  ggdensity::geom_hdr()"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#interpret-ggdensity",
    "href": "slides/week4.2-relationships-slides.html#interpret-ggdensity",
    "title": "EDS 240",
    "section": "",
    "text": "Interpreting {ggdensity} plots\n\nThese geoms similarly perform 2D density estimation, then compute and plot the resulting highest density regions (HDRs). These HDRs are computed to be the smallest such regions that bound that level of probability. By default, regions show the 50%, 80%, 95%, and 99% HDRs of the estimated density (though this can be updated using the probs argument).\n\nggplot(stream_chem_data, aes(x = SO4, y = pH)) +\n  ggdensity::geom_hdr() # update prob level e.g. `probs = c(0.99, 0.75, 0.5, 0.25)`"
  },
  {
    "objectID": "slides/week4.2-relationships-slides.html#end-break",
    "href": "slides/week4.2-relationships-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 2 (of 2) ~"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#title-slide",
    "href": "slides/week5.2-colors-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 5.2\nColors\n\nWeek 5 | February 5th, 2024"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#good-design",
    "href": "slides/week5.2-colors-slides.html#good-design",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)\n\n\nThis lesson will focus on the use of colors in a good data visualization."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#why-color",
    "href": "slides/week5.2-colors-slides.html#why-color",
    "title": "EDS 240",
    "section": "",
    "text": "Why do we use color?\n\n\nSpend a couple minutes discussing with your Learning Partners the following:\n\n\nWhy and / or when should we use color in data visualizations?\n\n\nFind an example(s) of a data viz that uses color to convey information to share in #eds-240-data viz. Note some of your own observations about the color choices (i.e. why these colors? palette arrangement?).\n\n\n\n\n\n−+\n02:00\n\n\n\n\n\nevoke emotions\nhighlight important data / concepts\nbranding"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#colors-difficult",
    "href": "slides/week5.2-colors-slides.html#colors-difficult",
    "title": "EDS 240",
    "section": "",
    "text": "Choosing colors is difficult and they should be purposefully chosen\n\n\n\nYou’ll probably iterate on them as you sit with your visualization and of course, as you get feedback from others.\n\n\n\nSome places to start / things to consider:\n\nis using color the best and / or only way to visually represent your variable(s)?\n\n\n\n\nare you designing for a particular organization / brand?\nwhat emotions are you trying (or not trying) to elicit?\nwho is your audience?\nare your data commonly represented using a particular color scheme?\nwhat data types (e.g. numeric vs. categorical, discrete vs. continuous?) are you working with?"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#color-properties",
    "href": "slides/week5.2-colors-slides.html#color-properties",
    "title": "EDS 240",
    "section": "",
    "text": "What is color?\n\nThere are a number of different color spaces that are used to represent and define color. HSV and HSL are used commonly in color pickers (e.g. Google color picker). HCL underlies some default {ggplot2} parameters. You don’t need to worry much about the underlying theory of color spaces, but know that changing any of the parameters (e.g. hue, saturation, etc.) can influence how we perceive information in a data visualization.\n\n\n\n\nHSV\n\n\n\n\n\n\n\n\n\n\n\nImage source: medium.com\n\n\n\nHCL\n\n\n\n\n\n\n\n\n\n\n\nImage source: Stauffer et al. (2015) https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\n\n\n\nHue ranges from 0 to 360 (an angle) and gives the “colour” of the colour (blue, red, orange, etc).\nChroma is the “purity” of a colour, ranging from 0 (grey) to a maximum that varies with luminance.\nLuminance is the lightness of the colour, ranging from 0 (black) to 1 (white).\n\nSource: https://ggplot2-book.org/scales-colour"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#color-scales",
    "href": "slides/week5.2-colors-slides.html#color-scales",
    "title": "EDS 240",
    "section": "",
    "text": "Different color scales for different data types\n\n\n\n\n\nImage source: Which color scale to use when visualizing data, by Lisa Charlottte Muth. This is the first article of a 4 part series (Part 2 / Part 3 / Part 4) – I highly recommend reading!"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#categorical",
    "href": "slides/week5.2-colors-slides.html#categorical",
    "title": "EDS 240",
    "section": "",
    "text": "Categorical scales\n\n\nmainly formed by selecting differet hues\nhues assigned to each group must be distinct and ideally have different lightnesses\ngroups don’t have an intrinsic order\nlimit to no more than 7 hues\n\n\n\nMap source: Analyzing US Census Data, by Kyle Walker"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#sequential",
    "href": "slides/week5.2-colors-slides.html#sequential",
    "title": "EDS 240",
    "section": "",
    "text": "Sequential scales\n\n\ncolors assigned to data values in a continuum, based on lightness, hue, or both\nlower values typically associated with lighter colors & higher values associated with darker colors\ncan use a single hue or two hues\n\n\n\n\n\nMap source: Analyzing US Census Data, by Kyle Walker"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#diverging",
    "href": "slides/week5.2-colors-slides.html#diverging",
    "title": "EDS 240",
    "section": "",
    "text": "Diverging scales\n\n\ncombination of two sequential palettes with a shared endpoint at the central value\ncentral value is assigned a light color (light gray is best)\nuse a distinctive hue for each of the component palettes\n\n\n\nMap source: 2020 U.S. Election Mapped: TrumpLand vs Biden Archipelago, by Vivid Maps"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#penguin-plots",
    "href": "slides/week5.2-colors-slides.html#penguin-plots",
    "title": "EDS 240",
    "section": "",
    "text": "Base plots (for applying color scales to)\n\nWe’ll be testing out different palettes throughout this lesson. Instead of having to retype the code for our plots each time, let’s create and save two versions of a penguin scatterplot. We can then call either of these plot objects to modify with different color scales:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\n\n\n\nRequires a categorical color scale\n\n\ncat_color_plot &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) +\n  geom_point(size = 4, alpha = 0.8)\n\ncat_color_plot \n\n\n\n\n\n\n\n\n\n\nRequires a continuous color scale\n\n\ncont_color_plot &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = body_mass_g)) +\n  geom_point(size = 4, alpha = 0.8) \n\ncont_color_plot"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#accessibility",
    "href": "slides/week5.2-colors-slides.html#accessibility",
    "title": "EDS 240",
    "section": "",
    "text": "Ensuring inclusive and accessible design through your color choices"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#colorblindness",
    "href": "slides/week5.2-colors-slides.html#colorblindness",
    "title": "EDS 240",
    "section": "",
    "text": "What is colorblindness?\n\nColor vision deficiency aka colorblindness is the decreased ability to see color or differences in color. It’s estimated that about 1 in 12 men (8%) and 1 in 200 women (0.5%) are affected (Wikipedia).\n\n\nColor plate tests are used to help identify different forms of color blindness. Try using the Let’s get color blind Chrome extension to emulate different forms of colorblindness while looking at the above plates. Image source: American Optometric Association"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#rainbow-colormaps",
    "href": "slides/week5.2-colors-slides.html#rainbow-colormaps",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with rainbow color maps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolors don’t follow any natural perceived ordering (no innate sense of higher or lower)\nperceptual changes in rainbow colors are not uniform (e.g. colors appear to change faster in yellow region than green region)\ninsensitive to color vision deficiencies\n\n\n\n\n\nTop image source: Why we use bad color maps and what you cando about it | Bottom left image source: Ware C, Stone M, Albers Szafir D (2023) Rainbow colormaps are not all bad. IEEE Computer Graphics and Applications 43:88-93 10.1109/MCG.2023.3246111 | For another example of poor use of rainbow color maps, see this world map with binned colors"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#rainbow-colormaps-alt",
    "href": "slides/week5.2-colors-slides.html#rainbow-colormaps-alt",
    "title": "EDS 240",
    "section": "",
    "text": "Rainbow colormaps aren’t all bad\n\n\n\n\n\nProblematic, perceptually nonuniform and unordered rainbow colormaps\n\n\n\n\n\n\n\n\n\n\n\n\nImproved, perceptual uniform and diverging rainbow colormaps\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage source: Ware C, Stone M, Albers Szafir D (2023) Rainbow colormaps are not all bad. IEEE Computer Graphics and Applications 43:88-93 10.1109/MCG.2023.3246111\n\n\nAlso check out Stoelzle & Stein (2021) (Figure 1 is particularly helpful!) and Crameri et al. (2020) for some really great supplemental reading"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#viridis",
    "href": "slides/week5.2-colors-slides.html#viridis",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative: Viridis\n\nThe viridis color scales are perceptually-uniform (even when printed in gray scale) and colorblindness-friendly:\n\n\n\n\nContinuous viridis scales\n\n\n\n\n\n\n\n\n\n\n\n\nBinned viridis scales\n\n\n\n\n\n\n\n\n\n\n\n\nThere are a number of different ways to apply viridis color scales, but I often opt for scale_*_viridis_*() functions, which come pre-loaded with {ggplot}."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#use-viridis",
    "href": "slides/week5.2-colors-slides.html#use-viridis",
    "title": "EDS 240",
    "section": "",
    "text": "Using viridis color scales\n\n\n\n\nDiscrete viridis scales\n\n\ncat_color_plot +\n  scale_color_viridis_d(option = \"viridis\") \n\n\n\n\n\n\n\n\n\n\nContinuous viridis scales\n\n\ncont_color_plot +\n  scale_color_viridis_c(option = \"magma\")\n\n\n\n\n\n\n\nCheck out the documentation and play around with some alternative options.\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#color-brewer",
    "href": "slides/week5.2-colors-slides.html#color-brewer",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative: RColorBrewer\n\nThe ColorBrewer color scales provides color schemes for maps and other graphics. There is also a web-based interface for generating palettes.\n\n\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\n\n\n\n\n\nRColorBrewer::display.brewer.all(colorblindFriendly = TRUE)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#color-brewer-pal",
    "href": "slides/week5.2-colors-slides.html#color-brewer-pal",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative: RColorBrewer\n\n\n{RColorBrewer} comes with a couple useful functions for quickly viewing and assembling your palette’s HEX codes:\n\n\n\n\nPreview a palette with your number of desired colors:\n\n\nRColorBrewer::display.brewer.pal(n = 4, name = 'Dark2')\n\n\n\n\n\n\n\n\n\n\nPrint the HEX codes of your palette:\n\n\nRColorBrewer::brewer.pal(n = 4, name = 'Dark2')\n\n[1] \"#1B9E77\" \"#D95F02\" \"#7570B3\" \"#E7298A\""
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#use-RColorBrewer",
    "href": "slides/week5.2-colors-slides.html#use-RColorBrewer",
    "title": "EDS 240",
    "section": "",
    "text": "Using RColorBrewer color palettes\n\nUse the right function (all pre-loaded with {ggplot2}) for the type of data / palette:\n\n\n\n\nUse scale_color_brewer() to apply qualitative palettes\n\n\ncat_color_plot +\n  scale_color_brewer(palette = \"Dark2\") \n\n\n\n\n\n\nUse scale_color_distiller() for unclassed versions of continuous color scales\n\n\ncont_color_plot +\n  scale_color_distiller(palette = \"BuPu\")\n\n\n\n\n\n\nUse scale_color_fermenter() for classed versions of continuous color scales\n\n\ncont_color_plot +\n  scale_color_fermenter(palette = \"YlGnBu\")\n\n\n\n\n\n\n\n\n\n\nCheck out the documentation and play around with some alternative options.\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#outline-points",
    "href": "slides/week5.2-colors-slides.html#outline-points",
    "title": "EDS 240",
    "section": "",
    "text": "Tip: outline points to make light colors more visible\n\nRather than color points by body_mass_g, we can fill points by body_mass_g. Then, we need to change the shape of our points to 21, which is the code for an outlined, fill-able point:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, fill = body_mass_g)) +\n  geom_point(shape = 21, size = 4, alpha = 0.8) +\n  scale_fill_distiller(palette = \"BuPu\")\n\n\n\nTrick comes courtesy of Albert Rapp and his How to Use Better Colors in ggplot (3 Easy Ways) video tutorial. Check out his YouTube channel for tons of great R content."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#redundant-mapping",
    "href": "slides/week5.2-colors-slides.html#redundant-mapping",
    "title": "EDS 240",
    "section": "",
    "text": "Use redundant mapping whenever possible\n\nRecall that colors are low on the hierarchy of elementary perceptual tasks. When possible, avoid conveying important information purely through color – consider how you might additionally use shapes, symbols, typography, or annotations.\n\n\nFigure 2 from Apigo A and Oono R (2022) Plant abundance, but not plant evolutionary history, shapes patterns of host specificity in foliar fungal endophytes. Ecosphere. 13(1):e03879. https://doi.org/10.1002/ecs2.3879"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#premade-palettes",
    "href": "slides/week5.2-colors-slides.html#premade-palettes",
    "title": "EDS 240",
    "section": "",
    "text": "There are so many other great pre-made color palettes to explore, many of which take into consideration color vision deficiencies (but always double check!)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#paletteer",
    "href": "slides/week5.2-colors-slides.html#paletteer",
    "title": "EDS 240",
    "section": "",
    "text": "Use paletteer to access TONS of palettes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt would be impossible to list out on one slide all the palette packages available for use, but the {paletteer} package gets close to doing just that.\n\nIt provides a common interface for accessing a near-comprehensive list of palettes (over 2,000!!) across various packages.\n\n\n\nExplore the extensive list of supported palette packages!"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#paletteer-fxns",
    "href": "slides/week5.2-colors-slides.html#paletteer-fxns",
    "title": "EDS 240",
    "section": "",
    "text": "Use {paletteer} to generate HEX codes or apply palettes directly\n\n\n\nGenerate a list of HEX codes using one of three paletteer_*() functions\nApply a palette directly to your ggplot using one of three scale_*_paletteer_*() functions\n\n\n\n\n\n\nFind most palettes on the R Color Palettes website\n\n\n\n\n\n\n\n\n\n\n\n\nClick on any palette for more information & example plots"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#try-paletteer",
    "href": "slides/week5.2-colors-slides.html#try-paletteer",
    "title": "EDS 240",
    "section": "",
    "text": "Give {paletteer} a try (or use any package directly)!\n\nUpdate the colors of the plots below, either by using the {paletteer} package or by following the documentation for any specific package. It’s helpful to start by looking over the list of supported packages.\n\n\n\ncat_color_plot\n\n\n\n\n\n\n\n\n\n\ncont_color_plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#try-paletteer-ex",
    "href": "slides/week5.2-colors-slides.html#try-paletteer-ex",
    "title": "EDS 240",
    "section": "",
    "text": "Examples\n\n\n\n\n\nsuperbloom3 palette from {calecopal}, applied using the paletteer::scale_color_paletteer_d()\n\n\ncat_color_plot +\n  paletteer::scale_color_paletteer_d(\"calecopal::superbloom3\")\n\n\n\n\n\n\n\n\n\n\nWindCave palette from {NatParksPalette}, created using {NatParksPalette} & applied using scale_color_gradientn()\n\n\nmy_parks_palette &lt;- NatParksPalettes::natparks.pals(name = \"WindCave\", n = 20, type = \"continuous\")\n\ncont_color_plot +\n  scale_color_gradientn(colors = rev(my_parks_palette))"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#climate-colors",
    "href": "slides/week5.2-colors-slides.html#climate-colors",
    "title": "EDS 240",
    "section": "",
    "text": "Climate and environmental science visualizations can (should) draw from community standards, when possible"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#suggested-colors",
    "href": "slides/week5.2-colors-slides.html#suggested-colors",
    "title": "EDS 240",
    "section": "",
    "text": "Some widely-used climate science palettes\n\n\n\n\n\nFigure 4. Appropriate diverging and sequential colour schemes for the following climate data (a), absolute temperature (b), absolute precipitation (c), temperature anomaly (d), precipitation or runoff anomaly (e and f) other climate variables with no symbolic association . Schemes in this figure are 7 class ones designed by Cynthia Brewer, (Brewer et al. 2003)\n\n\n\nCitation: Kaye NR, Hartley A, Hemming D (2012) Mapping the climate: guidance on appropriate techniques to map climate variables and their uncertainty. Geoscientific Model Development. 5:245-256. www.geosci-model-dev.net/5/245/2012/ (PDF download)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#color-theory",
    "href": "slides/week5.2-colors-slides.html#color-theory",
    "title": "EDS 240",
    "section": "",
    "text": "Want to design your own palette? Here are some helpful guidelines and considerations…"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#select-hue",
    "href": "slides/week5.2-colors-slides.html#select-hue",
    "title": "EDS 240",
    "section": "",
    "text": "Select hues using color wheels / pickers\n\n\n\n\n\n\n\n\nThere are lots of different variations of color wheels, but look for hues along the outer edge:\n\n\n\n\n\n\n\n\n\n\n\n \n\nCommon color models: RYB (used by painters), RGB (used in electonic displays), CMYK (used in modern printing). Image source: medium.com\n\n\n\nWhen using a color picker, adjust the HEX code sliding scale to pick a hue and ensure that the selector is set to the far right edge of the box:\n\n\n\n\n\n\n\n\n\n\n\nThere are lots of great color pickers out there, though Google color picker is a quick one to navigate to. HTML color codes is my personal favorite.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRGB: basis for all colors on the screen (with these primary colors, we can make all other colors digitally)\nRYB: known as painting color system (used by artists in painting)\nCMYK: used on modern printing"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#colors-harmonies1",
    "href": "slides/week5.2-colors-slides.html#colors-harmonies1",
    "title": "EDS 240",
    "section": "",
    "text": "Use color wheels identify color harmonies\n\n\n\n\n\n\n\n\n\n\n\nImage source: htmlcolorcodes.com\n\n\n\n\n\n\n\nblue-green & red-orange are complementary and therefore offer the strongest possible contrast\n\n\nFind descriptions of blue-green & red-orange on htmlcolorcodes.com"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#hue-meaning",
    "href": "slides/week5.2-colors-slides.html#hue-meaning",
    "title": "EDS 240",
    "section": "",
    "text": "Hues have associated meaning\n\n\nWe associate meaning with different hues (e.g. cold / sad = blue, hot / angry = red), and importantly, these associations can differ among cultures.\n\n\n\nSource: Information is Beautiful"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#multicultural-colors",
    "href": "slides/week5.2-colors-slides.html#multicultural-colors",
    "title": "EDS 240",
    "section": "",
    "text": "Some associations span multiple cultures\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nSource: Information is Beautiful\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Ed Hawkins (showyourstripes.info)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#emotional-response-bake-off",
    "href": "slides/week5.2-colors-slides.html#emotional-response-bake-off",
    "title": "EDS 240",
    "section": "",
    "text": "Colors elicit emotional responses\n\n“lightness, brightness, and saturation can communicate the level of seriousness, intensity, and emotional weight in a visual work” (Cédric Scherer)\n\n\n\n\n\n\n\n\n\n\n\n\nThe Great British Bake Off | Race to the Top, by Cara Thompson (source code)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe LEGO Color Explosion, by Cédric Scherer (source code)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#emotional-response-covid-cases",
    "href": "slides/week5.2-colors-slides.html#emotional-response-covid-cases",
    "title": "EDS 240",
    "section": "",
    "text": "Colors elicit emotional responses\n\n“lightness, brightness, and saturation can communicate the level of seriousness, intensity, and emotional weight in a visual work” (Cédric Scherer)\n\n\n\n(Right) COVID-19 tracker by the Johns Hopkins University (screenshot from 2020-07-27, courtesy of Cédric Scherer). Red tends to elicit panic / fear. (Left) A map of confirmed COVID-19 cases by Datawrapper (screenshot from 2020-07-27, courtesy of Cédric Scherer). Blues and greens help to avoid such a strong fearful emotional response."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#emotional-response-covid-deaths",
    "href": "slides/week5.2-colors-slides.html#emotional-response-covid-deaths",
    "title": "EDS 240",
    "section": "",
    "text": "Colors elicit emotional responses\n\n \n\n\n“We show the current or confirmed cases in another color than red. The coronavirus is not a death sentence. Most infected people will survive. If you’re infected, you want to find yourself on a map as a blue (or yellow, or beige, or purple…) dot, not as a “attention, danger, run!”-screaming red dot. Related, we show deaths in black, not red – it feels more respectful.”\n\n\n\n-Lisa Charlotte Muth in 17 (or so) responsible live visualizations about the coronavirus, for you to use,\npublished March 3, 2020"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#avoid-pure-hue",
    "href": "slides/week5.2-colors-slides.html#avoid-pure-hue",
    "title": "EDS 240",
    "section": "",
    "text": "Using pure hues can be overwhelming\n\nThough it may be temping to use bright / bold colors to grab attention, it can lead to eye strain and make it more challenging for your readers to focus on your chart.\n\n\nImage source: 5 pitfalls to avoid when working with color in data visualization"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#more-subdued",
    "href": "slides/week5.2-colors-slides.html#more-subdued",
    "title": "EDS 240",
    "section": "",
    "text": "Use more subdued colors instead\n\nThough it may be temping to use bright / bold colors to grab attention, it can lead to eye strain and make it more challenging for your readers to focus on your chart.\n\n\nImage source: 5 pitfalls to avoid when working with color in data visualization"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#adjust-sat1",
    "href": "slides/week5.2-colors-slides.html#adjust-sat1",
    "title": "EDS 240",
    "section": "",
    "text": "A few approaches for subduing a pure hue\n\n1. adjust the saturation (i.e. the level of intensity of a color)\n2. adjust value: tint (add white), tone (add gray), or shade (add black)\n3. increase transparency (e.g. using the alpha argument)\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) at 100% saturation\n\n\n\n\n\n\n\n\n\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) at 40% saturation\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaturation adjusted using the HSL (Hue, Saturation, Lightness) color model. Read about HSL vs HSV color models if you want a deeper dive."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#adjust-sat2",
    "href": "slides/week5.2-colors-slides.html#adjust-sat2",
    "title": "EDS 240",
    "section": "",
    "text": "A few approaches for subduing a pure hue\n\n1. adjust the saturation (i.e. the level of intensity of a color)\n2. adjust value: tint (add white), tone (add gray), or shade (add black)\n3. increase transparency (e.g. using the alpha argument)\n\n\n\nThe default chroma for ggplots is set to 100%\n\n\nggplot(na.omit(penguins), aes(x = species, fill = sex)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nUse scale_*_hue() to adjust chroma (saturation)\n\n\nggplot(na.omit(penguins), aes(x = species, fill = sex)) +\n  geom_bar() +\n  scale_fill_hue(c = 70)\n\n\n\n\n\n\n\n\n\n\n\nscale_*_hue() uses colors based on the HCL color model."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#adjust-lightness1",
    "href": "slides/week5.2-colors-slides.html#adjust-lightness1",
    "title": "EDS 240",
    "section": "",
    "text": "A few approaches for subduing a pure hue\n\n1. adjust the saturation (i.e. the level of intensity of a color)\n2. adjust value: tint (add white), tone (add gray), or shade (add black)\n3. increase transparency (e.g. using the alpha argument)\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) with lightness adjusted to 90% (more white)\n\n\n\n\n\n\n\n\n\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) with lightness adjusted to 10% (more black)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLightness adjusted using the HSL (Hue, Saturation, Lightness) color model. Read about HSL vs HSV color models if you want a deeper dive."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#adjust-lightness2",
    "href": "slides/week5.2-colors-slides.html#adjust-lightness2",
    "title": "EDS 240",
    "section": "",
    "text": "A few approaches for subduing a pure hue\n\n1. adjust the saturation (i.e. the level of intensity of a color)\n2. adjust value: tint (add white), tone (add gray), or shade (add black)\n3. increase transparency (e.g. using the alpha argument)\n\n\n\nThe default lightness for ggplots is set to 65%\n\n\nggplot(na.omit(penguins), aes(x = bill_length_mm, y = bill_depth_mm, color = sex)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nUse scale_*_hue() to adjust lightness / darkness\n\n\nggplot(na.omit(penguins), aes(x = bill_length_mm, y = bill_depth_mm, color = sex)) +\n  geom_point() +\n  scale_color_hue(l = 45)\n\n\n\n\n\n\n\n\n\n\n\nscale_*_hue() uses colors based on the HCL color space. The default lightness value of 65(%) is good for filled areas but may be a bit light for points and lines."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#adjust-opacity",
    "href": "slides/week5.2-colors-slides.html#adjust-opacity",
    "title": "EDS 240",
    "section": "",
    "text": "A few approaches for subduing a pure hue\n\n1. adjust the saturation (i.e. the level of intensity of a color)\n2. adjust value: tint (add white), tone (add gray), or shade (add black)\n3. increase transparency (e.g. using the alpha argument)\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) with default opacity (100%)\n\n\n\n\n\n\n\n\nGreen (HEX #00FF33 / 132° on the color wheel) with opacity reduced to 50%"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#build-palettes",
    "href": "slides/week5.2-colors-slides.html#build-palettes",
    "title": "EDS 240",
    "section": "",
    "text": "Building your own color palette\n\nBe sure to consider what we’ve already discussed:\n\nensure that you’re picking colorblind-friendly color combos\nuse color wheels to identify color harmonies\nthink carefully about what emotions / messages your color choices will convey\navoid lots of pure / fully-saturated hues\n\n\n\n\n And also consider some other important sources of inspiration:\n\nyour company or organization’s brand / logo\nsteal colors from your favorite / relevant images using tools like Color Thief\nuse a randomized palette generator, like coolers.co"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#apply-palettes",
    "href": "slides/week5.2-colors-slides.html#apply-palettes",
    "title": "EDS 240",
    "section": "",
    "text": "Some common functions for scaling colors\n\nFor qualitative (categorical) data  :\n\nscale_*_manual()\n\nFor quantitative (numeric) data:\nUnclassed palettes  :\n\nscale_*_gradient(): creates a two color gradient (low-high)\nscale_*_gradient2(): creates a diverging color gradient (low-mid-high)\nscale_*_gradientn(): creates a n-color gradient\n\nClassed palettes  :\n\nscale_*steps(): creates a two color binned gradient (low-high)\nscale_*_steps2(): creates a diverging binned color gradient (low-mid-high)\nscale_*_stepsn(): creates a n-color binned gradient\n\n\nUse the fill variant of the above functions for areas, bars, etc. and the color variant for points, lines, etc."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#save-palette",
    "href": "slides/week5.2-colors-slides.html#save-palette",
    "title": "EDS 240",
    "section": "",
    "text": "Tip: Save your palette outside of your ggplot\n\nI recommend saving your palette to a named vector outside of your ggplot – this prevents lengthy palettes from creating cluttered ggplot code and allows you to reuse your palette across multiple plots:\n\nmy_palette &lt;- c(\"#32DE8A\", \"#E36414\", \"#0F4C5C\")\n\nHere, we scale our colors for a categorical variable (species) using scale_color_manual():\n\ncat_color_plot +\n  scale_color_manual(values = my_palette)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#set-color-names1",
    "href": "slides/week5.2-colors-slides.html#set-color-names1",
    "title": "EDS 240",
    "section": "",
    "text": "Tip: Set color names (1/2)\n\nWe should always be consistent with our colors. E.g. if Gentoo penguins are blue in one plot, they should be blue in all plots. Notice that our colors don’t “stick” with the species they represent, but rather they’re applied in the order that they appear in our palette:\n\nmy_palette &lt;- c(\"#32DE8A\", \"#E36414\", \"#0F4C5C\")\n\n\n\n\nAdelie, Chinstrap & Gentoo penguins\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_manual(values = my_palette)\n\n\n\n\n\n\n\n\n\n\nJust Adelie & Gentoo penguins\n\n\npenguins |&gt; \n  filter(species != \"Chinstrap\") |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_manual(values = my_palette)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#set-color-names2",
    "href": "slides/week5.2-colors-slides.html#set-color-names2",
    "title": "EDS 240",
    "section": "",
    "text": "Tip: Set color names (2/2)\n\nSetting the names of our vector elements (colors) ensures that they stick with those factor levels across all of our visualizations:\n\nmy_palette_named &lt;- c(\"Adelie\" = \"#32DE8A\",\"Chinstrap\" = \"#E36414\", \"Gentoo\" = \"#0F4C5C\")\n\n\n\n\nAdelie, Chinstrap & Gentoo penguins\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_manual(values = my_palette_named)\n\n\n\n\n\n\n\n\n\n\nJust Adelie & Gentoo penguins\n\n\npenguins |&gt; \n  filter(species != \"Chinstrap\") |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_manual(values = my_palette_named)"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#modify-df",
    "href": "slides/week5.2-colors-slides.html#modify-df",
    "title": "EDS 240",
    "section": "",
    "text": "Tip: modify df to apply colors to observations\n\nThe scale_*_identity() functions allows you to map aesthetic values from your data frame to individual points. They will not produce a legend unless specified using guide = \"legend\".\n\n\n\npenguins |&gt; \n  mutate(\n    my_color = case_when(\n      bill_length_mm &lt; 40 ~ \"#D7263D\",\n      between(bill_length_mm, 40, 50) ~ \"#E4BB97\",\n      bill_length_mm &gt; 50 ~ \"#386150\"\n    )\n  ) |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = my_color)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_identity()\n\n\n\n\n\n\n\n\n\n\npenguins |&gt; \n  mutate(\n    my_color = case_when(\n      body_mass_g &gt; 6000 ~ \"#D7263D\",\n      TRUE ~ \"gray50\"\n    )\n  ) |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = my_color)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_identity(guide = \"legend\", \n                       name = \"Body mass (g)\", labels = c(\"&gt;6000\", \"&lt;= 6000\"))\n\n\n\n\n\n\n\n\n\n\n\nThis isn’t the only way to do this! Try creating a highlight variable in your data frame. See https://andrewirwin.github.io/data-visualization/colour.html#highlighting and"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#create-palette",
    "href": "slides/week5.2-colors-slides.html#create-palette",
    "title": "EDS 240",
    "section": "",
    "text": "Create your own palettes!\n\nCreate your own palettes and use them to scale colors in the plots below:\n\n\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point(size = 4, alpha = 0.8) \n\n\n\n\n\n\n\n\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = body_mass_g)) +\n  geom_point(size = 4, alpha = 0.8) \n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#general-rules",
    "href": "slides/week5.2-colors-slides.html#general-rules",
    "title": "EDS 240",
    "section": "",
    "text": "There are also some additional rules / guidelines that you should pretty much always abide by when selecting colors"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#saturation",
    "href": "slides/week5.2-colors-slides.html#saturation",
    "title": "EDS 240",
    "section": "",
    "text": "High saturation = greater / more important values\n\n\n\nIt’s okay to use saturated / brighter colors in moderation.\nWe tend to associate more saturated colors with greater values.\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage source: New York Times\n\n\n\n\n\n\n\n\n\n\n\n\nImage source: {ggdensity} pkgdown site."
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#no-more-than-7",
    "href": "slides/week5.2-colors-slides.html#no-more-than-7",
    "title": "EDS 240",
    "section": "",
    "text": "No more than 7 colors\n\n\nIf you need more than seven colors, consider alternative chart types.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#consistency",
    "href": "slides/week5.2-colors-slides.html#consistency",
    "title": "EDS 240",
    "section": "",
    "text": "Use colors consistently\n\n\nEnsure consistent use of colors across multiple visualizations that display the same groups.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#legend",
    "href": "slides/week5.2-colors-slides.html#legend",
    "title": "EDS 240",
    "section": "",
    "text": "Explain what your colors encode\n\n\nAlways include a color key, in the form of a traditional legend or otherwise.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#highlight",
    "href": "slides/week5.2-colors-slides.html#highlight",
    "title": "EDS 240",
    "section": "",
    "text": "Highlight important values\n\n\nUse gray for less important groups / values, annotations, contextual information, etc.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#intuitive-colors",
    "href": "slides/week5.2-colors-slides.html#intuitive-colors",
    "title": "EDS 240",
    "section": "",
    "text": "Be predictable in your color choices\n\n\nUse intuitive colors (e.g. green for forest, blue for water) but avoid stereotypes (e.g. pink for women, blue for men).\n\n\n\n\n\nTry a cold color for men (e.g. blue or purple) and a warmer color for women (e.g. yellow, orange or a warm green).\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#gradient-low-high",
    "href": "slides/week5.2-colors-slides.html#gradient-low-high",
    "title": "EDS 240",
    "section": "",
    "text": "Bright = low, dark = high\n\n\nIn most cases, readers will associate bright colors with lower values and darker colors with higher values. Build gradients accordingly.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#gradient-high-low",
    "href": "slides/week5.2-colors-slides.html#gradient-high-low",
    "title": "EDS 240",
    "section": "",
    "text": "Except in some cases. . .\n\n\n“humans perceive bright colors on elevation maps to represent a high altitude, with darker colors representing naturally low-lying and shady areas like valley” (Cédric Scherer, Colors and Emotions in Data Visualization)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilled contour plot of Mt. Shasta. Image source: EarthLab\n\n\n\n\n\n\n\n\n\n\n\n\nUSGS Digital Elevation Model of Pohnpei (Micronesia). Image source: PacIOOS"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#gradients-continuous",
    "href": "slides/week5.2-colors-slides.html#gradients-continuous",
    "title": "EDS 240",
    "section": "",
    "text": "Gradient palettes for continuous data only\n\n\nMost readers will associate dark colors with “high / important” and bright or light colors with “low / less”. Using a gradient palette with categorical data may imply a ranking of categories where there shouldn’t be.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#lightness-gradient",
    "href": "slides/week5.2-colors-slides.html#lightness-gradient",
    "title": "EDS 240",
    "section": "",
    "text": "Use lightness, not just hue, to build gradients\n\n\nGradients should also work in black and white.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#two-hues",
    "href": "slides/week5.2-colors-slides.html#two-hues",
    "title": "EDS 240",
    "section": "",
    "text": "Two hues are sometimes better than one\n\n\nReaders are generally better able to distinguish colors on a gradient better if they are encoded through both lightness and two (sometimes three) carefully-selected hues.\n\n\n\n\n\nExample from What to consider when choosing colors for data visualization, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week5.2-colors-slides.html#break",
    "href": "slides/week5.2-colors-slides.html#break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 2 (of 3) – A coding exercise is up next! ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#title-slide",
    "href": "slides/week6.1-typography-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 6.1\nTypography\n\nWeek 6 | February 12th, 2024"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#good-design",
    "href": "slides/week6.1-typography-slides.html#good-design",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)\n\n\nThis lesson will focus on the use of typefaces and fonts in a good data visualization."
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#typeography",
    "href": "slides/week6.1-typography-slides.html#typeography",
    "title": "EDS 240",
    "section": "",
    "text": "Type and font choice influences audience perception and readability"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#typography-defs",
    "href": "slides/week6.1-typography-slides.html#typography-defs",
    "title": "EDS 240",
    "section": "",
    "text": "Typeface vs. font\n\n\n\nTypeface (aka font family): underlying visual design (e.g. Times New Roman, Helvetica, Roboto)\n\n\n\n\n\n\n\n\n\n\nFont: an implementation of a typeface; they can come in different weights and styles (e.g. bold, italic)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou choose a typeface (e.g. Nunito)\n\nYou use a font (e.g. regular, italic, bold)"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#typography-importance",
    "href": "slides/week6.1-typography-slides.html#typography-importance",
    "title": "EDS 240",
    "section": "",
    "text": "Typeface choices affect emotions and perceptions\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n“Typography is the art and technique of arranging type to make written language legible, readable and appealing when displayed.”\n\n\n-Wikipedia\n\n\nSimilar to colors, typefaces / fonts influence the how viewers perceive information (check out this short TEDx talk).\n\n Source: The Daily Egg\n\n\n\nWant to dive deeper into the world of typography? Start with this quick read, Why care about typography? and explore other great articles by Google Fonts."
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#font-psychology",
    "href": "slides/week6.1-typography-slides.html#font-psychology",
    "title": "EDS 240",
    "section": "",
    "text": "Context matters - choose typeface accordingly\n\nTypefaces and fonts communicate beyond more than just the written text – they can evoke emotions and can be used to better connect your audience with your work.\n\n\n\nSource: Typography for a better user experience, by Suvo Ray\n\n\n\nInterested in font pyschology? Check out this short video and this article to learn a bit more."
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#sans-serifs",
    "href": "slides/week6.1-typography-slides.html#sans-serifs",
    "title": "EDS 240",
    "section": "",
    "text": "When in doubt, use sans-serif fonts\n\nSerif fonts have small decorative lines (aka “tails” or “feet”) that extend off characters while sans serif fonts don’t.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSans-serif fonts = cleaner and easier to read.\n\nRoboto, Lato, Open Sans are good, free options\n\nSerif fonts = classy / traditional / professional / serious tone; typically only used for visualization headlines\n\nIf your organization uses a serif font, consider using it in your visualization’s headline\n\n\n\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#lining",
    "href": "slides/week6.1-typography-slides.html#lining",
    "title": "EDS 240",
    "section": "",
    "text": "Use a typeface with lining figures for numerals\n\nDifferent typefaces display numbers differently. Serif fonts tend to have “oldstyle figures”, which extend above and below the “line” – these can be difficult to read in a visualization.\nInstead, look for options with lining figures, where numbers “line up”, i.e. they’re all the same height.\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#monospaced",
    "href": "slides/week6.1-typography-slides.html#monospaced",
    "title": "EDS 240",
    "section": "",
    "text": "Use a monospaced typeface for numerals\n\n\nTypefaces with tabular figures print every character with equal width – you may see these referred to as monospaced typefaces. These work well in tables, visualizations, or any scenario where figures should line up vertically (see how you can quickly identify how many figures a number has in the table on the right, below).\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples from Which fonts to use for your charts and tables, by Lisa Charlotte Muth & Understanding numerals article by Google Fonts"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#symbols",
    "href": "slides/week6.1-typography-slides.html#symbols",
    "title": "EDS 240",
    "section": "",
    "text": "Use a typeface with all the symbols you need\n\n\nConfirm that all symbols (aka glyphs) that you need exist and that they look good for your chosen typeface.\n\n\n\nConsider special characters for different languages, currency symbols, math symbols, reference marks, sub / superscript numbers, etc.\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#bold",
    "href": "slides/week6.1-typography-slides.html#bold",
    "title": "EDS 240",
    "section": "",
    "text": "Use bold fonts for emphasis only\n\nMost typefaces come with fonts for different weights (Google Fonts uses numbers for font weights – extra light (200), light (300), regular (400, default), medium (500), semi bold (600), bold (700), extra bold (800)).\nUse bold text for titles or to emphasize a few words in annotations. Regular or medium weights are often easiest for longer text (descriptions, annotations, notes).\n\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#thin",
    "href": "slides/week6.1-typography-slides.html#thin",
    "title": "EDS 240",
    "section": "",
    "text": "Avoid really thin fonts\n\nThin (light-weight fonts) fonts are hard to read. Only use them in a high-contrast color and in large sizes (often, titles are the only place you’ll want to use think fonts.)\n\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#large-font-size",
    "href": "slides/week6.1-typography-slides.html#large-font-size",
    "title": "EDS 240",
    "section": "",
    "text": "Ensure your font size is large enough\n\nMake sure your font size is large enough, especially when presenting visualizations in a slide-based presentation (this oftentimes means increasing it larger than you would have it in print). In ggplot, adjust font sizes using theme().\n\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#contrast",
    "href": "slides/week6.1-typography-slides.html#contrast",
    "title": "EDS 240",
    "section": "",
    "text": "Use high-contrast color for most text\n\nWeb Content Accessibility Guidelines (WCAG) recommends a minimum contrast ratio of 4.5:1 – use a color contrast checker to check your ratio. This particular color contrast checker will enhance poor color combinations to meet WCAG guidelines. For example, here is a color combo with a bad contrast ratio, and here is the updated color combo with an improved contrast ratio.\n\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#uppercase",
    "href": "slides/week6.1-typography-slides.html#uppercase",
    "title": "EDS 240",
    "section": "",
    "text": "Use UPPERCASE text sparingly\n\nUppercase text is more difficult to read compared to sentence case – limit use to headlines or labels. Region labels on maps are commonly uppercase (e.g. see maps in these New York Times pieces, How to Think About Ukraine, in Maps and Charts and Closing the Back Door to Europe).\n\n\n\nExample from Which fonts to use for your charts and tables, by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#typographic-hierarchy",
    "href": "slides/week6.1-typography-slides.html#typographic-hierarchy",
    "title": "EDS 240",
    "section": "",
    "text": "Typographic hierarchy\n\nNo one wants to read a wall of text. You can use font size, style, color, spacing, and typeface (or combinations of these) to create a hierarchy that guide your readers.\n\n\n\n\nSource: The UX Designer’s Guide to Typography"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#recap-font-choices",
    "href": "slides/week6.1-typography-slides.html#recap-font-choices",
    "title": "EDS 240",
    "section": "",
    "text": "Recap: choosing the right typeface(s) & font(s)\n\n\n\ncontext matters – the type(s) should fit the topic and audience\nwhen in doubt, use a sans-serif style\nchoose a monospaced typeface with lining figures for numbers\nensure that your chosen typeface has all the symbols you need and that they look okay\nuse bold fonts for emphasis and avoid thin fonts\nmake font sizes large enough to easily read\nuse high-contrast font colors\nstrategically use types & fonts to create hierarchy\navoid (extensively) using ALL CAPS\n\n\n\n\nAvoid using too many typefaces (stick to just 1-3)\n\n\nCheck out fontpair.co to explore aesthetically-pleasing font pairings!\n\n\n\n\nThere are lots of excellent resources out there for choosing the right typeface / font check out the resources page on the course website for some recommendations."
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#nicault-horror",
    "href": "slides/week6.1-typography-slides.html#nicault-horror",
    "title": "EDS 240",
    "section": "",
    "text": "Horror Movies, by Cristophe Nicault (source code)\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#anyene-hbcu",
    "href": "slides/week6.1-typography-slides.html#anyene-hbcu",
    "title": "EDS 240",
    "section": "",
    "text": "HBCUs, by Ijeamaka Anyene (source code)\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#rennie-rladies",
    "href": "slides/week6.1-typography-slides.html#rennie-rladies",
    "title": "EDS 240",
    "section": "",
    "text": "R-Ladies Chapter Events, by Nicola Rennie (source code) | Font inspired by R-Ladies Global\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#change-fonts",
    "href": "slides/week6.1-typography-slides.html#change-fonts",
    "title": "EDS 240",
    "section": "",
    "text": "Let’s learn how to use different fonts in our ggplots!"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#sys-fonts1",
    "href": "slides/week6.1-typography-slides.html#sys-fonts1",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with system fonts\n\nA system font is one that’s already assumed to be on the vast majority of users’ devices, with no need for a web font to be downloaded.\n\nThere are only three system fonts that are guaranteed to work everywhere: sans (the default), serif, or mono. Use the family argument to specify which font family you’d like to use for a particular text element, and use the face argument to specify font face (bold, italic, plain (default)):\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point() + \n  labs(title = \"This title is serif font\",\n       subtitle = \"This subtitle is mono font\",\n       x = \"This axis label is sans font (default)\",\n       y = \"This axis is also sans font (default)\") +\n  theme(\n    plot.title = element_text(family = \"serif\", size = 30),\n    plot.subtitle = element_text(family = \"mono\", size = 25),\n    axis.title = element_text(family = \"sans\", size = 22),\n    axis.text.x = element_text(family = \"serif\", face = \"bold\", size = 18),\n    axis.text.y = element_text(family = \"mono\", face = \"italic\", size = 18)\n    )"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#sys-fonts2",
    "href": "slides/week6.1-typography-slides.html#sys-fonts2",
    "title": "EDS 240",
    "section": "",
    "text": "The problem with system fonts\n\nA graphics device (GD) is something used to make a plot appear – everytime you create a plot in R, it needs to be sent to a specific GD to be rendered. There are two main device types:\n\n\n\nscreen devices: the most common place for your plot to be “sent” – whenever our plot appears in a window on our computer screen, it’s being sent to a screen device; different operating systems (e.g. Mac, Windows, Linux) have different screen devices\nfile devices: if we want to write (i.e. save) our plot to a file, we can send our plot to a particular file device (e.g. pdf, png, jpeg)\n\n\n\n\nUnfortunately, text drawing is handled differently by each graphics device, which means that if we want a font to work everywhere, we need to configure all these different devices in different ways.\n\nRead a bit more about graphics devices in Chapter 8 of Exploratory Data Analysis with R, by Roger Peng"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#font-pkgs",
    "href": "slides/week6.1-typography-slides.html#font-pkgs",
    "title": "EDS 240",
    "section": "",
    "text": "R packages to the rescue!\n\nFortunately, there are a couple super handy packages that make working with fonts relatively painless:\n\n{showtext}\n{extrafont}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll be using {showtext} for a couple reasons: it supports more file formats and more graphics devices, and it also avoids using external software ({extrafont} requires that you install some additional software and packages first). {showtext} makes is super easy to import and use Google Fonts.\n\nAlbert Rapp and Nicola Rennie both have written great blog posts on using {showtext}. These materials draw from both their work!\n\n\n\n\nre: opening a new GD, windows() after showtext_auto() https://gradientdescending.com/adding-custom-fonts-to-ggplot-in-r/"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#original-salary-plot",
    "href": "slides/week6.1-typography-slides.html#original-salary-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Recall our dumbbell plot from week 4\n\nLet’s improve this plot by updating the colors, modifying the theme, and using some new fonts!"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#wrangle-data",
    "href": "slides/week6.1-typography-slides.html#wrangle-data",
    "title": "EDS 240",
    "section": "",
    "text": "Wrangle data\n\nThis code should look familiar (copied from Lecture 4.1):\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\njobs &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv\")\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                wrangle data                              ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\njobs_clean &lt;- jobs |&gt;\n\n  # add cols (needed for dumbbell plot) ----\n  mutate(percent_male = 100 - percent_female, # % of females within each industry was already included\n       difference_earnings = total_earnings_male - total_earnings_female) |&gt;  # diff in earnings between M & F\n\n  # rearrange columns ----\n  relocate(year, major_category, minor_category, occupation,\n           total_workers, workers_male, workers_female,\n           percent_male, percent_female,\n           total_earnings, total_earnings_male, total_earnings_female, difference_earnings,\n           wage_percent_of_male) |&gt;\n\n  # drop rows with missing earning data ----\n  drop_na(total_earnings_male, total_earnings_female) |&gt;\n\n  # make occupation a factor ----\n  mutate(occupation = as.factor(occupation)) |&gt;\n\n# ---- this next step is for creating our dumbbell plots ----\n\n# classify jobs by percentage male or female ----\n  mutate(group_label = case_when(\n    percent_female &gt;= 75 ~ \"Occupations that are 75%+ female\",\n    percent_female &gt;= 45 & percent_female &lt;= 55 ~ \"Occupations that are 45-55% female\",\n    percent_male &gt;= 75 ~ \"Occupations that are 75%+ male\"\n  ))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                              create subset df                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#....guarantee the same random samples each time we run code.....\nset.seed(0)\n\n#.........get 10 random jobs that are 75%+ female (2016).........\nf75 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 75%+ female\") |&gt;\n  slice_sample(n = 10)\n\n#..........get 10 random jobs that are 75%+ male (2016)..........\nm75 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 75%+ male\") |&gt;\n  slice_sample(n = 10)\n\n#........get 10 random jobs that are 45-55%+ female (2016).......\nf50 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 45-55% female\") |&gt;\n  slice_sample(n = 10)\n\n#.......combine dfs & relevel factors (for plotting order).......\nsubset_jobs &lt;- rbind(f75, m75, f50) |&gt;\n  mutate(group_label = fct_relevel(group_label, \n                                   \"Occupations that are 75%+ female\",\n                                   \"Occupations that are 45-55% female\", \n                                   \"Occupations that are 75%+ male\"))"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#original-plot-code",
    "href": "slides/week6.1-typography-slides.html#original-plot-code",
    "title": "EDS 240",
    "section": "",
    "text": "Code for our original plot\n\nThis code was copied from Lecture 4.1. Resulting plot is rendered on the next slide!\n\n\nplot &lt;- ggplot(subset_jobs) +\n  geom_segment(aes(x = total_earnings_female, xend = total_earnings_male,\n                 y = fct_reorder(occupation, total_earnings), yend = occupation)) +\n  geom_point(aes(x = total_earnings_male, y = occupation),\n             color = \"#CD93D8\", size = 3.25) +\n  geom_point(aes(x = total_earnings_female, y = occupation),\n             color = \"#6A1E99\", size = 3.25) +\n  facet_wrap(~group_label, nrow = 3, scales = \"free_y\") +\n  scale_x_continuous(labels = scales::label_dollar(scale = 0.001, suffix = \"k\"),\n                     breaks = c(25000, 50000, 75000, 100000, 125000))\n\nplot"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#create-palette",
    "href": "slides/week6.1-typography-slides.html#create-palette",
    "title": "EDS 240",
    "section": "",
    "text": "Create a better (named) palette\n\nIn last week’s lecture on colors, we learned to be predictable in our color choices, but to avoid stereotypes (Muth 2018). It can be helpful for readers to choose a cool color for men (e.g. blues / purples) and warmer color for women (e.g. yellows, oranges, warm greens).\nWe’ll do that here, but this time, let’s create a named vector of colors to call from. In addition to our point colors, we’ll also include colors for our plot’s text:\n\nearnings_pal &lt;- c(\"males\" = \"#2D7787\",\n                  \"females\" = \"#FC6B4B\",\n                  dark_text = \"#0C1509\",\n                  light_text = \"#4E514D\") \n\nThe primary purpose of the {monochromeR} package is for creating monochrome colour palettes, however, it also includes a helpful function for viewing our palette:\n\nmonochromeR::view_palette(earnings_pal)"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#apply-colors",
    "href": "slides/week6.1-typography-slides.html#apply-colors",
    "title": "EDS 240",
    "section": "",
    "text": "Apply new colors by name\n\n\nplot &lt;- ggplot(subset_jobs) +\ngeom_segment(aes(x = total_earnings_female, xend = total_earnings_male,\n                 y = fct_reorder(occupation, total_earnings), yend = occupation)) +\n  geom_point(aes(x = total_earnings_male, y = occupation),\n             color = earnings_pal[\"males\"], size = 3.25) +\n  geom_point(aes(x = total_earnings_female, y = occupation),\n             color = earnings_pal[\"females\"], size = 3.25) +\n  facet_wrap(~group_label, nrow = 3, scales = \"free_y\") +\n  scale_x_continuous(labels = scales::label_dollar(scale = 0.001, suffix = \"k\"),\n                     breaks = c(25000, 50000, 75000, 100000, 125000))\n\nplot"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#titles-theme-code",
    "href": "slides/week6.1-typography-slides.html#titles-theme-code",
    "title": "EDS 240",
    "section": "",
    "text": "Add titles / caption & modify theme\n\nResulting plot is rendered on the next slide!\n\nplot +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = \"Median earnings of full-time male vs. female workers by occupation in 2016\",\n       caption = \"Data Source: TidyTuesday (March 5, 2019)\") +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(face = \"bold\",\n                              size = 25,\n                              color = earnings_pal[\"dark_text\"]),\n    plot.subtitle = element_text(size = 17,\n                                 color = earnings_pal[\"light_text\"],\n                                 margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = element_text(face = \"italic\",\n                                color = earnings_pal[\"light_text\"],\n                                margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(x = 1, \"lines\"),\n    axis.text = element_text(color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )\n\n\nNote: We can apply our font colors in the same way we applied our point colors, calling named values from our earnings_pal"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#pick-google-fonts",
    "href": "slides/week6.1-typography-slides.html#pick-google-fonts",
    "title": "EDS 240",
    "section": "",
    "text": "Pick a typeface(s) from Google Fonts\n\nBrowse typefaces and fonts at https://fonts.google.com/. It can be helpful to type your desired text into the Preview field (you may need to expand the sidebar by clicking the Filters button on the top left of the page) to get a better sense of how your font choice will look. You can also search typefaces by name:"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#our-typefaces",
    "href": "slides/week6.1-typography-slides.html#our-typefaces",
    "title": "EDS 240",
    "section": "",
    "text": "We’ll use these two typefaces:\n\n\n\n\n\nJosefin Sans\n\n\n\n\n\n\n\n\n\n\n\n\nSen"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#import-google-fonts",
    "href": "slides/week6.1-typography-slides.html#import-google-fonts",
    "title": "EDS 240",
    "section": "",
    "text": "Import Google Fonts\n\n\nImport {showtext} at the top of your script, then use font_add_google() to specify the font family(ies) you want to import. Importantly, you’ll also need to “turn on” showtext using showtext_auto() – this enables showtext font rendering for any newly opened graphics devices.\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(showtext)\n\n#..........................import fonts..........................\n# `name` is the name of the font as it appears in Google Fonts\n# `family` is the user-specified id that you'll use to apply a font in your ggpplot\nfont_add_google(name = \"Josefin Sans\", family = \"josefin\")\nfont_add_google(name = \"Sen\", family = \"sen\")\n\n#................enable {showtext} for rendering.................\nshowtext_auto()\n\n# ~ additional setup code omitted for brevity ~"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#apply-google-fonts-code",
    "href": "slides/week6.1-typography-slides.html#apply-google-fonts-code",
    "title": "EDS 240",
    "section": "",
    "text": "Apply Google Fonts (code)\n\nResulting plot is rendered on the next slide!\n\nplot +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = \"Median earnings of full-time male vs. female workers by occupation in 2016\",\n       caption = \"Data Source: TidyTuesday (March 5, 2019)\") +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(family = \"josefin\",\n                              face = \"bold\",\n                              size = 25,\n                              color = earnings_pal[\"dark_text\"]),\n    plot.subtitle = element_text(family = \"sen\",\n                                 size = 17,\n                                 color = earnings_pal[\"light_text\"],\n                                 margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = element_text(family = \"sen\",\n                                face = \"italic\", # NOTE: this no longer applies since the typeface \"Sen\" does not exist in an italic font style\n                                color = earnings_pal[\"light_text\"],\n                                margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(family = \"josefin\",\n                                face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(x = 1, \"lines\"),\n    axis.text = element_text(family = \"sen\",\n                             color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )\n\n\nNote: Our previously italicized caption is no longer, since Sen does not come in an italicized font style"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#import-fa-fonts",
    "href": "slides/week6.1-typography-slides.html#import-fa-fonts",
    "title": "EDS 240",
    "section": "",
    "text": "Import Font Awesome fonts\n\nFont Awesome is a library of icons, which can be imported and used similar to Google Fonts. You’ll need to download the font files first (see week 5 pre-class prep instructions). We can then use showtext::font_add() to make them available for use in our ggplots:\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(showtext)\n\n#......................import Google Fonts.......................\n# `name` is the name of the font as it appears in Google Fonts\n# `family` is the user-specified id that you'll use to apply a font in your ggpplot\nfont_add_google(name = \"Josefin Sans\", family = \"josefin\")\nfont_add_google(name = \"Sen\", family = \"sen\")\n\n#....................import Font Awesome fonts...................\nfont_add(family = \"fa-brands\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Brands-Regular-400.otf\"))\nfont_add(family = \"fa-regular\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Regular-400.otf\")) \nfont_add(family = \"fa-solid\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Solid-900.otf\"))\n\n#................enable {showtext} for rendering.................\nshowtext_auto()\n\n# ~ additional setup code omitted for brevity ~"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#fa-unicode",
    "href": "slides/week6.1-typography-slides.html#fa-unicode",
    "title": "EDS 240",
    "section": "",
    "text": "Reference icons by their Unicode\n\nLet’s say I want to include my GitHub username along with the GitHub icon in the caption of my plot. Start by searching the Free icons on Font Awesome and click on the one you want to use (here, the github icon). Find the icon’s Unicode in the top right corner of the popup box:"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#create-caption",
    "href": "slides/week6.1-typography-slides.html#create-caption",
    "title": "EDS 240",
    "section": "",
    "text": "Add an icon to our caption\n\nTo use this unicode in HTML, we need to stick a &#x ahead of it. We can make our lives a bit easier by saving our unicode (as well as our username text) to variable names. We’ll then use the glue::glue() function to construct our full caption. Importantly, glue() will evaluate expressions enclosed by braces as R code.\n\n\n#.........................create caption.........................\ngithub_icon &lt;- \"&#xf09b\"\ngithub_username &lt;- \"samanthacsik\"\n\ncaption &lt;- glue::glue(\n  \"Data Source: TidyTuesday (March 5, 2019) |\n  &lt;span style='font-family:fa-brands;'&gt;{github_icon};&lt;/span&gt;\n  {github_username}\"\n)\n\n\nNote that we (1) wrap our object names in {} to use the values that are saved to them, and (2), we use the HTML &lt;span&gt; tag to apply styles to text – here, we use the font-family property and supply it the value, fa-brands (which is the id (i.e. family) we created when loading the Font Awesome 6 Brands-Regular-400.otf file at the top of our script)."
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#create-subtitle",
    "href": "slides/week6.1-typography-slides.html#create-subtitle",
    "title": "EDS 240",
    "section": "",
    "text": "Let’s also add an icon to our subtitle\n\nWe can do this the same way that we constructed our caption – note that this money icon is from the fa-regular family (though you could choose to use the solid version as well):\n\n\n#........................create subtitle.........................\nmoney_icon &lt;- \"&#xf3d1\"\n\nsubtitle &lt;- glue::glue(\"Median earnings \n                       &lt;span style='font-family:fa-regular;'&gt;{money_icon};&lt;/span&gt;\n                       of full-time male versus female workers by occupation in 2016\")"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#update-plot-text",
    "href": "slides/week6.1-typography-slides.html#update-plot-text",
    "title": "EDS 240",
    "section": "",
    "text": "Apply our new subtitle & caption\n\nResulting plot is rendered on the next slide!\n\nplot +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = subtitle,\n       caption = caption) +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(family = \"josefin\",\n                              face = \"bold\",\n                              size = 25),\n    plot.subtitle = element_text(family = \"sen\",\n                                 size = 17,\n                                 color = earnings_pal[\"light_text\"],\n                                 margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = element_text(family = \"sen\",\n                                face = \"italic\", # NOTE: this no longer applies since the typeface \"sen\" does not exist in an italic font style\n                                color = earnings_pal[\"light_text\"],\n                                margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(family = \"josefin\",\n                                face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(1, \"lines\"),\n    axis.text = element_text(family = \"sen\",\n                             color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#ggplot-HTML-parsing",
    "href": "slides/week6.1-typography-slides.html#ggplot-HTML-parsing",
    "title": "EDS 240",
    "section": "",
    "text": "ggplot doesn’t (natively) know how to parse HTML\n\n\n. . . but the {ggtext} package does! If we want to render ggplot text using HTML or Markdown syntax, we also need to use one of {ggtext}’s theme() elements, which will parse and render the applied styles.\n\nThere are a few options, all which replace {ggplot2}’s element_text() – be sure to check out the documentation as you’re deciding which to use:\n\nelement_markdown()\nelement_textbox()\nelement_textbox_simple()"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#update-theme-elements-code",
    "href": "slides/week6.1-typography-slides.html#update-theme-elements-code",
    "title": "EDS 240",
    "section": "",
    "text": "Update theme() elements to render styling\n\n\nplot +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = subtitle,\n       caption = caption) +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(family = \"josefin\",\n                              face = \"bold\",\n                              size = 25),\n    plot.subtitle = ggtext::element_textbox_simple(family = \"sen\",\n                                                   size = 17,\n                                                   color = earnings_pal[\"light_text\"],\n                                                   margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = ggtext::element_textbox_simple(family = \"sen\",\n                                                  face = \"italic\", # NOTE: this no longer applies since the typeface \"sen\" does not exist in an italic font style\n                                                  color = earnings_pal[\"light_text\"],\n                                                  margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(family = \"josefin\",\n                                face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(1, \"lines\"),\n    axis.text = element_text(family = \"sen\",\n                             color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#text-legend",
    "href": "slides/week6.1-typography-slides.html#text-legend",
    "title": "EDS 240",
    "section": "",
    "text": "We also need to tell reader what our colors mean!\n\nTraditional legends are fine, but for this plot, we’ll opt to color-code our subtitle text (i.e. male & female) to match the points in our plot. We can again use the {ggtext} package to apply simple Markdown and HTML rendering to our ggplot text.\n\n\nWe already have the correct theme() elements added to our plot, but we do need to update our subtitle text with Markdown and HTML styling. Let’s bold, color, and make these words slightly larger than the surrounding text:\n\n\n#........................create subtitle.........................\nmoney_icon &lt;- \"&#xf3d1\"\n\nsubtitle &lt;- glue::glue(\"Median earnings &lt;span style='font-family:fa-regular;'&gt;{money_icon};&lt;/span&gt;\n                       of full-time\n                       &lt;span style='color:#2D7787;font-size:20pt;'&gt;**male**&lt;/span&gt;\n                       versus &lt;span style='color:#FC6B4B;font-size:20pt;'&gt;**female**&lt;/span&gt;\n                       workers by occupation in 2016\")\n\n\nNote: We combine both Markdown syntax (e.g. ** to bold text) and HTML syntax to apply in-line CSS styling (e.g. &lt;span style=...&gt;)):"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#before-after",
    "href": "slides/week6.1-typography-slides.html#before-after",
    "title": "EDS 240",
    "section": "",
    "text": "Before & after"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#text-size-resolution",
    "href": "slides/week6.1-typography-slides.html#text-size-resolution",
    "title": "EDS 240",
    "section": "",
    "text": "Saving your plots can be a bit tricky\n\nGetting your fonts / plots to look just right when writing to a file device can be a bit tricky. Check out Understanding text size and resolution in ggplot2, by Christophe Nicault to understand why and for solutions on how to fix / avoid this.\n\n\n\n\nA very obviously not great saved ggplot\n\n\n\n\n\n\n\n\n\n\n\n\nMuch better!"
  },
  {
    "objectID": "slides/week6.1-typography-slides.html#break",
    "href": "slides/week6.1-typography-slides.html#break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 2) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#title-slide",
    "href": "slides/week1.2-intro-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 1.2\nData visualization: an intro\n\nWeek 1 | January 8th, 2024"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#what-is-visualization1",
    "href": "slides/week1.2-intro-slides.html#what-is-visualization1",
    "title": "EDS 240",
    "section": "",
    "text": "What is data visualization?\n\n\n“…the practice of designing and creating easy-to-communicate and easy-to-understand graphic or visual representations of a large amount of complex quantitative and qualitative data and information with the help of static, dynamic or interactive visual items.”\n\n\n-from Wikipedia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreated using {ggplot2}\n\n\n\nCreated using {gganimate}\n\n\n\nCreated using {shiny}"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#what-is-visualization2",
    "href": "slides/week1.2-intro-slides.html#what-is-visualization2",
    "title": "EDS 240",
    "section": "",
    "text": "What is data visualization?\n\n \n\n“any graphical representation of information and data”\n\n\n-Cédric Scherer, Effective Data Visualization\n\n\n\n\n“part art and part science”\n\n\n-Claus O. Wilke, Fundamentals of Data Visualization"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history1",
    "href": "slides/week1.2-intro-slides.html#history1",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nLascaux Caves in the southwest of France; Pleiades star cluster (seven sisters) also found on the cave walls"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history2",
    "href": "slides/week1.2-intro-slides.html#history2",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nTurin Papyrus Map, generally considered the oldest surviving map of topographical interest in the ancient world; was prepared for Ramses IV’s quarrying expedition to the Wadi Hammamat; the expedition purpose was to obtain blocks of stone for building statues of the king"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history3",
    "href": "slides/week1.2-intro-slides.html#history3",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history4",
    "href": "slides/week1.2-intro-slides.html#history4",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nvan Langren was a dutch mathematician / astronomer; served as royal mathematician to King Phillip IV of Spain; worked on one of the most significant problems of his time (accurate determination of longitude between Toledo & Rome, particularly navigation by sea); graph shows all available estimates in distance (inaccuracies resulted in many shipwrecks)"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history5",
    "href": "slides/week1.2-intro-slides.html#history5",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history6",
    "href": "slides/week1.2-intro-slides.html#history6",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\nWillard map maker & founder of first school for women’s higher education in the US; Temple of Time uses the architecture as a metaphor for history; foreground = present; columns represent centuries; she believed that facts must be connected to one another to be meaningful and that they will they be most easily retained if presented visually"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history7",
    "href": "slides/week1.2-intro-slides.html#history7",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nNightingale was an English wartime nurse; campaigned to improve sanitary conditions of military hospitals; collected data and created data viz; used color to emphasize particular aspects; famous “polar-area” viz shows the causes of mortality in the military hospital &gt; deaths from preventable diseases (blue) outnumbered combat fatalities (red) in 1854 & early 1855; the changes she put in place greatly reduced those deaths by April 1855 (see here)"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history8",
    "href": "slides/week1.2-intro-slides.html#history8",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history9",
    "href": "slides/week1.2-intro-slides.html#history9",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nWEB DuBois was an African American writer, scholar and activist; first African American to earn a PhD from Harvard University; helped found the National Association for the Advancement of Colored People (NAACP)."
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history10",
    "href": "slides/week1.2-intro-slides.html#history10",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nTufte: statistician & professor emeritus at Yale; nobably famous for his books on information design; pioneer in the field of data viz; this book is a classic on statistical graphics"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#history11",
    "href": "slides/week1.2-intro-slides.html#history11",
    "title": "EDS 240",
    "section": "",
    "text": "History of data visualization\n\nNote: this is by no means a comprehensive history of the visual representation of information!\n\n\nImages from BBC News, Wikipedia (a, b, c, d), Smithsonian, The Marginalian, Scientific American & Twitter\n\n\n\nR is a programming language for statistical computing and graphics\nTableau is a interactive data visualization software\nD3.js is a JavaScript library for producing dynamic, interactive data visualizations in web browsers"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#why-visualize",
    "href": "slides/week1.2-intro-slides.html#why-visualize",
    "title": "EDS 240",
    "section": "",
    "text": "Why do we visualize data?\n\n\nSpend the next few minutes discussing with your Learning Partners, and if possible, pull up some example visualizations that demonstrate your thoughts / discussion points\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#answer-qs",
    "href": "slides/week1.2-intro-slides.html#answer-qs",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to answer questions / derive insights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRipple et al. 2023\n\nFig Caption: Unusual climate anomalies in 2023 (the red line, which appears bold in print). Sea ice extent (a, b), temperatures (c–e), and area burned in Canada (f) are presently far outside their historical ranges. These anomalies may be due to both climate change and other factors. Sources and additional details about each variable are provided in supplemental file S1. Each line corresponds to a different year, with darker gray representing later years.\n\n\nA nice Twitter thread on key takeaways from the above paper"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#exploration",
    "href": "slides/week1.2-intro-slides.html#exploration",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to explore & generate new questions\n\n\n“Exploratory data analysis (EDA) is not a formal process with a strict set of rules. More than anything, EDS is a state of mind…you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will hone in on a few particularly productive insights that you’ll eventually write-up and communicate to others.”\n\n\n-Hadley Wickham, author of R for Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#see-trends",
    "href": "slides/week1.2-intro-slides.html#see-trends",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to identify trends\n\n\nSame summary statistics, different distributions!\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnscombe’s Quartet\n(Anscombe 1973)\n\n\n\nDatasaurus Dozen\n(Matejka & Fitzmaurice 2017, expanding upon Albert Cairo’s Datasaurus)"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#prompt-discussion1",
    "href": "slides/week1.2-intro-slides.html#prompt-discussion1",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to prompt discussion\n\n\n\n\n\nWarming Strips, by Ed Hawkins"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#prompt-discussion2",
    "href": "slides/week1.2-intro-slides.html#prompt-discussion2",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to prompt discussion\n\n\n\n\n\ngif created from Antti Lipponen’s Temperature Anomolies."
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#prompt-discussion3",
    "href": "slides/week1.2-intro-slides.html#prompt-discussion3",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to prompt discussion\n\n\n\n\n\ngif created from Mark SubbaRao’s Climate Spiral. For a similar visualization with accompanying {ggplot2} code, see Nicola Rennie’s TidyTuesday contribution!"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#bremer-pathwork",
    "href": "slides/week1.2-intro-slides.html#bremer-pathwork",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to create art / tell a story\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatchwork Kingdoms, by Nadieh Bremer portraying the “digital divide” in schools across the world\n\n\n\na data & generative art charity collection for the Giga Connect project of UNICEF which aims to connect all of the schools in the world to the internet.\na dataset of 1 million schools and for ±280,000 of those they know if those schools are connected to the internet\ntook this data about the schools, split it into 1000 subsets, and turned each school into a tiny square\nupright kingdoms are schools that are already connected to the internet, while those in the hidden / upside down kingdoms are not. Each of the 1000 pieces is thereby showing the “digital divide” that still exists in our world, and the funds from this sale will help to bring more schools from the hidden to the upright kingdom."
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#astronauts",
    "href": "slides/week1.2-intro-slides.html#astronauts",
    "title": "EDS 240",
    "section": "",
    "text": ". . . to create art / tell a story\n\n\nTo enlarge, Right click &gt; Open Image in New Tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraveling to Outer Space, by Cédric Scherer\n\n\n\n\n\n\n\n\n\n\n\n\n\nGalaxy of Astronauts, by Ijeamaka Anyene\n\n\n\n\n\n\n\n\n\n\n\n\nAges Through Time and Space, by Cara Thompson\n\n\n\n\n\nFind the data on the TidyTuesday repo"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#vertices",
    "href": "slides/week1.2-intro-slides.html#vertices",
    "title": "EDS 240",
    "section": "",
    "text": "Vertices of Visualization\n\n\n\nVertices of Communication by Albert Cairo, as presented by Cédric Scherer during his 2022 Graphic Design with ggplot2 workshop (slides)"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#r-for-data-viz",
    "href": "slides/week1.2-intro-slides.html#r-for-data-viz",
    "title": "EDS 240",
    "section": "",
    "text": "Why R for data viz?\n\n\n\n   \n\n\nI’m most comfortable in R \ngreat ecosystem of data wrangling & visualization packages (inc. a massive and growing collection of {ggplot2} extensions)\namazing online learning communities\ndata viz fundamentals apply no matter the language / tool"
  },
  {
    "objectID": "slides/week1.2-intro-slides.html#end-break",
    "href": "slides/week1.2-intro-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 2 (of 3) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/random-notes.html",
    "href": "slides/random-notes.html",
    "title": "random things to find a place for",
    "section": "",
    "text": "plot data directly\ne.g. plot income and expenses as separate lines or just plot a singe net income line? (latter) plot your data directly, if difference matters more, plot the difference! (need environmental example here)\n\nSOME TIPS\n\nbaselines\nbreaking up plots when data vary so much that presenting them all on a single chart renders it useless (e.g. use fracking data?)\nordering variables / categories – e.g. see trends across age groups by grouping bars by media (see pg 139) (NEED EDS EXAMPLE HERE)\n\n\nuse logical & meaningful baselines\n\nbar, lollipops, histograms, etc should always have a 0 baseline – cannot truncate when main visual cue is height/length measured from a common baseline\nscatterplot, line graph, ec. – can be okay to truncate axes since main visual cue is position, not height/length"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#title-slide",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 3.1\nChoosing the right graphic form\n\nWeek 3 | January 22nd, 2024"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#viz-complex-nums",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#viz-complex-nums",
    "title": "EDS 240",
    "section": "",
    "text": "We understand complex numbers better when they’re represented visually\n\n\n“Exams will have a total of 137 points rather than the usual 100. This scoring system has no effect on the grade you get in the course, but it seems to make you happier”\n\n\n-Richard H. Thaler, economist & professor\n\n\nEarly years: exam graded 0 - 100 with an average score of 72 points = lots of complaints\nLater years: exam graded 0 - 137 with an average score of 96 points = very few complaints\n\n\n\n\n\n\n\n\n\n\n\n\nAlbert Cairo’s visualization of the scores from Thaler’s exam case study"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#vision-sense",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#vision-sense",
    "title": "EDS 240",
    "section": "",
    "text": "Vision is our most well-developed sense\n\n  \n\nMapping data into visual properties is powerful\n\n \n\n\nMapping?\nHow values of a variable(s) of interest are represented by visuals (e.g height of bar, shaded region of area plot, color of data points)"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#choose-graphic",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#choose-graphic",
    "title": "EDS 240",
    "section": "",
    "text": "How do you choose the right graphic form to represent your data?\n\n  \n\n\n“If I had the answer to that, I’d be rich by now…I have no idea, but I can give you some clues to make your own choices based on what we know about why and how visualization works”\n\n\n\n-Albert Cairo1, in his book, The Truthful Art\n\n\n1Someone who, in fact, knows a lot about effectively visualizing data"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#ex-choose-graph",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#ex-choose-graph",
    "title": "EDS 240",
    "section": "",
    "text": "Exercise: Map data to visual properties\n\n  \n\n\n\n−+\n03:00\n\n\n\nLet’s say you want to compare unemployment rates of 5 countries: A, B, C, D, E (the actual values here are not important).\n\n\nHow would you map the unemployment rates to visual properties in a way that enables your readers to accurately compare values without having to read all the numbers?\n\nExample adapted from Albert Cairo’s, The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#ex-possible-choices",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#ex-possible-choices",
    "title": "EDS 240",
    "section": "",
    "text": "Different methods of encoding the same data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphs recreated based on Albert Cairo’s example (Fig 5.2) in The Truthful Art\nFor all graphics: A (22%), B (25%), C (24%), D (29%), E (32%)\n\n\nLENGHT, HEIGHT, POSITION probably the best (have students discuss)"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#hierarchy",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#hierarchy",
    "title": "EDS 240",
    "section": "",
    "text": "“Hierarchy of elementary perceptual tasks”\n\n\n\n\nWilliam S. Cleveland & Robert McGill (1984) Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods, Journal of the American Statistical Association, 79:387, 531-554, DOI: 10.1080/01621459.1984.10478080\n\n\n\na viewer performs one or more of these mental-visual tasks (judging position, perceiving angles / areas, etc.) to extract the values of real variables represented on most graphs\nsuccessful charts are constructed based on elementary tasks “as high in the hierarchy as possible”\n\nAlbert Cairo’s recreation of Cleveland & McGill’s Hierarchy of Elementary Perceptual Tasks"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#compare-circles",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#compare-circles",
    "title": "EDS 240",
    "section": "",
    "text": "Exercise: How many times bigger is the larger circle?\n\n\n\n\n\n−+\n01:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#compare-bars",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#compare-bars",
    "title": "EDS 240",
    "section": "",
    "text": "Exercise: How many times bigger is the larger bar?\n\n\n\n\n\n−+\n01:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#7x",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#7x",
    "title": "EDS 240",
    "section": "",
    "text": "Both the circles & rectangles differ by a magnitude of 7"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#caveats1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#caveats1",
    "title": "EDS 240",
    "section": "",
    "text": "Caveats to the hierarchy\n\n \n1. Cleveland & McGill only considered statistical charts. What about data maps, for example, that rely on area / shading / hue, which fall lower on the hierarchy?"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#caveats1.1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#caveats1.1",
    "title": "EDS 240",
    "section": "",
    "text": "Caveats to the hierarchy - an example\n\nLower scale methods can be appropriate when the goal is to reveal general patterns. For example, a choropleth map displays divided geographical areas / regions, which are colored in relation to a numeric variable.\n\n\n\n\nPrecipitation data downloaded from NOAA’s National Centers for Environmental Information. Map created using the {maps} package."
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#caveats2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#caveats2",
    "title": "EDS 240",
    "section": "",
    "text": "Caveats to the hierarchy\n\n \n1. Cleveland & McGill only considered statistical charts. What about data maps, for example, that reply on area / shading / hue, which fall lower on the hierarchy?\n\n2. No method of choosing a graphic form is perfect! It’s important to think critically about your graphic’s purpose and how best to represent your data to serve that purpose."
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#caveats2.1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#caveats2.1",
    "title": "EDS 240",
    "section": "",
    "text": "Caveats to the hierarchy - an example\n\nConsider how you might display the same data in the following Sankey diagram, which depicts the flow of refugees in 2022, using graph types from the top of Cleveland & McGill’s hierarchy. What is the purpose of this chart?\n\n\n\n\n\n\n\nGraphic recreated using the {networkD3} package following Louise E. Sinks’ blog post, TidyTuesday: Exploring Refugee Flow with A Sankey Diagram\n\n\nIt would be hard to use a method of encoding from the top of the hierarchy! In this Sankey diagram, readers need to decode length and area, but that’s not a huge issue since the purpose of the chart is to show high-level trends / flows of refugees"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#tips0",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#tips0",
    "title": "EDS 240",
    "section": "",
    "text": "Tips for choosing the right graphic form\n\n\n\nThink about the task(s) you want to enable or message(s) you want to convey. For example, do you want to compare, see change or flow, reveal relationships or connections, envision temporal or spatial patterns.\n\n\n\n\nConsider the number of variables and the number of data points, as well as the data types you’re working with. For example, do you have several vs. many data points? How many categorical and/or numeric variables? Are your variables ordered or not ordered? Data types can dictate which graphical form is appropriate.\n\n\n\n\nTry different graphic forms, especially if you have more than one task to enable or message to convey.\n\n\n\n\nArrange the components of the graphic to make it as easy as possible to extract meaning from your graphic quickly.\n\n\n\n\nTest the outcomes of your graphic on others, particularly on those who are representative of the audience you are trying to reach.\n\n\nMost of the above tips are adapted from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#tips1-2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#tips1-2",
    "title": "EDS 240",
    "section": "",
    "text": "Tips for choosing the right graphic form\n\n\nThink about the task(s) you want to enable or message(s) you want to convey. For example, do you want to compare, see change or flow, reveal relationships or connections, envision temporal or spatial patterns.\nConsider the number of variables and the number of data points, as well as the data types you’re working with. For example, do you have several vs. many data points? How many categorical and/or numeric variables? Are your variables ordered or not ordered? Data types can dictate which graphical form is appropriate.\nTry different graphic forms, especially if you have more than one task to enable or message to convey.\nArrange the components of the graphic to make it as easy as possible to extract meaning from your graphic quickly.\nTest the outcomes of your graphic on others, particularly on those who are representative of the audience you are trying to reach.\n\n\nMost of the above tips are adapted from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#chart-selectors",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#chart-selectors",
    "title": "EDS 240",
    "section": "",
    "text": "1. What task(s) to enable / message(s) to convey\n2. Number of variables & data points, data types\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Viz Project\ndisplays one small data set 100 different ways\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Data to Viz\nsearch graphic types by data type or by function (+ R & Python Graph Gallery)\n\n\n\n\n\n\n\n\n\n\n\n\nThe Visualization Universe\ncompares most popular graphic forms\n\n\n\n\nSpend a couple minutes exploring these tools.\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#cat-disc1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#cat-disc1",
    "title": "EDS 240",
    "section": "",
    "text": "2. Number of variables & data points, data types\n\n\n\n\nQuantitative data\n\n\n\n\n\n\n\n\n\n\n\nContinuous variables: temperature (10.6°C, 14.9°C, 8.1°C), rainfall (1.7”, 3.3”, 9.4”)\nDiscrete variables: # of species counted in a region (1, 4, 6), a county’s population size (1,578, 10,324, 540,013)\n\n\n\n\n\n\nArt by Allison Horst"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#cat-disc2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#cat-disc2",
    "title": "EDS 240",
    "section": "",
    "text": "2. Number of variables & data points, data types\n\n\n\n\nQuantitative data\n\n\n\n\n\n\n\n\n\n\n\nContinuous variables: temperature (10.6°C, 14.9°C, 8.1°C), rainfall (1.7”, 3.3”, 9.4”)\nDiscrete variables: # of species counted in a region (1, 4, 6), a county’s population size (1,578, 10,324, 540,013)\n\n\n\nQualitative data\n\n\n\n\n\n\n\n\n\n\n\nNominal variables: gender identity (cisgender, transgender, non-binary), species (dog, cat, bird), land use (residential, parks, agriculture)\nOrdinal variables: income level (low / middle / high), satisfaction level (unsatisfied, neutral, satisfied)\nBinary: penguin sex (male / female), habitat type (shade / sun)\n\n\n\n\nArt by Allison Horst"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#tips3",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#tips3",
    "title": "EDS 240",
    "section": "",
    "text": "Tips for choosing the right graphic form\n\n\nThink about the task(s) you want to enable or message(s) you want to convey. For example, do you want to compare, see change or flow, reveal relationships or connections, envision temporal or spatial patterns.\nConsider the number of variables and the number of data points, as well as the data types you’re working with. For example, do you have several vs. many data points? How many categorical and/or numeric variables? Are your variables ordered or not ordered? Data types can dictate which graphical form is appropriate.\nTry different graphic forms especially if you have more than one task to enable or message to convey.\nArrange the components of the graphic to make it as easy as possible to extract meaning from your graphic quickly.\nTest the outcomes of your graphic on others, particularly on those who are representative of the audience you are trying to reach.\n\n\nMost of the above tips are adapted from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#choro-bar",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#choro-bar",
    "title": "EDS 240",
    "section": "",
    "text": "3. Try different graphic forms\n\nRecall our choropleth map from earlier, which displays total precipitation by US county. What if we want to compare precipitation between CA counties? Choosing a graphical form from the top of the hierarchy (e.g. bar chart) may be more effective.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we want to show both big picture patterns and detailed comparisons, we may consider including multiple graphic forms in the same visualization."
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#tips4",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#tips4",
    "title": "EDS 240",
    "section": "",
    "text": "Tips for choosing the right graphic form\n\n\nThink about the task(s) you want to enable or message(s) you want to convey. For example, do you want to compare, see change or flow, reveal relationships or connections, envision temporal or spatial patterns.\nConsider the number of variables and the number of data points, as well as the data types you’re working with. For example, do you have several vs. many data points? How many categorical and/or numeric variables? Are your variables ordered or not ordered? Data types can dictate which graphical form is appropriate.\nTry different graphic forms, especially if you have more than one task to enable or message to convey.\nArrange the components of the graphic to make it as easy as possible to extract meaning from your graphic quickly.\nTest the outcomes of your graphic on others, particularly on those who are representative of the audience you are trying to reach.\n\n\nMost of the above tips are adapted from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#ad-methods1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#ad-methods1",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\n How does the influence of in-theater advertising change across generations?  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImages from Albert Cairo’s The Truthful Art\n\n\n\n\n\n−+\n01:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#ad-methods2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#ad-methods2",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\n How does the influence of in-theater advertising change across generations?  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImages from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#fed-spending1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#fed-spending1",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\nLet’s say we’re interested in:\n\nchanges in the amount spent on Social Security relative to other major spending categories over time (2012-2015)?\n\n\n\n\n\nExample from Derek L. Sonderegger’s online textbook, STA 141 - Exploratory Data Analysis and Visualization"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#fed-spending2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#fed-spending2",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\nLet’s say we’re interested in:\n\nchanges in the amount spent on Social Security relative to other major spending categories over time (2012-2015)?\nthe amount of money spent on Social Security over time (2012-2015)?\n\n\n\n\n\nExample from Derek L. Sonderegger’s online textbook, STA 141 - Exploratory Data Analysis and Visualization"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#internet1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#internet1",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\nDo we want to convey:\n\ninternet usage in 2016? or\n\n\n\n\nExample from Claus Wilke’s, Fundamentals of Data Visualization"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#internet2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#internet2",
    "title": "EDS 240",
    "section": "",
    "text": "4. Arrange components of the graphic\n\nDo we want to convey:\n\ninternet usage in 2016? or\nhow early or late adoption of internet relates to current-day usage?\n\n\n\n\nExample from Claus Wilke’s, Fundamentals of Data Visualization"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#tips5",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#tips5",
    "title": "EDS 240",
    "section": "",
    "text": "Tips for choosing the right graphic form\n\n\nThink about the task(s) you want to enable or message(s) you want to convey. For example, do you want to compare, see change or flow, reveal relationships or connections, envision temporal or spatial patterns.\nConsider the number of variables and the number of data points, as well as the data types you’re working with. For example, do you have several vs. many data points? How many categorical and/or numeric variables? Are your variables ordered or not ordered? Data types can dictate which graphical form is appropriate.\nTry different graphic forms, especially if you have more than one task to enable or message to convey.\nArrange the components of the graphic to make it as easy as possible to extract meaning from your graphic quickly.\nTest the outcomes of your graphic on others, particularly on those who are representative of the audience you are trying to reach.\n\n\nMost of the above tips are adapted from Albert Cairo’s The Truthful Art"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#iraq",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#iraq",
    "title": "EDS 240",
    "section": "",
    "text": "5. Test the outcomes of your graphic on others\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Iraq’s bloody toll.\n\n\n\n\nTo enlarge image (in Chrome), right click on image &gt; Open image in New Tab\n\n\n\nWhat is the take home message of this graphic?\nWhat is effective? What is confusing?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#guns1",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#guns1",
    "title": "EDS 240",
    "section": "",
    "text": "5. Test the outcomes of your graphic on others\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: This Chart Shows An Alarming Rise In Florida Gun Deaths After ‘Stand Your Ground’ Was Enacted.\n\n\n\n\nTo enlarge image (in Chrome), right click on image &gt; Open image in New Tab\n\n\n\nWhat is the take home message of this graphic?\nWhat is effective? What is confusing?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#iraq-guns",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#iraq-guns",
    "title": "EDS 240",
    "section": "",
    "text": "5. Test the outcomes of your graphic on others\n\n\n\n\n\n\n\n\n\n\n\n\nBaseline at the top is clear, suggesting that bars are falling from it. Clear metaphor (dripping blood).\n\n\n\n\n\n\n\n\n\n\nEyes are drawn to baseline at the bottom, on top of which data are sitting. Headline indicates rise but visually represented by falling. Thick black line makes white area stand out over red (data).\n\n\n\n\nCritique by Albert Cairo in his post In visualization, baselines and negative space matter"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#guns2",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#guns2",
    "title": "EDS 240",
    "section": "",
    "text": "5. Test the outcomes of your graphic on others\n\nBusiness Insider published an updated graphic (originally designed by Reuters), which was submitted by a reader that, “more clearly shows that gun deaths increased between 2005 and 2007 by flipping the y-axis”:"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#critique-considerations",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#critique-considerations",
    "title": "EDS 240",
    "section": "",
    "text": "5. Test the outcomes of your graphic on others\n\n\nCritiquing a data visualization:\n\nIdentify the primary and secondary insights that the graphic is trying to convey.\n\n\n\nIdentify elementary perceptual tasks (e.g. comparing lengths, angles) and what is confusing or difficult to do.\n\n\n\n\nIdentify if it’s possible (and if it makes sense) to use more effective elementary perceptual tasks for the primary and secondary insights\n\n\n\n\nIdentify points of confusion and decide how those could be addressed (e.g. a different graphic form, rearranging components, including an introduction graph, better annotation)\n\n\n\nAdapted from Derek L. Sonderegger’s online textbook, STA 141 - Exploratory Data Analysis and Visualization"
  },
  {
    "objectID": "slides/week3.1-choosing-graphic-forms-slides.html#end-break",
    "href": "slides/week3.1-choosing-graphic-forms-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 3) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html",
    "href": "slides/sections/delete/choropleth-practice-NEW.html",
    "title": "EDS 240",
    "section": "",
    "text": "Warning: package 'ggplot2' was built under R version 4.3.1\n\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\nWarning: package 'stringr' was built under R version 4.3.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWarning: package 'maps' was built under R version 4.3.1\n\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 3107 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): ID, Name, State, Value, 1901-2000 Mean\ndbl (2): Rank, Anomaly (1901-2000 base period)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nJoining with `by = join_by(state, county)`"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html#create-base-map",
    "href": "slides/sections/delete/choropleth-practice-NEW.html#create-base-map",
    "title": "EDS 240",
    "section": "—————– Create base map —————–",
    "text": "—————– Create base map —————–\n\n# 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\nbase_map &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n  \n  # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n  geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n  \n  # darken state lines ----\n  geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n  \n  # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n  #coord_fixed(1.3) +\n  \n  # update labels ----\n  labs(title = \"Total Precipitation, by County\",\n       subtitle = \"October 2023\") +\n  \n  # set theme to clean up appearance ----\n  theme_void() + \n  \n  # theme adjustments ----\n  theme(\n    legend.position = \"bottom\"\n  )\n  \nbase_map"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html#add-projection",
    "href": "slides/sections/delete/choropleth-practice-NEW.html#add-projection",
    "title": "EDS 240",
    "section": "—————– Add projection —————–",
    "text": "—————– Add projection —————–\n\nbase_map_proj &lt;- base_map + \n  coord_map(projection = \"mercator\")\n\nbase_map_proj"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html#custom-function-to-add-correct-guide-bar-styling",
    "href": "slides/sections/delete/choropleth-practice-NEW.html#custom-function-to-add-correct-guide-bar-styling",
    "title": "EDS 240",
    "section": "—————– Custom function to add correct guide bar styling —————–",
    "text": "—————– Custom function to add correct guide bar styling —————–\n\n# apply to following maps to customize legend appearance ----\ncustom_guide &lt;- function(type) {\n  \n  # if gradient, use guide_color()\n  if (type == \"g\") {\n    guides(fill = guide_colorbar(title = \"Precipitation (inches)\",\n                                 title.position = \"top\",\n                                 barwidth = 15, barheight = 1))\n    \n  # if bin, use guide_colorsteps()\n  } else if (type == \"b\") {\n    guides(fill = guide_colorsteps(title = \"Precipitation (inches)\",\n                                   title.position = \"top\",\n                                   barwidth = 15, barheight = 1))\n  }\n}"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html#initial-attempt-manually-create-binned-color-gradient",
    "href": "slides/sections/delete/choropleth-practice-NEW.html#initial-attempt-manually-create-binned-color-gradient",
    "title": "EDS 240",
    "section": "—————– Initial attempt: manually create binned color gradient —————–",
    "text": "—————– Initial attempt: manually create binned color gradient —————–\n\n# # plot (viridis) ----\n# base_map_proj + \n#   scale_fill_viridis_c() +\n#   custom_guide(type = \"g\")\n\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#D5D4CE\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n\n# plot (gradient) ----\nbase_map_proj + \n  scale_fill_gradientn(colors = my_palette) +\n  custom_guide(type = \"g\")\n\n\n\n# plot (binned) ----\nbase_map_proj + \n  scale_fill_stepsn(colors = my_palette) +\n  custom_guide(type = \"b\")\n\n\n\n\nWe have a map (yay!) but the binned version is not so helpful yet. We’re not seeing much detail (most of the country is colored brown, having received 0-5”). ggplot is also defaulting to 5 bins (colors), which is not what we want. We’ll have to define our own bins. One approach is to calculate & specify equal bin sizes:\n\nget max & min precipitations\nsubtract them\ndivide the result by the number of intervals that we want (11 colors, ideally)\n\n\n# range of data ----\nrange(na.omit(joined_precip_us_counties)$precip) # 0.0-10.2 \n\n[1]  0.0 10.2\n\n# calculate bin size ----\n(max(na.omit(joined_precip_us_counties)$precip) - min(na.omit(joined_precip_us_counties)$precip))/11 # 0.93\n\n[1] 0.9272727\n\n\nUsing this approach, class size would be 1 (rounded from 0.93). To achieve that, we need to set breaks that are a width of 1 from our min value (0) to our max (11, since max value is 10.2). We also need the appropriate amount of colors to fill those bins.\n\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#16726B\", \"#003C30\") \n\n# define breaks ----\nmy_breaks &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)\n\n# plot ----\nbase_map_proj + \n  scale_fill_stepsn(colors = my_palette,\n                    breaks = my_breaks,\n                    values = scales::rescale(my_breaks)) +\n  custom_guide(type = \"b\") \n\n\n\n# base_map_proj + \n#   scale_fill_stepsn(colors = my_palette,\n#                     breaks = my_breaks, \n#                     values = scales::rescale(my_breaks)) +\n#   custom_guide(type = \"b\")\n# \n# \n# scale_fill_stepsn(name = \"\", \n#                     colors =c(\"#2171b5\", \"#6baed6\", \"#bdd7e7\", \"#fcae91\", \"#fb6a4a\", \"#cb181d\"),\n#                     breaks = c(-25, -10, 0, 10, 50),\n#                     values = scales::rescale(c(-25, -10, 0, 10, 25, 50))) \n\nAttempt B is a better, though it would be wise to look at the distribution of our precipitation data to see if we might be losing any important details:\n\n# plot histogram ----\nggplot(joined_precip_us_counties, aes(x = precip)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n# calculate median ----\nmedian(na.omit(joined_precip_us_counties)$precip) # 2.02\n\n[1] 1.99\n\n\nOur data are heavily right-skewed (most are smaller values), and our median value is 2.02” – meaning half our our data fall below 2.02”. This means that we’re likely losing details at the lower end of the spectrum, since we have so many small precipitation totals. Let’s take an even closer look by calculating some quantiles:\n\n# default quartiles ----\nquantile(joined_precip_us_counties$precip,\n         probs = seq(from = 0, to = 1, by = 0.25),\n         na.rm = TRUE)\n\n   0%   25%   50%   75%  100% \n 0.00  1.19  1.99  3.30 10.20 \n\n\nHow do we interpret this?\n\nOur min value is 0 and max value is 10.20.\n25% of our precipitation recordings live below 1.19”\n50% of our precipitation recordings live below 2.02”\n75% of our precipitation recordings live below 3.31”\n100% of our precipitation recordings live below 10.20”\n\nWe can adjust the quantiles calculated:\n\nquantile(joined_precip_us_counties$precip, \n         probs = seq(from = 0, to = 1, by = 0.10),\n         na.rm = TRUE)\n\n   0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100% \n 0.00  0.66  1.05  1.35  1.60  1.99  2.47  3.03  3.59  4.47 10.20 \n\n\nWe see here that 10% of all our precipitation recordings live below 0.65”! And 90% live below 4.47”.\n\n# define palette ----\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#16726B\", \"#003C30\") \n# my_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n#                  \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n\n# define breaks ----\nmy_breaks = c(0, 0.65, 1.05, 1.35, 1.61, 2.02, 2.51, 3.05, 3.61, 4.47, 10.20)\n\n# plot ----\nbase_map +\n  scale_fill_stepsn(trans = scales::pseudo_log_trans(),\n                    colors = my_palette,\n                    breaks = my_breaks) +\n  custom_guide(type = \"b\")\n\n\n\n\n\n\n\n\n# mean(na.omit(joined_precip_us_counties$precip)) # 2.4\n# sd(na.omit(joined_precip_us_counties$precip)) # 1.6\n\n\n\n# # define palette ----\n# my_palette &lt;- c(\"#543006\", \"#AC7E42\", \"#C09C66\", \"#E8E8E8\",\n#                 \"#64A7A1\", \"#3B8E86\", \"#003C30\")\n# \n# # define breaks ----\n# my_breaks &lt;- c(0, 0.8, 2.4, 4, 5.6, 7.2, 8.8, 10.4)\n# \n# # plot ----\n# base_map_proj + \n#   scale_fill_stepsn(colors = my_palette,\n#                     breaks = my_breaks) +\n#   custom_guide(type = \"b\")\n\n\n\n# # define palette ----\n# my_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n#                  \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n# \n# # define breaks ----\n# my_breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)\n# \n# # plot ----\n# base_map +\n#     scale_fill_stepsn(trans = \"log\",\n#                       colors = my_palette,\n#                       breaks = my_breaks) \n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method3 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # # OPTION 1: update colors with pre-fab palette ----\n#   # scale_fill_viridis_c(option = \"D\") +\n#   # scale_fill_distiller(palette = 'Purples')\n#   # scale_fill_viridis_c(trans = \"log\", breaks=c(0.1, 0.5, 2,4,6, 8, 10, 12, 15, 20, 25), \n#   #                  name=\"Number of restaurant\", \n#   #                  guide = guide_legend( \n#   #                                        label.position = \"bottom\", \n#   #                                        title.position = 'top',\n#   #                                        nrow=1))\n#   # \n#   # OPTION 2: manually create a color gradient ----\n#   # scale_fill_gradient(low = \"#C8ECE6\", high = \"#213943\") +\n#   \n#   # OPTION 2: manually create a color gradient ----\n#   #scale_fill_gradient2(low = \"#77A8B9\", mid = \"#FFFFFF\", high = \"#213943\") +\n#   scale_fill_steps2(#trans = \"log\",\n#                     low = \"#543006\", mid = \"#E8E8E8\", high = \"#003C30\",\n#                     midpoint = 4) +\n#                     # colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                     #            \"#E8E8E8\", \n#                     #            \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"), \n#                     # breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)) +\n#   \n#   # update legend ----\n#   guides(fill = guide_coloursteps(title = \"Precipitation (inches)\", \n#                                   title.position = \"top\",\n#                                   barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n# \n# method3\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# original &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient; nice.breaks = TRUE by default ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#EBD9B0\",\n#                                \"#E8E8E8\", \"#B2DDD7\", \"#8BC2BC\", \"#3B8E86\", \"#16726B\", \"#003C30\")) +\n#                     #breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)) +\n# \n# \n#   # update legend ----\n#   # guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#   #                               title.position = \"top\",\n#   #                               barwidth = 15, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# original\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method1 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                                \"#E8E8E8\", \n#                                \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"),\n#                     breaks = c(0, 1.7, 3.4, 5.1, 6.8, 8.5, 10.2, 11.9, 13.6, 15.3, 17, 18.7)) +\n#                    \n# \n#   # update legend ----\n#   guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#                                 title.position = \"top\",\n#                                 barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# method1\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method2 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                                \"#E8E8E8\", \n#                                \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"),\n#                     breaks = c(0, 1, 4, 7, 10, 13, 16, 19)) +\n#                    \n# \n#   # update legend ----\n#   guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#                                 title.position = \"top\",\n#                                 barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# method2\n\n\n  # # OPTION 2: manually create a color gradient ----\n  # #scale_fill_gradient2(low = \"#77A8B9\", mid = \"#FFFFFF\", high = \"#213943\") +\n  # scale_fill_stepsn(trans = \"log\",\n  #                   colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#EBD9B0\", \"#B2DDD7\", \"#8BC2BC\", \"#3B8E86\", \"#16726B\", \"#003C30\"), \n  #                   breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)) +\n  # \n  # # update legend ----\n  # guides(fill = guide_coloursteps(title = \"Precipitation (inches)\", \n  #                                 title.position = \"top\",\n  #                                 barwidth = 15, barheight = 1)) +\n  # \n  # # update labels ----\n  # labs(title = \"Total Precipitation, by County\",\n  #      subtitle = \"January 2023\") +\n  # \n  # # set theme to clean up appearance ----\n  # theme_void() + \n  # \n  # # theme adjustments ----\n  # theme(\n  #   legend.position = \"bottom\"\n  # )"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice-NEW.html#data-wrangling-2-usmap",
    "href": "slides/sections/delete/choropleth-practice-NEW.html#data-wrangling-2-usmap",
    "title": "EDS 240",
    "section": "—————– Data wrangling 2 ({usmap}) —————–",
    "text": "—————– Data wrangling 2 ({usmap}) —————–\n\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# ##                                    setup                                 ----\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# \n# #..........................load packages.........................\n# library(tidyverse)\n# library(usmap)\n# \n# #.........................get shape data.........................\n# county_map &lt;- us_map(regions = \"counties\") |&gt; \n#   rename(state_abb = abbr, state_name = full)\n# \n# #....................import precipitation data...................\n# precip_counties &lt;- read_csv(here::here(\"slides\", \"data\", \"county-precip-oct2023.csv\"), skip = 4) |&gt; \n#   janitor::clean_names() |&gt; \n#   rename(county = name, state_name = state, precip_in = value) |&gt; \n#   mutate(precip_in = as.numeric(precip_in))\n# \n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# ##                                  join dfs                                ----\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# \n# precip_counties_wrangled &lt;- full_join(precip_counties, county_map)\n\n\n# # empty map ----\n# plot_usmap(regions = c(p),\n#            exclude = c(\"AK\", \"HI\"))\n# \n# # fill counties ----\n# precip_counties_wrangled |&gt; \n#   select(fips, precip_in) |&gt; \n#   plot_usmap(regions = \"counties\", exclude = c(\"AK\", \"HI\"),\n#              data = precip_counties_wrangled, values = \"precip_in\") + \n#   scale_fill_viridis_c() +\n#   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/week10.1-tbd.html",
    "href": "slides/week10.1-tbd.html",
    "title": "EDS 240",
    "section": "",
    "text": "see issue: https://github.com/samanthacsik/EDS-240-data-viz/issues/16 {waffle} {treemapify} {ggraph} {ggbump} {ggstream} {gggibbous}"
  },
  {
    "objectID": "getting-unstuck.html",
    "href": "getting-unstuck.html",
    "title": "Getting unstuck",
    "section": "",
    "text": "A large part of being a data scientist is ~being okay~ with not immediately knowing the answers to your code challenges – troubleshooting errors, deciphering code, and trying new things (and likely failing at some…er many…of them) is all a part of the job. We all experience it, no matter how many years we’ve been at it."
  },
  {
    "objectID": "getting-unstuck.html#where-to-find-help",
    "href": "getting-unstuck.html#where-to-find-help",
    "title": "Getting unstuck",
    "section": "Where to find help",
    "text": "Where to find help\nWe often learn the most (and remember more of what we learned) when we take the time to troubleshoot on our own (or at least narrow down the potential problem(s)), so you should always plan to start there . The graphic below shows the order in which you should approach different resources for help:"
  },
  {
    "objectID": "getting-unstuck.html#roadblock-checklist",
    "href": "getting-unstuck.html#roadblock-checklist",
    "title": "Getting unstuck",
    "section": "Roadblock checklist",
    "text": "Roadblock checklist\nIf you hit a roadblock, run through this checklist to make sure you’ve done your due diligence before bringing your question(s) to a peer, TA, or instructor:\n\nrevisit the course materials – your question may already be answered in the slides\nread the documentation – you can do so directly from RStudio by typing ?function_name in the console\nsearch for and read the package’s, vignette if available – these are often linked on CRAN under the Documents section (e.g. see {dplyr} on CRAN) or found by Googling package_name vignette (e.g. the result of Googling dplyr vignette leads to the dplyr vignette)\ntry Googling! – don’t forget to a look back some of our suggested troubleshooting and Googling tips in Teach Me How to Google:"
  },
  {
    "objectID": "getting-unstuck.html#how-to-ask-questions",
    "href": "getting-unstuck.html#how-to-ask-questions",
    "title": "Getting unstuck",
    "section": "How to ask questions",
    "text": "How to ask questions\nWhen you decide you’re going to ask a question to a peer / TA / instructor, be sure to (borrowed from Dr. Allison Horst’s Troubleshooting 101 lecture, EDS 221):\n\nProvide context. For example, “I’m trying to do this…” or “I’m working on the task where we do this…”\nShare the specific challenge. “I’m specifically trying to [insert function / package] to do this thing.”\nShare what happens and what you’ve learned. “I repeatedly get an error message that says [this]. I’ve tried [this] and [this]”\nShow your code ideally with a reprex that they can run / test.\nValue and expect the Socratic method, especially in classes and workshops – our goal is to provide critical thinking that is transferable, not just to provide a quick fix for a single error."
  },
  {
    "objectID": "getting-unstuck.html#some-words-of-wisdom",
    "href": "getting-unstuck.html#some-words-of-wisdom",
    "title": "Getting unstuck",
    "section": "Some words of wisdom",
    "text": "Some words of wisdom\nFinally, Julia Evans shares some funny (and highly relatable) words of wisdom:"
  },
  {
    "objectID": "assignments/SR3-endcourse.html",
    "href": "assignments/SR3-endcourse.html",
    "title": "End-of-course reflection (SR #3)",
    "section": "",
    "text": "In this assignment, you’ll reflect on your learning throughout this class. Revisit your self-evaluations from the start and middle of the quarter, and answer the following questions in 2-6 sentences each:\n\nSince your mid-quarter self-evaluation, have you improved any of your existing skills? Have you learned new ones?\nHave you accomplished your learning goals for this quarter (that you set at the beginning of the quarter)? If you did, how did you do it?\nWhat are you proudest of accomplishing in this course?\nWhat are some transferable skills that you developed in this course? How might you apply them to other courses / deliverables within the MEDS program or jobs in the future?\nWhat is one thing that you really liked about this course, and why? What is one thing you think could be improved about this course, and how?\nIs there anything else you’d like the instructors to know about your experience in the course?"
  },
  {
    "objectID": "assignments/SR3-endcourse.html#description",
    "href": "assignments/SR3-endcourse.html#description",
    "title": "End-of-course reflection (SR #3)",
    "section": "",
    "text": "In this assignment, you’ll reflect on your learning throughout this class. Revisit your self-evaluations from the start and middle of the quarter, and answer the following questions in 2-6 sentences each:\n\nSince your mid-quarter self-evaluation, have you improved any of your existing skills? Have you learned new ones?\nHave you accomplished your learning goals for this quarter (that you set at the beginning of the quarter)? If you did, how did you do it?\nWhat are you proudest of accomplishing in this course?\nWhat are some transferable skills that you developed in this course? How might you apply them to other courses / deliverables within the MEDS program or jobs in the future?\nWhat is one thing that you really liked about this course, and why? What is one thing you think could be improved about this course, and how?\nIs there anything else you’d like the instructors to know about your experience in the course?"
  },
  {
    "objectID": "assignments/SR3-endcourse.html#rubric-specifications",
    "href": "assignments/SR3-endcourse.html#rubric-specifications",
    "title": "End-of-course reflection (SR #3)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for this End-of-course reflection:\nComplete the following steps in your GitHub Classroom repo (eds240-SR3/SR3-endcourse-reflection.qmd):\n\ninclude your preferred name, and if you feel comfortable, your preferred pronouns in the title of the SR3-endcourse-reflection.qmd YAML\naddress each question in at least 2-6 sentences (but please feel free to expand on any of these, if you’d like)\npush SR3-endcourse-reflection.qmd to GitHub using GitHub Classrooms by 11:59pm PT on Sat 03/16/2024\n\nAdditionally, please complete the ESCI evaluations associated with this course (EDS 240) for both the instructor (Sam Csik) and TA (Sevan Esaian) by the deadline (Friday, 03/15/2024)."
  },
  {
    "objectID": "assignments/HW3.html",
    "href": "assignments/HW3.html",
    "title": "Assignment #3 (HW #3)",
    "section": "",
    "text": "HW #3 will have you focus on making more progress towards completing your final assignment (HW #4). Your final assignment is meant to combine all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\nassess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "assignments/HW3.html#learning-objectives",
    "href": "assignments/HW3.html#learning-objectives",
    "title": "Assignment #3 (HW #3)",
    "section": "",
    "text": "HW #3 will have you focus on making more progress towards completing your final assignment (HW #4). Your final assignment is meant to combine all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\nassess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "assignments/HW3.html#description",
    "href": "assignments/HW3.html#description",
    "title": "Assignment #3 (HW #3)",
    "section": "Description",
    "text": "Description\nPlease begin by reviewing the description for HW #4 so that you are familiar with the expectations for your final submission at the end of the quarter – we’ll again be making some more incremental steps towards our final deliverables here in HW #3.\nFor HW #3, you must complete the following:\n\nWhich option do you plan to pursue?\nRestate your question(s). Has this changed at all since HW #1? If yes, how so?\n\n\n\n\n\n\n\nNote\n\n\n\nBe mindful that the number of questions you list above will depend on which option you choose to pursue:\n\nIf you choose option 1, you should have one question that each of your three visualizations works to answer, where each visualization is meant to reach / serve a different target audience and purpose.\nIf you choose option 2, you should have one overarching question and at least three sub-questions that each of your infographic components answer.\n\nPlease refer to HW #4 for full details on each of these options.\n\n\n\nExplain which variables from your data set(s) you will use to answer your question(s).\n\n\n\n\n\n\n\nImportant – be specific here!\n\n\n\nFor example, let’s say I’m interested in how Lyme disease incidence is changing over time for states X, Y and Z. An appropriate explanation of variables might look something like this:\n\n“I have two data sets, one containing population estimates by state from the {tidycensus} package, and another from the CDC containing lyme disease case counts by county and year. After wrangling / joining these data sets, I was able to calculate disease incidence as cases per 100k people at the state level. Doing so provides me with three variables to visualize: time (years), disease incidence (cases per 100k people), and state.”\n\n\n\n\n\nIn HW #2, you should have created some exploratory data viz to better understand your data. You may already have some ideas of how you plan to formally visualize your data, but it’s incredibly helpful to look at visualizations by other creators for inspiration. Find at least two data visualizations that you could (potentially) borrow / adapt pieces from. Link to them or download and embed them into your .qmd file, and explain which elements you might borrow (e.g. the graphic form, legend design, layout, etc.).\n\n\n\n\n\n\n\nTip: Remember to check out the Resources page!!\n\n\n\nI’ve added a tons of really wonderful websites, tutorials, and links to the repos / websites of some seriously incredible data viz creators. This is an excellent place to start when looking for inspiration.\nIf you have an account, it can also be helpful to search #tidytuesday on X (formally known as Twitter).\n\n\n\nHand-draw your anticipated three visualizations (option 1) or infographic (option 2). Take a photo of your drawing and embed it in your rendered .qmd file – note that these are not exploratory visualizations, but rather your plan for your final visualizations that you will eventually polish and submit with HW #4.\n\n\n\n\n\n\n\nTip: Embedding images into a .qmd file\n\n\n\nThere are a number of ways to render an image in .qmd file. Two ways I find easiest are:\n\nUsing knitr::include_graphics() in a code chunk. Here are the chunk options I often specify:\n\n#| eval: true\n#| echo: false\n#| fig-align: \"center\"\n#| out-width: \"100%\"\n#| fig-alt: \"Alt text here\"\nknitr::include_graphics(\"path/to/image\")\n\nUsing Markdown syntax:\n\n![](file/path/to/image){fig-alt=\"Alt text goes here\"}\nHere is a minimal example of a hand-drawn plot – you don’t need to be an artist, but your vision (and handwriting) should be clear:\n\n\n\n\n\n\n\n\n\n\n\n\nMock up your visualizations using code. We understand that you will continue to iterate on these into HW #4 (particularly after receiving feedback), but by the end of HW #3, you should:\n\nhave your data plotted (if you’re experimenting with an advanced graphic form(s) that were not explicitly covered in class, we understand that this may take some more time to build; you should have as much put together as possible)\nuse appropriate strategies to highlight / focus attention on a clear message\ninclude appropriate text such as titles, captions, axis labels\nexperiment with colors and typefaces / fonts\ncreate a presentable / aesthetically-pleasing theme (e.g. (re)move gridlines / legends as appropriate, adjust font sizes, etc.)\n\nAnswer the following questions:\n\nWhat challenges did you encounter or anticipate encountering as you continue to build / iterate on your visualizations in R?\nWhat ggplot extension tools / packages do you need to use to build your visualizations? Are there any that we haven’t covered in class that you’ll be learning how to use for your visualizations?\nWhat feedback do you need from the instructional team and / or your peers to ensure that your intended message is clear?"
  },
  {
    "objectID": "assignments/HW3.html#rubric-specifications",
    "href": "assignments/HW3.html#rubric-specifications",
    "title": "Assignment #3 (HW #3)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for Assignment #3:\nComplete the following steps under your lastName-eds240-HW4 repo:\n\nComplete all work in a file named, HW3-drafting-viz.qmd – you are welcome to draft / practice things in different files / scripts, but you must have all required elements of the assignment available in this file for us to reference and grade.\nAdd any necessary YAML options (title, author, date, etc.). You must also include the following options:\n\n\n---\n# ~ additional YAML options omitted for brevity ~\nformat:\n  html:\n    embed-resources: true\n---\n\n\nComplete all exercises and answer all questions under the Description section above (use the check boxes to ensure you’ve completed all required parts).\n\n\n\n\n\n\n\nA few notes on expectations\n\n\n\n\nYour plots don’t have to be perfect but the message you want to convey should be clear\nThe more progress you make now, the more feedback we can provide ahead of HW #4\nThere are no strict length requirements for the free-response questions above. However, we expect that you answer them thoughtfully and fully. Low-effort responses will result in a “Not Yet” mark.\n\n\n\n\nEnsure all code chunks have the correct options set so that (a) code and outputs render, and (b) warnings and messages are suppressed (unless there is a reason to have them print). Please note that rendered documents that don’t have correctly specified chunk options will receive a “Not Yet” score.\nCode should be appropriately styled and annotated (please see this resource on the course website), and your .qmd file should be easy to navigate.\nWhen complete, render your HW3-drafting-viz.qmd file, verify that you can open the resulting HW3-drafting-viz.html file in your browser and that all formatting looks good. Rename your .html file so that it has your first initial / last name at the start (e.g. SCsik-HW3-drafting-viz.html) then send it to both Sevan and Sam on Slack via direct message."
  },
  {
    "objectID": "assignments/HW1.html",
    "href": "assignments/HW1.html",
    "title": "Assignment #1 (HW #1)",
    "section": "",
    "text": "You must earn a “Satisfactory” mark for each individual Part (I and II) to earn a “Satisfactory” mark for Assignment #1.\nNOTE: Assignments are to be submitted via GitHub Classrooms, unless otherwise noted. Each student receives one “free pass” for not submitting assignments via specified channels, after which you will receive a “Not Yet” mark.\nRead each part of the assignment carefully, and use the check boxes to ensure you’ve addressed all elements of the assignment!"
  },
  {
    "objectID": "assignments/HW1.html#learning-outcomes",
    "href": "assignments/HW1.html#learning-outcomes",
    "title": "Assignment #1 (HW #1)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nread code written by others\nassess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "assignments/HW1.html#description",
    "href": "assignments/HW1.html#description",
    "title": "Assignment #1 (HW #1)",
    "section": "Description",
    "text": "Description\nMuch of your time as a data scientist will be spent looking at code written by others – maybe you’re trying to learn from and adapt someone else’s code for your own work, or perhaps you’ve been asked to conduct a code review for a colleague. Being able to look at and make sense of code that you did not write yourself is an invaluable skill and an important one to practice throughout your learning journey. Here, you’ll be asked to interpret and annotate {ggplot2} code written by someone else. This will likely require running code (both as a whole and line-by-line), as well as Googling and / or reading documentation.\nI recognize that there is (likely) a lot of new code presented here, and that we haven’t covered much at all yet in this course. This is intentionally an exercise is resourcefulness! By the end of this exercise, you should feel a bit more confident in your ability to interpret (and maybe even reuse!) code written by others.\n(Part 1a) Annotate the following code, adapted from Christophe Nicault’s visualization titled, Evolution of deaths from indoor air pollution (original code) – to enlarge image (in Chrome) right-click on image &gt; Open Image in New Tab:\n\n\n\n\n\n\n\n\n\nYou can find metadata and additional information about the data set on the rfordatascience/tidytuesday (2022-04-12) readme.md. Note: A select few lines of code have already been annotated for you.\n\n\n\n\n\n\nClick here to expand the code AND for tips on getting started\n\n\n\n\n\nInstall the following packages (if you don’t already have them) using install.packages(\"package_name\") or install.packages(pkgs = c(\"package_name1\", \"package_name2\", ...)):\n\n{tidytuesdayR}\n{tidyverse}\n{patchwork}\n{showtext}\n{sysfonts}\n{countrycode}\n{glue}\n{scales}\n{ragg}\n\nTips:\n\nSee lines 114 and 120 (among others) for examples of code annotations – aim to include this level of detail.\nWriting clean annotations makes it easier for you and others to read them – I love using the {ARTofR} package to create titles, dividers, and block comments in my scripts and Qmd / Rmd files. Read more about how to create different dividers using the {ARTofR} package on this resource page of the course website.\nPull up documentation for a function directly in RStudio’s Help pane by running ?function_name in the console. Vignettes and pkgdown sites are incredible resources as well (e.g. here is a vignette and the pkgdown site for the {patchwork} package)\nIf you don’t immediately understand the purpose of a line / chunk of code, skip over it (temporarily) and continue working your way through the following code – it oftentimes becomes more evident given additional context.\nPlots may look super squished in the RStudio Viewer pane – use the Zoom button to pop them open in a separate window.\nKeep in mind: While this is fairly complex ggplot code, remember that it’s constructed in layers – meaning you can run code line-by-line to see exactly how the plot is changing with each new layer. You may come across functions and arguments that you’re already familiar with (yay!), and of course, others that are totally new.\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                  1. setup                                ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse) # ANNOTATE (brief explanation of pkg) ----\nlibrary(patchwork) # ANNOTATE (brief explanation of pkg) ----\nlibrary(showtext) # ANNOTATE (brief explanation of pkg) ----\n\n#......................download Google Fonts.....................\n# ANNOTATE (explain differences between arguments `name` & `family`) ----\nfont_add_google(name = \"Roboto\", family = \"roboto\")\nfont_add_google(name = \"Roboto Condensed\", family = \"roboto condensed\")\nfont_add_google(name = \"Oswald\", family = \"oswald\")\nfont_add_google(name = \"Khula\", family = \"khula\")\nfont_add_google(name = \"Share Tech Mono\", family = \"techmono\")\n\n#.....settings for using imported texts in future saved plot.....\nshowtext_opts(dpi = 320) # tell {showtext} the resolution for the device ----\nshowtext_auto(enable = TRUE) # automatically use {showtext} to render text for future devices ----\n\n#................load TidyTuesday data from GitHub...............\ntuesdata &lt;- tidytuesdayR::tt_load(x = 2022, week = 15)\n\n#........extract individual data sets from tuesdata (list).......\nindoor_pollution &lt;- tuesdata$indoor_pollution \ndeath_ts &lt;- tuesdata$death_timeseries\ndeath_full &lt;- tuesdata$death_fuel\nfuel_gdp &lt;- tuesdata$fuel_gdp\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                              2. data wrangling                           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#......ANNOTATE (generally, what does this code block do?).......\nindoor_pollution &lt;- indoor_pollution %&gt;%\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  rename(perc_death = 4) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  mutate(continent = countrycode::countrycode(sourcevar = Code, origin = \"iso3c\", destination = \"continent\")) \n\n#......ANNOTATE (generally, what does this code block do?).......\ngap_indoor &lt;- indoor_pollution %&gt;%\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  filter(!is.na(Code), Code != \"OWID_WRL\") %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  filter(Year %in% c(1990, 2019)) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  mutate(year = glue::glue(\"Y{Year}\")) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  pivot_wider(id_cols = c(\"Entity\", \"Code\"), names_from = year, values_from = perc_death) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  mutate(gap = Y2019 - Y1990) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  mutate(continent = countrycode::countrycode(sourcevar = Code, origin = \"iso3c\", destination = \"continent\")) \n\n#......ANNOTATE (generally, what does this code block do?).......\nfuel_gdp_clean &lt;- fuel_gdp %&gt;%\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  rename(clean_fuel = 4, gdp = 5, population = 6) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  select(-Continent) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  mutate(continent = countrycode::countrycode(sourcevar = Code, origin = \"iso3c\", destination = \"continent\")) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  filter(!is.na(continent)) \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          3. prep ggplot elements                         ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#......ANNOTATE (generally, what does this code block do?).......\npal &lt;- c(\"#02403A\", \"#0A7373\", \"#757A62\", \"#EDAA25\", \"#C43302\")\n\n#......ANNOTATE (generally, what does this code block do?).......\ngraph_legend &lt;- \"The first graph shows the relation between the decrease of the percentage of deaths and the access to clean fuel.\\nEach country is represented by a line connecting all the values from 2002 to 2019.\\nIt shows that for many countries the access to clean fuel for cooking increased over\\n the years resulting in a reduction of percentage of death due to indoor air pollution.\\n\\nThe graph below shows the evolution between 1990 and 2019\\n in the distribution of the percentage of death among\\n the countries of each continent.\"\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                       4. build connected scatterplot                     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#......ANNOTATE (generally, what does this code block do?).......\nconnected_scatterplot_df &lt;- indoor_pollution %&gt;%\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  select(-continent) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  left_join(fuel_gdp_clean, by = c(\"Entity\" = \"Entity\", \"Code\" = \"Code\", \"Year\" = \"Year\")) %&gt;% \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  filter(!is.na(clean_fuel), !is.na(gdp)) \n\n#..................create connected scatterplot..................\n\n#......ANNOTATE (generally, what does this code block do?).......\nconnected_scatterplot &lt;- ggplot(data = connected_scatterplot_df, aes(x = clean_fuel, y = perc_death, alpha = Year)) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_line(aes(group = Code, color = continent), linewidth = 0.9) + \n  \n  # add scatterplot layer; points colored by 'continent' variable, outlined in white ----\n  geom_point(aes(fill = continent), size = 1, shape = 21, color = \"white\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  annotate(\"text\", x = 96, y = 21, label = graph_legend, family = \"roboto\", size = 4, hjust = 1, vjust = 1) + \n  \n  # convert x-axis & y-axis values to %; add some padding between data and axes ----\n  scale_x_continuous(labels = scales::label_percent(scale = 1), expand = c(0.01, 0.01)) + \n  scale_y_continuous(labels = scales::label_percent(scale = 1, accuracy = 1), expand = c(0.01, 0.01)) + \n  \n  # ANNOTATE (briefly explain these lines of code) ----\n  scale_color_manual(values = rev(pal)) + \n  scale_fill_manual(values = rev(pal)) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  guides(alpha = \"none\", color = \"none\", fill = \"none\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  theme_light(base_family = \"roboto condensed\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  labs(x = \"% of access to clean fuel\", \n       y = \"% of deaths\") + \n  \n  # ANNOTATE (briefly explain these lines of code) ----\n  theme(axis.title.y = element_text(margin = margin(t = -20, r = -80, b = 0, l= 0), angle = 0, size = 12), \n        axis.title.x = element_text(margin = margin(t = 10), size = 12), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        axis.text = element_text(size = 11), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        panel.border = element_blank())\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            5. build histograms                           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#.............df of % ranges used to build histogram.............\nhisto_evolution_df &lt;- gap_indoor %&gt;%\n  \n  # assign % death to a range (e.g. AFG (Y1990): 19.623 -&gt; range of 15-20), as factors ----\n  mutate(c1990 = cut(Y1990, breaks = c(0,1,2,5,10,15,20,25)), \n         c2019 = cut(Y2019, breaks = c(0,1,2,5,10,15,20,25))) %&gt;% \n  \n  # use regular expressions (regex) to separate the lower and upper range values ----\n  mutate(sep1990 = str_match(c1990, \"^\\\\(([0-9]+),([0-9]+)]$\"), \n         sep2019 = str_match(c2019, \"^\\\\(([0-9]+),([0-9]+)]$\")) %&gt;%\n  \n  # use regex to create nicely-formatted percentage ranges ----\n  mutate(c1990 = glue::glue(\"{sep1990[,2]}% to {sep1990[,3]}%\"), \n         c2019 = glue::glue(\"{sep2019[,2]}% to {sep2019[,3]}%\")) %&gt;% \n  \n  # reorder factors in the c1990 & c2019 cols by values in the `sep1990[,2]` & `sep2019[,2]` columns ----\n  mutate(c1990 = fct_reorder(c1990, parse_number(sep1990[,2])), \n         c2019 = fct_reorder(c2019, parse_number(sep2019[,2]))) %&gt;%\n  \n  # reverse the order of factors (low &gt; high) in c1990 & c2019 cols ----\n  mutate(c2019 = fct_rev(c2019),\n         c1990 = fct_rev(c1990)) \n\n#......ANNOTATE (generally, what does this code block do?).......\n# ANNOTATE (briefly explain this line of code) ----\nhisto_evolution &lt;- ggplot(data = histo_evolution_df) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_histogram(aes(x = c1990), stat = \"count\", alpha = 0) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  annotate(\"rect\", xmin = 4.5 ,xmax = 7.6, ymin = 0, ymax = 36, fill = \"#e1e1e1\", alpha = 0.5) +\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  annotate(\"text\", x = 5, y = 25, label = \"0% to 5%\", color = \"grey60\", family = \"Oswald\", size = 5, fontface = \"bold\") +\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_histogram(aes(x = c1990, fill = continent), stat = \"count\", alpha = 0.3) +\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_histogram(aes(x = c2019, fill = continent), stat = \"count\", width = 0.5) +\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  scale_fill_manual(values = rev(pal)) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  coord_flip() + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  facet_wrap(~continent, ncol = 5) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  guides(fill = \"none\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  labs(caption = \"Number of country for each range of percentage of death from indoor air pollution.\\nThe light bars represent the distribution in 1990 and the dark and narrow bars represent the distribution in 2019.\\nThe bin from 0% to 5% is splitted in 3 differents bins (0% to 1%, 1% to 2% and 2% to 3%) to give more detail for the countries\\n which reached a low level of death, while the other bins represent 5% range.\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  theme_void() + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  theme(axis.text.x = element_text(margin = margin(t = 5, r = 0, b = 0, l = 0), family = \"roboto condensed\", color = \"grey30\", size = 12), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        axis.text.y = element_text(family = \"roboto condensed\", color = \"grey30\", size = 12),\n        \n        # ANNOTATE (briefly explain this line of code) ----\n        panel.grid.major.x = element_line(color = \"grey60\", linetype = \"13\"), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        panel.spacing.x = unit(8, \"mm\"), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        strip.text = element_blank(), \n        \n        # ANNOTATE (briefly explain this line of code) ----\n        plot.caption = element_text(family = \"roboto\", size = 12, color = \"black\", hjust = 0, margin = margin(t = 25, l = 40), lineheight = 1.1)) \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                              6. build legends                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#......ANNOTATE (generally, what does this code block do?).......\nlegend_df &lt;- tibble(pos = c(0, 2, 4, 6, 8),\n                    country = sort(unique(fuel_gdp_clean$continent)))\n\n#......ANNOTATE (generally, what does this code block do?).......\n# ANNOTATE (briefly explain this line of code) ----\nlegend &lt;- ggplot(data = legend_df) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_rect(aes(xmin = pos, xmax = pos + 1, \n                ymin = 0.35, ymax = 0.75, fill = country), size = 6) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  geom_text(aes(x = pos + 0.5, y = 0.45, label = country), \n            family = \"oswald\", color = \"white\", size = 6, \n            hjust = 0.5, vjust = 0, fontface = \"bold\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  scale_fill_manual(values = rev(pal)) +\n  \n  # ANNOTATE (briefly explain this line of code) ----\n  scale_y_continuous(limits = c(0,1)) + \n  scale_x_continuous(limits = c(0,9)) + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  guides(color = \"none\", fill = \"none\") + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  theme_void() \n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##              7. assemble all plot components using {patchwork}           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n## NOTE: this plot may not look correct when opened in the Viewer! You'll need to save a PNG (in part 8, below) to view it correctly ##\n\n# ANNOTATE (briefly explain this line of code) ----\nfinal_plot &lt;- connected_scatterplot / legend / histo_evolution + \n  \n  # ANNOTATE (briefly explain this line of code) ----\n  plot_layout(heights = c(3, 0.5, 1)) + \n  \n  ## ANNOTATE (briefly explain these lines of code) ----\n  plot_annotation( \n  caption = \"Visualization: Christophe Nicault | Data: Our world in Data\",\n  title = \"Evolution of deaths from indoor air pollution\",\n  subtitle = str_wrap(\"The percentage of death from indoor air pollution decreased in many countries in the last 30 years, due to a better access to clean fuel for cooking. However there are inequalities with many countries still lacking access, particularly in Africa, Oceania and Asia.\", 100),\n  \n  # ANNOTATE (briefly explain these lines of code) ----\n  theme = theme( \n    plot.margin = margin(10,10,5,10),\n    plot.title = element_text(family = \"khula\", size = 22, color = \"#02403A\", face = \"bold\", hjust = 0.5, margin = margin(5,0,10,0)),\n    plot.subtitle = element_text(family = \"khula\", size = 14, color = \"black\", hjust = 0.5, margin = margin(10,0,20,0)),\n    plot.caption = element_text(family = \"techmono\", size = 11, color = \"#02403A\", hjust = 0.95, margin = margin(20,0,5,0))   \n  )\n)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            8. save plot as a PNG                         ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#........open plotting device to draw plot to a PNG file.........\n# specify file path/name and png resolution & size\nragg::agg_png(here::here(\"outputs\", paste0(\"indoor_pollution_\", format(Sys.time(), \"%Y%m%d_%H%M%S\"), \".png\")), \n              res = 320, width = 12, height = 13, units = \"in\")\n\n#................plot object that you want to draw...............\nfinal_plot\n\n#....................turn off plotting device....................\n# once off, you should see your .png file appear in outputs/ folder\ndev.off()\n\n\n\n\n(Part 1b) Once complete, answer the following questions:\n\n1. Describe two elements of this plot that you find visually-pleasing / easy to understand / intuitive. Why? (4-10 sentences)\n2. Describe two elements of this plot that you feel could be better presented in a different way. Why? (4-10 sentences)\n3. Describe two new things that you learned by interpreting / annotating this code. These could be packages, functions, or even code organizational approaches that you hadn’t previously known about or considered. (4-10 sentences)"
  },
  {
    "objectID": "assignments/HW1.html#rubric-specifications",
    "href": "assignments/HW1.html#rubric-specifications",
    "title": "Assignment #1 (HW #1)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for Assignment #1, Part I:\nComplete the following steps in your GitHub Classroom repo (eds240-hw1-USERNAME/Part1.qmd):\n\ninclude your preferred name, and if you feel comfortable, your preferred pronouns in the author field of the Part1.qmd YAML\nupdate each comment line in the code that reads, ANNOTATE, with a brief description, written in your own words (see lines 114 & 120 for example annotations; there are other lines that have been already annotated for you as well – you do not need to re-write these annotations – you are allowed up to five incorrect or missing annotations\nleave the code chunk options set to eval: false and echo: true\nanswer all three Part 1b questions adhering to the length requirements specified at the end of each question prompt\nwe (your instructors) should be able to successfully render Part1.qmd locally without errors, however do not push any html files to GitHub (i.e. Part1.html and Part1_files/; consider adding these to your .gitignore so that you don’t accidentally push them)\npush your completed Part1.qmd to GitHub via GitHub Classrooms by 11:59pm PT on Sat 01/20/2024\n\n\n\n End Part I"
  },
  {
    "objectID": "assignments/HW1.html#learning-outcomes-1",
    "href": "assignments/HW1.html#learning-outcomes-1",
    "title": "Assignment #1 (HW #1)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nNote: This part of HW #1 is the first step in working towards your final course assignment (we’ll be breaking it down a bit, week-by-week). Your final assignment is meant to combine nearly all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\n\nThis week, we’ll mostly be focused on some prep work. Read the description, below, for details."
  },
  {
    "objectID": "assignments/HW1.html#description-1",
    "href": "assignments/HW1.html#description-1",
    "title": "Assignment #1 (HW #1)",
    "section": "Description",
    "text": "Description\nA small part of each homework assignment will be dedicated to working on a series of data visualizations which will be due as part of Assignment #4 at the end of the quarter. Assignment #4 will ask you to build three related, but different data visualizations – all which will use the same data set(s), but present those data differently for three different audiences / purposes:\n\na visualization for a general audience (i.e. without domain expertise) – this data visualization may be designed to prompt conversation, clearly display findings (without the use of jargon), display findings in an atypical but creative way, and / or may blend both art and science\na visualization to be included in a paper, technical documentation, or report – this visualization should tell a story, but can include much more detail, more data, more domain-specific language, etc.\na visualization that you could include in a presentation – you might imagine an audience with familiarity with your domain, but they only have a brief amount of time to process the information being presented; key takeaways should be clearly highlighted, and you may have multiple versions, each with an added layer (as if you’re animating pieces of your visualization onto a slide)\n\nThis week, you’ll focus on finding data that interest you and begin brainstorming some questions that you might explore / answer using those data.\nYour data set(s) may be related to a past project, or even your current Capstone or GP. It may also be a completely new data set(s), unrelated to anything you’re currently working on. Explore the Data sources section of the course website’s resources page if you need some inspiration on where to start (you are not limited to just these data sources):\n\n\n\n\nOnce you’ve found your data set(s), answer the following questions:\n\n1. Describe your data set(s). Be sure to address the following (&lt;=4 sentences)\n\n1a. Where did you find these data?\n1b. What variables do these data contain? Is there sufficient metadata for understanding what those variables are?\n\n2. What steps are involved in downloading or accessing the data (e.g. “I can download using a button via this online portal,” “There’s an R package for scraping the data,” “I need to use an API to scrape the data,” etc.)? (1-2 sentences)\n3. What question(s) do you want to answer using these data (it’s okay if these questions evolve over time, this is just a starting point)? (&lt;=4 sentences)\n4. Will you need to combine multiple data sets to successfully answer your question(s)? If so, have you found all the necessary data? Do you have a way to combine it (e.g. matching key values across all data sets)? (&lt;=4 sentences)\nOptional: Import your data into R! (this will be a part of the next homework assignment) IMPORTANT: If your data files are large (&gt;2GB) DO NOT push your data to GitHub – instead, add your data file(s) or entire data folder to your .gitignore (you’ll practice this in Discussion section this week)."
  },
  {
    "objectID": "assignments/HW1.html#rubric-specifications-1",
    "href": "assignments/HW1.html#rubric-specifications-1",
    "title": "Assignment #1 (HW #1)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for Assignment #1, Part II:\nComplete the following step under your own personal GitHub profile, not in GitHub Classrooms:\n\ncreate a GitHub repository named lastName-eds240-HW4, which is where you’ll be doing any / all work related to Assignment #4. Be sure to make your repository public, initialize your repository with a README, and add a .gitignore file.\nadd Sam and Sevan as collaborators on your repo (on GitHub: Settings &gt; Collaborators &gt; Add people; our user names are samanthacsik and SevanEsaian)\nadd your repository’s URL next to your name on this Google Sheet\n\nComplete the following steps in your GitHub Classroom repo (eds240-hw1-USERNAME/Part2.qmd):\n\nlink to (or otherwise prove the existence of) at least one data set that you plan to use for Assignment #4\nanswer all parts of the four concluding questions, adhering to the length requirements specified at the end of each question prompt; you do not need to complete the optional importing of data – if you do want to practice importing your data, be sure to do so in your lastName-eds240-HW4 repository\nwe (your instructors) should be able to successfully render Part2.qmd locally without errors, however do not push any html files to GitHub (i.e. Part2.html and Part2_files/; consider adding these to your .gitignore so that you don’t accidentally push them) – only push Part2.qmd\npush your completed Part2.qmd to GitHub via GitHub Classrooms by 11:59pm PT on Sat 01/20/2024\n\n\n\n End Part II"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Earning “Satisfactory” marks on Self-reflections (SRs) and Homework Assignments (HWs) will determine your letter grade (e.g. A, B, etc.) for this course.\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nSR\nPre-course reflection (SR #1)\nMon 01/08/2024\nSat 01/13/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #1\nMon 01/08/2024\nSat 01/20/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #2\nMon 01/22/2024\nSat 02/03/2024, 11:59pm PT\n\n\nSR\nMid-course reflection (SR #2)\nMon 02/05/2024\nSat 02/10/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #3\nMon 02/12/2024\nSat 02/24/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #4\nMon 02/26/2024\nSat 03/09/2024, 11:59pm PT\n\n\nSR\nEnd-of-course reflection (SR #3)\nMon 03/11/2024\nSat 03/16/2024, 11:59pm PT"
  },
  {
    "objectID": "assignments.html#assignments",
    "href": "assignments.html#assignments",
    "title": "Assignments",
    "section": "",
    "text": "Earning “Satisfactory” marks on Self-reflections (SRs) and Homework Assignments (HWs) will determine your letter grade (e.g. A, B, etc.) for this course.\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nSR\nPre-course reflection (SR #1)\nMon 01/08/2024\nSat 01/13/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #1\nMon 01/08/2024\nSat 01/20/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #2\nMon 01/22/2024\nSat 02/03/2024, 11:59pm PT\n\n\nSR\nMid-course reflection (SR #2)\nMon 02/05/2024\nSat 02/10/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #3\nMon 02/12/2024\nSat 02/24/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #4\nMon 02/26/2024\nSat 03/09/2024, 11:59pm PT\n\n\nSR\nEnd-of-course reflection (SR #3)\nMon 03/11/2024\nSat 03/16/2024, 11:59pm PT"
  },
  {
    "objectID": "assignments.html#end-of-class-surveys",
    "href": "assignments.html#end-of-class-surveys",
    "title": "Assignments",
    "section": "End-of-class surveys",
    "text": "End-of-class surveys\nEnd-of-class surveys (EOCs) will become available at the end of each class (Mondays) and are due by end-of-day (11:55pm PT). Completing EOCs by the due dates / times will, in-part (along with class attendance), determine whether you earn a +/- on your course grade.\n\n\n\nEOC link\nDate Assigned\nDate Due\n\n\n\n\nEOC (week 1)\nMon 01/08/2024\nMon 01/08/2024, 11:55pm PT\n\n\nNo lecture or EOC (week 2)\nNA\nNA\n\n\nEOC (week 3)\nMon 01/22/2024\nMon 01/22/2024, 11:55pm PT\n\n\nEOC (week 4)\nMon 01/29/2024\nMon 01/29/2024, 11:55pm PT\n\n\nEOC (week 5)\nMon 02/05/2024\nMon 02/05/2024, 11:55pm PT\n\n\nEOC (week 6)\nMon 02/12/2024\nMon 02/12/2024, 11:55pm PT\n\n\nNo lecture or EOC (week 7)\nNA\nNA\n\n\nEOC (week 8)\nMon 02/26/2024\nMon 02/26/2024, 11:55pm PT\n\n\nEOC (week 9)\nMon 03/04/2024\nMon 03/04/2024, 11:55pm PT\n\n\nEOC (week 10)\nMon 03/11/2024\nMon 03/11/2024, 11:55pm PT"
  },
  {
    "objectID": "assignments.html#grade-tracker",
    "href": "assignments.html#grade-tracker",
    "title": "Assignments",
    "section": "Grade Tracker",
    "text": "Grade Tracker\nUse the Grade Tracker, below, to determine your course grade:\n\n\n\n\n\n\n\n\n\nRedeem tokens in exchange for assignment extensions, missing class, or to revise / resubmit an assignment that received a “Not Yet” mark."
  },
  {
    "objectID": "assignments/SR1-precourse.html",
    "href": "assignments/SR1-precourse.html",
    "title": "Pre-course reflection (SR #1)",
    "section": "",
    "text": "In this assignment, you’ll introduce yourself, come up with a plan for what you’d like to get out of the class, and roughly outline how you’ll accomplish your goals throughout the quarter. You’ll continue visiting the goals you set for yourself in this assignment throughout the quarter, so it’s worthwhile to be reflective!\nBecause everyone is participating under unique circumstances, I want to learn about your learning contexts. I can best support you in this class if you address the following:\n\nSome questions about school and life:\n\nWhere are you coming from (e.g. “I recently finished my undergraduate degree”, “I’ve been working in industry X for Y years”) (1-2 sentences)\nWhat do you hope to get out of this class? (3-4 sentences)\nIf you have a particular career goal in mind, how does this course apply to your future career, if at all? (1-3 sentences)\nWhat do you wish your instructors knew about you, but don’t? (2-4 sentences)\n\nSome questions about the way you like to learn:\n\nWhat kinds of assignments, skills, or behaviors have you felt most comfortable with / enjoy from past classes? Why do you enjoy them? (4-5 sentences)\nHow confident do you feel in your data visualization skills? Why? (3-4 sentences)\nHow confident do you feel in your coding skills (primarily R, but feel free to elaborate on any of the languages you’ve used)? Why? (3-4 sentences)\nWhat have you struggled with in the past in other graduate-level courses? Why? (3-4 sentences)\nOf the courses you’re taking this quarter, which do you expect to be the most challenging? Most demanding? (1-2 sentences)\nWhat responsibilities do you have outside of school, and how do you want to balance them? (3-4 sentences)\nWhich learning goals from the syllabus are you most excited about? (3-4 sentences)\nMost importantly, how do you plan on accomplishing your learning goals for this course? Note: be specific here! Instead of writing, “I will complete homework assignments” or “I will study”, you can make these more specific strategies: “I will create a schedule to map out assignments“ (elaborate on this), “I will use the homework assignments as opportunities to practice X,” I will communicate with classmates to ask for help after trying X,” “I will participate in online learning communities, such as TidyTuesday…” etc. (5-8 sentences)\n\nSome fun questions:\n\nWhat activity(ies) (outside of school / work) brings you the most joy? How do you plan to incorporate that activity into your schedule this quarter (if at all)? If you are unable to do so, is there something else you can plan to do that will bring you similar joy? (3-5 sentences)\nWhat is a piece of media you enjoyed recently? (e.g. music, book, movie, tweet, meme) (2-4 sentences)"
  },
  {
    "objectID": "assignments/SR1-precourse.html#description",
    "href": "assignments/SR1-precourse.html#description",
    "title": "Pre-course reflection (SR #1)",
    "section": "",
    "text": "In this assignment, you’ll introduce yourself, come up with a plan for what you’d like to get out of the class, and roughly outline how you’ll accomplish your goals throughout the quarter. You’ll continue visiting the goals you set for yourself in this assignment throughout the quarter, so it’s worthwhile to be reflective!\nBecause everyone is participating under unique circumstances, I want to learn about your learning contexts. I can best support you in this class if you address the following:\n\nSome questions about school and life:\n\nWhere are you coming from (e.g. “I recently finished my undergraduate degree”, “I’ve been working in industry X for Y years”) (1-2 sentences)\nWhat do you hope to get out of this class? (3-4 sentences)\nIf you have a particular career goal in mind, how does this course apply to your future career, if at all? (1-3 sentences)\nWhat do you wish your instructors knew about you, but don’t? (2-4 sentences)\n\nSome questions about the way you like to learn:\n\nWhat kinds of assignments, skills, or behaviors have you felt most comfortable with / enjoy from past classes? Why do you enjoy them? (4-5 sentences)\nHow confident do you feel in your data visualization skills? Why? (3-4 sentences)\nHow confident do you feel in your coding skills (primarily R, but feel free to elaborate on any of the languages you’ve used)? Why? (3-4 sentences)\nWhat have you struggled with in the past in other graduate-level courses? Why? (3-4 sentences)\nOf the courses you’re taking this quarter, which do you expect to be the most challenging? Most demanding? (1-2 sentences)\nWhat responsibilities do you have outside of school, and how do you want to balance them? (3-4 sentences)\nWhich learning goals from the syllabus are you most excited about? (3-4 sentences)\nMost importantly, how do you plan on accomplishing your learning goals for this course? Note: be specific here! Instead of writing, “I will complete homework assignments” or “I will study”, you can make these more specific strategies: “I will create a schedule to map out assignments“ (elaborate on this), “I will use the homework assignments as opportunities to practice X,” I will communicate with classmates to ask for help after trying X,” “I will participate in online learning communities, such as TidyTuesday…” etc. (5-8 sentences)\n\nSome fun questions:\n\nWhat activity(ies) (outside of school / work) brings you the most joy? How do you plan to incorporate that activity into your schedule this quarter (if at all)? If you are unable to do so, is there something else you can plan to do that will bring you similar joy? (3-5 sentences)\nWhat is a piece of media you enjoyed recently? (e.g. music, book, movie, tweet, meme) (2-4 sentences)"
  },
  {
    "objectID": "assignments/SR1-precourse.html#rubric-specifications",
    "href": "assignments/SR1-precourse.html#rubric-specifications",
    "title": "Pre-course reflection (SR #1)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for this Pre-course reflection:\nComplete the following steps in your GitHub Classroom repo (eds240-sr1-USERNAME/SR1-precourse-reflection.qmd):\n\ninclude your preferred name, and if you feel comfortable, your preferred pronouns in the author field of the SR1-precourse-reflection.qmd YAML\nanswer all questions above, adhering to the length requirements specified at the end of each question prompt\nwe (your instructors) should be able to successfully render SR1-precourse-reflection.qmd locally without error, however do not push any html files to GitHub (i.e. SR1-precourse-reflection.html and SR1-precourse-reflection_files/; consider adding these to your .gitignore so that you don’t accidentally push them)\npush your completed SR1-precourse-reflection.qmd to GitHub via GitHub Classrooms by 11:59pm PT on Sat 01/13/2024"
  },
  {
    "objectID": "assignments/HW2.html",
    "href": "assignments/HW2.html",
    "title": "Assignment #2 (HW #2)",
    "section": "",
    "text": "You must earn a “Satisfactory” mark for each individual Part (I and II) to earn a “Satisfactory” mark for Assignment #2.\nNOTE: Assignments are to be submitted via GitHub Classrooms, unless otherwise noted. Each student receives one “free pass” for not submitting assignments via specified channels, after which you will receive a “Not Yet” mark.\nRead each part of the assignment carefully, and use the check boxes to ensure you’ve addressed all elements of the assignment!"
  },
  {
    "objectID": "assignments/HW2.html#learning-outcomes",
    "href": "assignments/HW2.html#learning-outcomes",
    "title": "Assignment #2 (HW #2)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing, visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages"
  },
  {
    "objectID": "assignments/HW2.html#description",
    "href": "assignments/HW2.html#description",
    "title": "Assignment #2 (HW #2)",
    "section": "Description",
    "text": "Description\nIn class, we discussed strategies and considerations for choosing the right graphic form to represent your data and convey your intended message. Here, you’ll apply what we’ve learned to a data set on lobster abundance and sizes, collected from coastal rocky reef sites within the Santa Barbara Coastal LTER. Unfold the following note to read more about the data before continuing on (collapsed to save space):\n\n\n\n\n\n\nLearn about the data:\n\n\n\n\n\n\nAbout SBC LTER\nThe Santa Barbara Coastal Long Term Ecological Research (SBC LTER) site was established in 2000 as part of the LTER Network to understand the ecology of coastal kelp forest ecosystems. Research and long-term ecological and environmental monitoring data is collected within a 10,000 square kilometer area of the northern portion of the Southern California Bight, which includes the Santa Barbara Channel, coastal watersheds, small estuaries, and sandy beaches that border the Channel. You can explore the full data catalog.\n\n\nAbout the data set\nThere are five coastal rocky reef research sites at which the SBC LTER collects long-term monitoring data:\n\nNaples Reef (NAPL)\nIsla Vista Reef (IVEE)\nArroyo Quemado Reef (AQUE)\nMohawk Reef (MOHK)\nCarpinteria Reef (CARP)\n\nIn January 2012, Naples Reef and Isla Vista Reef were designated as Marine Protected Areas (MPAs), prohibiting any future take of lobsters (along with other living marine resources). Since then, the SBC LTER has conducted annual (late summer) benthic surveys at each of the above five sites, where SCUBA divers record lobster abundance and sizes. Explore the metadata for more information.\n\n\nData citation\nReed, D, R. Miller. 2023. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012 ver 9. Environmental Data Initiative. https://doi.org/10.6073/pasta/3595322687af94cd532620ad9db94c77.\n\n\nFinding this data set\nKnowing how to search for data can be tricky! Here’s how I accessed this particular data set, should you want to search for LTER data yourself, in the future:\n\nFilter the SBC LTER Data Catalog for data sets related to Reef/Kelp Forest habitats (check the box next to the habitat type of interest, or filter by measurement type or LTER Core Research Area). This produces a table of data collections, descriptions, and links to individual data and metadata records.\nChoose a data set of interest. I was interested in the SBC LTER: Spiny lobster in California Collection, which includes three different data sets. I specifically chose, Lobster abundace, size, and fishing pressure – here, you’ll find lots of metadata, including people and organizations involved in this data collection, temporal, geographic, and taxonomic coverage, methods and protocols, and links to data files. Additionally, you’ll see a link to the EDI Data Portal (top right corner), which is the data repository that maintains all data and metadata produced by the LTER. EDI assigns a DOI (Digital Object Identifier) to each version of a data package (data package = data + metadata; SBC LTER updates this data set each year when new data is collected – each update receives a new DOI).\nDownload or import the data. You can download the data file from either the SBC LTER Data Catalog or the EDI Data Package. However I prefer reading in the data directly from online (that way, I don’t need to worry about storing large data files). I recommend doing this from the EDI Data Package (rather than the SBC LTER Data Catalog), since the DOI ensures you can re-reference the exact same version, even after the data set is updated with new data (SBC LTER Data Catalog only has a download link for the most up-to-date version of the data). To do so, right click on the Download Data button, then select Copy Link Address.\n\n\n\n\n\n\n\n\n\n\nUse this url inside read_csv() to import the data into your script or Qmd / Rmd file:\n\nlobster_data &lt;- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.77.9&entityid=f32823fba432f58f66c06b589b7efac6\")\n\n\n\n\n\nYour goal is to create a visualization that explores how lobster size differs across each of the five coastal rocky reef SBC LTER sites for the years 2012 (when IVEE and NAPL were established as MPAs) and 2022 (10 years later).\nThis will first require some data exploration and wrangling. Some tips (unfold below):\n\n\n\n\n\n\nData exploration & wrangling tips\n\n\n\n\n\nData exploration tips:\n\nUse glimpse() and / or str() to check out your variables and data types\nUse names() to return all column names\nExtract unique elements using unique(df$column_name)\nOpen up the spreadsheet-style data viewer using View(df)\nBe sure to review the metadata (including methods & protocols) to fully understand the data\n\nData wrangling tips:\n\nI love starting all my cleaning pipelines with janitor::clean_names() to convert column headers into lowercase snake_case (not necessary, but easy to implement and super helpful for yourself and others)\nYou’ll want to keep just the years of interest\nMissing size measurements are denoted with -99999 – you do not want to leave those values as-is (what’s a lobster with -9999 mm carapace length?? ); consider how to deal with these\nEach row is not always a single observation, but rather summed lobster counts at each size observed within a site / transect / replicate. You’ll want to wrangle the data such that each row represents a single lobster observation. You may need to do some Googling to figure out a solution for this (HINT: you’re looking to perform the opposite of count()).\nI often find that I’ll need to return to my data wrangling pipeline again after I start plotting my data – it’s at this stage that I’ll often catch variables that are the wrong data type (e.g. numeric, factor, character) for plotting and need to make the appropriate updates.\n\n\n\n\n(Part 1a) After exploring and wrangling your data, answer the following questions:\n\n1. What are your variables of interest and what kinds of data (e.g. numeric, categorical, ordered, etc.) are they? (a bullet point list here is fine)\n2. Using From Data to Viz, identify which graphic forms / geoms are appropriate, given your data. List them out. (a bullet point list here is fine)\n3. Now that you have a list of options, what are some of your considerations as you decide which type of graph create? For example, is it important / valuable to show sample size? Why or why not? How will you represent multiple groups? etc. (3-4 sentences)\n\nNow that you’ve explored and starting wrangling your data, it’s time to create some plots. It’s often important to try out multiple graphic forms (e.g. geom_*()s) as you decide which is the most effective way of presenting your data. This process is commonly referred to as Exploratory Data Analysis or Exploratory Data Visualization. Some tips (unfold below):\n\n\n\n\n\n\nData viz creation tips\n\n\n\n\n\nData viz creation tips:\n\nI always find it helpful to sketch things out on paper first\nThere’s no need to create anything special or particularly visually-pleasing during this exploratory visualization phase. It can be helpful to make minor modifications, (e.g. rearranging groups in a logical order, color groups, etc.) to help you identify any emerging patterns\nWe created a number of different plot types together in class, exploring different geoms and some of the arguments that each ggplot layer can take. Be sure to take a look back at the lecture materials, but also know that you may need to reference documentation and / or online examples to create / modify your intended visualizations.\n\n\n\n\n(Part 1b) Complete the following:\n\nCreate at least three different plots as part of your exploratory data visualization phase to test out which graphic forms / geoms works best. Your last plot should be the version that you feel is best suited for presenting your data. (NOTE: Your first two plots do not need to be at all polished – during the exploratory data visualization phase, we’re most concerned with choosing a graphic form / geom(s) for effectively presenting our data.)\n1. Consider all three of your plots. What about the graphic forms / geoms used in plots #1 and #2 was not as effective as plot #3? Justify your decision to pursue plot #3. (5-8 sentences)\n2. (For plot #3 only) Consider modifications that we discussed in lecture that may make this plot easier to interpret (e.g. updating colors, moving or removing legends, highlighting groups, ordering groups) – be sure to update your plot as appropriate, then explain why you chose to make the above modifications. If you chose not to make any of these modifications, why not? (2-5 sentences)\n3. Polish your third (final) plot by updating the labels and theme (we’ll cover theme modifications during week 4 discussion section, so you may consider waiting until then). List out the changes you made to your plot’s theme (e.g. “updated axis text size”, “removed minor gridlines”, etc.). (a bullet list here is fine)\n4. Describe two or more challenges you encountered while deciding on / creating your plots – these can be conceptual (e.g. challenges in determining how to best represent your data) and / or technical (e.g. code-based challenges). (4-8 sentences)\n5. Add alt text to your final visualization following the formula discussed during week 2’s discussion section and using the #| fig-alt: code chunk option."
  },
  {
    "objectID": "assignments/HW2.html#rubric-specifications",
    "href": "assignments/HW2.html#rubric-specifications",
    "title": "Assignment #2 (HW #2)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for Assignment #2, Part I:\nComplete the following steps in your GitHub Classroom repo (eds240-HW2/Part1.qmd):\n\ninclude your preferred name, and if you feel comfortable, your preferred pronouns in the author field of the Part1.qmd YAML\nanswer the three Part 1a questions, adhering to the length requirements specified at the end of each question prompt\ncreate three different plots (two unpolished exploratory data visualizations and one polished final plot) in accordance with Part 1b instructions (NOTE: there isn’t necessarily a single correct answer here, but your final plot should clearly display the variables of interest and you should be able to justify your choice in your written responses)\ncode should be clearly organized and annotated following conventions and guidelines outlined in the Writing clean code page on the course website\nanswer the five Part 1b questions, adhering to the length requirements specified at the end of each question prompt\nadd alt text to your final visualization in accordance with Part 1b instructions\nwe should be able to run individual lines / chunks of code and render Part1.qmd without errors\nall three plot outputs should appear in your rendered doc\npush your completed Part1.qmd to GitHub via GitHub Classrooms by 11:59pm PT on Sat 02/03/2024\n\n\n\n End Part I"
  },
  {
    "objectID": "assignments/HW2.html#learning-outcomes-1",
    "href": "assignments/HW2.html#learning-outcomes-1",
    "title": "Assignment #2 (HW #2)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nNote: This part of HW #2 is a continuation of HW #1, Part II and is the next step in working towards your final course assignment. Your final assignment is meant to combine nearly all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\n\nRead the description, below, for details on what to work on this week."
  },
  {
    "objectID": "assignments/HW2.html#description-1",
    "href": "assignments/HW2.html#description-1",
    "title": "Assignment #2 (HW #2)",
    "section": "Description",
    "text": "Description\nA small part of each homework assignment will be dedicated to working on a series of data visualizations which will be due as part of Assignment #4 at the end of the quarter. Assignment #4 will ask you to build three related, but different data visualizations – all which will use the same data set(s), but present those data differently for three different audiences / purposes:\n\na visualization for a general audience (i.e. without domain expertise) – this data visualization may be designed to prompt conversation, clearly display findings (without the use of jargon), display findings in an atypical but creative way, and / or may blend both art and science\na visualization to be included in a paper, technical documentation, or report – this visualization should tell a story, but can include much more detail, more data, more domain-specific language, etc.\na visualization that you could include in a presentation – you might imagine an audience with familiarity with your domain, but they only have a brief amount of time to process the information being presented; key takeaways should be clearly highlighted, and you may have multiple versions, each with an added layer (as if you’re animating pieces of your visualization onto a slide)\n\n(Part 2a) This week, you’ll focus on importing / wrangling / and beginning the exploratory data visualization phase, using the data you found as part of HW #1, Part II. Complete the following:\n\nCreate an file named, HW2-exploration.qmd within your lastName-eds240-HW4 repo and add appropriate YAML fields\nLoad necessary packages and read in your data\nClean & wrangle your data\nCreate at least three (but of course feel free to create more!) exploratory visualizations (similar to plot #1 and #2 in Part I of this assignment).\nIMPORTANT: If you have a downloaded data file saved to your repo (e.g. you’re not reading in your data directly from online, from a server, etc.) be sure to add your data folder / file to your .gitignore, particularly if this file is large.\n\n(Part 2b) After completing the above steps, answer the following questions:\n\n1. What have you learned about your data? Have any potentially interesting patterns emerged? (5-8 sentences)\n2. In HW #1, you outlined some questions that you wanted to answer using these data. Have you made any strides towards answering those questions? If yes, how so? If no, what next steps do you need to take (e.g. I need to create X plot type, I still need to track down Y data, I need to restructure existing data so that you can visualize it in Z ways, etc.)? (8-12 sentences)\n3. What challenges do you foresee encountering with your data? These can be data wrangling and / or visualization challenges. (4-6 sentences)"
  },
  {
    "objectID": "assignments/HW2.html#rubric-specifications-1",
    "href": "assignments/HW2.html#rubric-specifications-1",
    "title": "Assignment #2 (HW #2)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for Assignment #2, Part II:\nComplete the following steps under your lastName-eds240-HW4 repo, not in GitHub Classrooms:\n\nperform all Part 2a steps, as described above, in HW2-exploration.qmd\nanswer Part 2b questions, also in HW2-exploration.qmd, adhering to the length requirements specified at the end of each question prompt\nall three plot outputs should appear in your rendered doc\nHW2-exploration.qmd should be neatly organized – this does not need to be a perfectly polished document, but sections should be clearly labeled with prose and / or annotations so that we can easily follow along.\npush your completed HW2-exploration.qmd to your repo by 11:59pm PT on Sat 02/03/2024\n\n\n\n End Part II"
  },
  {
    "objectID": "assignments/HW4.html",
    "href": "assignments/HW4.html",
    "title": "Assignment #4 (HW #4)",
    "section": "",
    "text": "Your final assignment is meant to combine all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\nassess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "assignments/HW4.html#learning-outcomes",
    "href": "assignments/HW4.html#learning-outcomes",
    "title": "Assignment #4 (HW #4)",
    "section": "",
    "text": "Your final assignment is meant to combine all of the course learning outcomes(!):\n\nidentify which types of visualizations are most appropriate for your data and your audience\nprepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nbuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nwrite code from scratch and read and adapt code written by others\napply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\nassess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "assignments/HW4.html#description",
    "href": "assignments/HW4.html#description",
    "title": "Assignment #4 (HW #4)",
    "section": "Description",
    "text": "Description\nChoose to complete one of the two options below:\n\nOPTION 1:\nBuild three separate visualizations – all three should feature the same data which are used to answer the same (single) question, but present those data differently for three different target audiences / purposes:\n\na visualization for a general audience (i.e. without domain expertise) – this data visualization may be designed to prompt conversation, clearly display findings (without the use of jargon), display findings in an atypical but creative way, and / or may blend both art and science\na visualization to be included in a paper, technical documentation, or report – this visualization should tell a similar story, but can include much more detail, more data, more domain-specific language, etc.\na visualization that you could include in a presentation – presenting data on slides often requires a slightly different approach – we ask a lot of an audience (regardless of their familiarity with your domain) when we spend only ~60 sec on any given slide. It’s often imperative to build up your visualizations, slide-by-slide, adding data layers bit-by-bit. Oftentimes, you will only present a subset of data on any given figure. Key takeaways should be clearly highlighted. For this visualization, consider how you would layer on data and what arrows / annotations you’d potentially animate in to make your messaging clear.\n\nWe’ve seen a lots of amazing visualizations throughout the quarter. Be sure to take a look through past lectures, and definitely check out the resources page to see work from some of my favorite data viz creators. Here are just a few cool / helpful pieces to get the creative thoughts flowing:\nThe following examples fall into the first cateogry, above (for a general audience):\n\nThe Rise of Craft Beer!, by Cédric Scherer (this is an awesome example of how a relatively simple graphic form (i.e. a bar chart) can be made into an engaging piece for a general audience)\nSeasonality of Bird Collisions in Chicago, by Jake Kaupp\nRatings of Japanese Instant Shio Ramen, by Georgios Karamanis\nA is for Actrapid, Z is for Zyprexa, by Georgios Karamanis\nThe Rise of Adobe Inc., by Nicola Rennie (Nicola also records all of her tidytuesday contributions using the {camcorder} package))\n\nThese are two excellent examples of how you might adapt a publication-worthy visualization for an oral presentation (categories two and three, above):\n\nAlex Phillips’ Ten Tips for Presentations lecture features a visualization from Rougier et al. 2014\nSciFig’s Spectrum of Figure Creation (you’ll need to expand the Details drop-down)\n\n\n\nOPTION 2:\nBuild a cohesive infographic-style visualization that includes at least three different, but complementary visualizations that work together to tell a complete story. You should have one overarching question with (at least) three sub-questions which are addressed using each of the component pieces of the infographic.\nAn infographic typically exists to address one overarching question or idea, and it’s subcomponents (e.g. visualizations, numbers, imagery) each help to tell part of the story (or in other words, help to answer sub-questions). While text is important in all visualizations, it can be particularly critical in weaving together all your infographic elements to successfully convey your story. The order and orientation in which your elements are positioned will also be essential for creating a visual hierarchy that successfully guides your readers. Packages like {patchwork} will likely be critical in stitching together the different elements of your infographic.\nI encourage you to look back at past lecture materials and to check out the resources page to explore the works of some really cool data viz creators. Here are a just a few examples of infographic-style visualizations (created using {ggplot2} + extension packages) to get you thinking about the possibilities:\n\nUFO Sightings, by Dan Oehm\nNumbats, by Dan Oehm\nHaunted Places, by Dan Oehm\nSchool Diversity, by Cédric Scherer\nAllons-y to Gallifrey, by Aman Bhargava\n\n\nRegardless of which option you choose, you are expected to consider all design elements discussed throughout the quarter, implement as appropriate, and justify your decisions! These include, but are not limited to:\n\ngraphic form (you are not limited to just those fundamental chart types discussed in weeks 3 & 4 – explore other advanced chart types and don’t be afraid to get really creative with it; check out some of these awesome data viz creators to find inspiration)\ntext (e.g. titles, captions, annotations, axis labels, axis ticks, alt text)\nthemes (i.e. all non-data plot elements; these should be intentionally modified and visually-pleasing)\ncolors\ntypography\ngeneral design (e.g. group order, spacing, text orientation, data-ink ratio, creating a visual hierarchy, avoiding information overload)\ncontextualizing your data\ncentering your primary message\nconsidering accessibility (e.g. colorblind-friendly palettes / contrast, alt text)\napplying a DEI lens to your design (e.g. considering the people / communities / places represented in your data, consider how you frame your questions / issue)\n\n\nIn addition to producing your visualizations, you are expected to follow clean and organized coding practices:\n\nfollow the tidyverse style guide (important styles are outlined on the course website)\norganize and annotate code (see these recommendations from the course website)\napply the appropriate code chunk options (e.g. in most (if not all) cases, code and outputs should be rendered but warnings and messages should not) – see the Quarto documentation on HTML Code Blocks and Execution Options for more\n\n(optional) you may consider applying the code-fold option, which can make scrolling past long code chunks easier\n\n\nYou will also document your data design process and decisions in a short 1-2 page (~500-1,000 words) write up:\nYour writing should:\n\nclearly state your question(s)\ndescribe your data (including your data source)\naddress your approach and decisions for each of the ten design elements listed above (though you are welcome and encouraged to comment on any others that are not explicitly listed). If your visualizations do not include and / or consider a listed element(s), please comment on why (it’s possible that not all will be applicable to your visualizations, but be sure to say why that is the case).\n\nYou may submit your assignment in one of two ways:\n\nA published Quarto document that is deployed using GitHub Pages\n\n\n\n\n\n\n\nInstructions for publishing a Quarto doc using GitHub Pages\n\n\n\n\n\n\nYour Quarto doc must be named index.qmd and live in your repository’s root directory. Be sure to rename / move it, if necessary.\nHead to your remote repository on GitHub. Navigate to the Settings page (top navbar), then select Pages from the left-hand menu. Once there, you should see something that looks like this:\n\n\n\n\n\n\n\n\n\n\n\nUnder Build and deployment &gt; Branch, update the drop down that says None to main. Leave the second drop down on /(root) (this tells GitHub to look for and deploy our index.html file from the root directory of the main branch). Click Save. Your URL will appear at the top of the page once it’s deployed (you will need to refresh the page – this could take a few minutes):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs a blog post on your personal website – check out the Adding a blog to your existing Quarto website workshop materials for a refresher, if needed"
  },
  {
    "objectID": "assignments/HW4.html#rubric-specifications",
    "href": "assignments/HW4.html#rubric-specifications",
    "title": "Assignment #4 (HW #4)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following to receive a “Satisfactory” mark for Assignment #4:\n\ncomplete option 1 or option 2, as detailed\nall data visualizations must implement the ten design elements (listed above), as appropriate (it’s up to you to decide when to consider, include, omit, modify any of these elements)\nall code should be appropriately formatted, annotated, and code chunks should all have the appropriate chunk options specified (see above for all details).\ndescribe your design process and decisions in a 1-2 page write-up, as described above\nsubmit your work as either a published Quarto doc or as a blog post on your personal website\nadd the link to your published Quarto doc / blog post to this Google Sheet"
  },
  {
    "objectID": "assignments/SR2-midcourse.html",
    "href": "assignments/SR2-midcourse.html",
    "title": "Mid-course reflection (SR #2)",
    "section": "",
    "text": "In this assignment, you’ll be writing about your learning throughout this course so far. Remember that these assignments are opportunities for you to reflect on your own progress in the course.\nReread your responses to your Pre-course reflection (SR #1) to refresh your memory, and answer the following questions in 2-6 sentences each:\n\nHow have you progressed towards your learning goals for this course?\nWhat skills are you proud of developing?\nIf you’ve needed help, how have you sought it out? If you haven’t sought out help, why not?\nLooking forward, how have your learning goals changed? Have they stayed the same?\nWhat topics have excited you the most (so far)? Have you spent time or efforts outside of class and / or the assignments diving deeper into any of these topics? If yes, what did you learn?\nHow would you change the structure of this course, if at all? If you wouldn’t, what in particular has been working for you?\nIs there anything about this course that you are really enjoying? Anything that isn’t working for you?\nWhat else would you like me to know about your experience in the course thus far?"
  },
  {
    "objectID": "assignments/SR2-midcourse.html#description",
    "href": "assignments/SR2-midcourse.html#description",
    "title": "Mid-course reflection (SR #2)",
    "section": "",
    "text": "In this assignment, you’ll be writing about your learning throughout this course so far. Remember that these assignments are opportunities for you to reflect on your own progress in the course.\nReread your responses to your Pre-course reflection (SR #1) to refresh your memory, and answer the following questions in 2-6 sentences each:\n\nHow have you progressed towards your learning goals for this course?\nWhat skills are you proud of developing?\nIf you’ve needed help, how have you sought it out? If you haven’t sought out help, why not?\nLooking forward, how have your learning goals changed? Have they stayed the same?\nWhat topics have excited you the most (so far)? Have you spent time or efforts outside of class and / or the assignments diving deeper into any of these topics? If yes, what did you learn?\nHow would you change the structure of this course, if at all? If you wouldn’t, what in particular has been working for you?\nIs there anything about this course that you are really enjoying? Anything that isn’t working for you?\nWhat else would you like me to know about your experience in the course thus far?"
  },
  {
    "objectID": "assignments/SR2-midcourse.html#rubric-specifications",
    "href": "assignments/SR2-midcourse.html#rubric-specifications",
    "title": "Mid-course reflection (SR #2)",
    "section": "Rubric (specifications)",
    "text": "Rubric (specifications)\nYou must complete the following, as detailed below, to receive a “Satisfactory” mark for this Mid-course reflection:\nComplete the following steps in your GitHub Classroom repo (eds240-sr2/SR2-midcourse-reflection.qmd):\n\ninclude your preferred name, and if you feel comfortable, your preferred pronouns in the title of the SR1-precourse-reflection.qmd YAML\naddress each question in at least 2-6 sentences (but please feel free to expand on any of these, if you’d like)\npush SR2-midcourse-reflection.qmd to GitHub using GitHub Classrooms by 11:59pm PT on Sat 02/10/2024"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Data Visualization & Communication",
    "section": "Course Description",
    "text": "Course Description\nEffectively communicating your work in a responsible, accessible and visually-pleasing way is often (if not, always) a central part of data science. This course will focus on the basic principles for effective communication through data visualization and using technical tools and workflows for creating and sharing data visualizations with diverse audiences.\nBy the end of this course, learners should be able to:\n\nIdentify which types of visualizations are most appropriate for your data and your audience\nPrepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\nBuild effective, responsible, accessible, and aesthetically-pleasing visualizations using the R programming language, and specifically {ggplot2} + ggplot2 extension packages\nWrite code from scratch and read and adapt code written by others\nApply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\nAssess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Data Visualization & Communication",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\n\nSam Csik\nEmail: scsik@ucsb.edu\nLearn more: samanthacsik.github.io\n\n\n\n\nTA\n\n\n\n\n\n\n\n\n\n\n\nSevan Esaian\nEmail: sevan.esaian@lifesci.ucsb.edu\nLearn more: linkedin.com/in/sevan-esaian"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Data Visualization & Communication",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nBuilding this course meant learning from the many incredible folks who think a lot about producing effective, beautiful, and responsible data visualizations. I relied heavily on the open source R / {ggplot2} / data viz teaching materials and tutorials that this wonderful data science community shares so willingly. Attribution will be included on any slides / materials where content is adapted from other educators."
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html",
    "href": "slides/sections/delete/choropleth-practice.html",
    "title": "EDS 240",
    "section": "",
    "text": "Warning: package 'ggplot2' was built under R version 4.3.1\n\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\nWarning: package 'stringr' was built under R version 4.3.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWarning: package 'maps' was built under R version 4.3.1\n\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 3107 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): ID, Name, State, Value, 1901-2000 Mean\ndbl (2): Rank, Anomaly (1901-2000 base period)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `precip = as.numeric(precip)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nJoining with `by = join_by(state, county)`\nJoining with `by = join_by(state, county)`\nJoining with `by = join_by(state, county)`"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html#create-base-map",
    "href": "slides/sections/delete/choropleth-practice.html#create-base-map",
    "title": "EDS 240",
    "section": "—————– Create base map —————–",
    "text": "—————– Create base map —————–\n\n# 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\nbase_map &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n  \n  # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n  geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n  \n  # darken state lines ----\n  geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n  \n  # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n  #coord_fixed(1.3) +\n  \n  # update labels ----\n  labs(title = \"Total Precipitation, by County\",\n       subtitle = \"October 2023\") +\n  \n  # set theme to clean up appearance ----\n  theme_void() + \n  \n  # theme adjustments ----\n  theme(\n    legend.position = \"bottom\"\n  )\n  \nbase_map"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html#add-projection",
    "href": "slides/sections/delete/choropleth-practice.html#add-projection",
    "title": "EDS 240",
    "section": "—————– Add projection —————–",
    "text": "—————– Add projection —————–\n\nbase_map_proj &lt;- base_map + \n  coord_map(projection = \"mercator\")\n\nbase_map_proj"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html#custom-function-to-add-correct-guide-bar-styling",
    "href": "slides/sections/delete/choropleth-practice.html#custom-function-to-add-correct-guide-bar-styling",
    "title": "EDS 240",
    "section": "—————– Custom function to add correct guide bar styling —————–",
    "text": "—————– Custom function to add correct guide bar styling —————–\n\n# apply to following maps to customize legend appearance ----\ncustom_guide &lt;- function(type) {\n  \n  # if gradient, use guide_color()\n  if (type == \"g\") {\n    guides(fill = guide_colorbar(title = \"Precipitation (inches)\",\n                                 title.position = \"top\",\n                                 barwidth = 15, barheight = 1))\n    \n  # if bin, use guide_colorsteps()\n  } else if (type == \"b\") {\n    guides(fill = guide_colorsteps(title = \"Precipitation (inches)\",\n                                   title.position = \"top\",\n                                   barwidth = 15, barheight = 1))\n  }\n}"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html#initial-attempt-manually-create-binned-color-gradient",
    "href": "slides/sections/delete/choropleth-practice.html#initial-attempt-manually-create-binned-color-gradient",
    "title": "EDS 240",
    "section": "—————– Initial attempt: manually create binned color gradient —————–",
    "text": "—————– Initial attempt: manually create binned color gradient —————–\n\n# # plot (viridis) ----\n# base_map_proj + \n#   scale_fill_viridis_c() +\n#   custom_guide(type = \"g\")\n\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#D5D4CE\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n\n# plot (gradient) ----\nbase_map_proj + \n  scale_fill_gradientn(colors = my_palette) +\n  custom_guide(type = \"g\")\n\n\n\n# plot (binned) ----\nbase_map_proj + \n  scale_fill_stepsn(colors = my_palette) +\n  custom_guide(type = \"b\")\n\n\n\n\nWe have a map (yay!) but the binned version is not so helpful yet. We’re not seeing much detail (most of the country is colored brown, having received 0-5”). ggplot is also defaulting to 5 bins (colors), which is not what we want. We’ll have to define our own bins. One approach is to calculate & specify equal bin sizes:\n\nget max & min precipitations\nsubtract them\ndivide the result by the number of intervals that we want (11 colors, ideally)\n\n\n# range of data ----\nrange(na.omit(joined_precip_us_counties)$precip) # 0.0-10.2 \n\n[1]  0.0 10.2\n\n# calculate bin size ----\n(max(na.omit(joined_precip_us_counties)$precip) - min(na.omit(joined_precip_us_counties)$precip))/11 # 0.93\n\n[1] 0.9272727\n\n\nUsing this approach, class size would be 1 (rounded from 0.93). To achieve that, we need to set breaks that are a width of 1 from our min value (0) to our max (11, since max value is 10.2). We also need the appropriate amount of colors to fill those bins.\n\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#16726B\", \"#003C30\") \n\n# define breaks ----\nmy_breaks &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)\n\n# plot ----\nbase_map_proj + \n  scale_fill_stepsn(colors = my_palette,\n                    breaks = my_breaks,\n                    values = scales::rescale(my_breaks)) +\n  custom_guide(type = \"b\") \n\n\n\n# base_map_proj + \n#   scale_fill_stepsn(colors = my_palette,\n#                     breaks = my_breaks, \n#                     values = scales::rescale(my_breaks)) +\n#   custom_guide(type = \"b\")\n# \n# \n# scale_fill_stepsn(name = \"\", \n#                     colors =c(\"#2171b5\", \"#6baed6\", \"#bdd7e7\", \"#fcae91\", \"#fb6a4a\", \"#cb181d\"),\n#                     breaks = c(-25, -10, 0, 10, 50),\n#                     values = scales::rescale(c(-25, -10, 0, 10, 25, 50))) \n\nAttempt B is a better, though it would be wise to look at the distribution of our precipitation data to see if we might be losing any important details:\n\n# plot histogram ----\nggplot(joined_precip_us_counties, aes(x = precip)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1626 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n# calculate median ----\nmedian(na.omit(joined_precip_us_counties)$precip) # 2.02\n\n[1] 2.01\n\n\nOur data are heavily right-skewed (most are smaller values), and our median value is 2.02” – meaning half our our data fall below 2.02”. This means that we’re likely losing details at the lower end of the spectrum, since we have so many small precipitation totals. Let’s take an even closer look by calculating some quantiles:\n\n# default quartiles ----\nquantile(joined_precip_us_counties$precip,\n         probs = seq(from = 0, to = 1, by = 0.25),\n         na.rm = TRUE)\n\n   0%   25%   50%   75%  100% \n 0.00  1.18  2.01  3.30 10.20 \n\n\nHow do we interpret this?\n\nOur min value is 0 and max value is 10.20.\n25% of our precipitation recordings live below 1.19”\n50% of our precipitation recordings live below 2.02”\n75% of our precipitation recordings live below 3.31”\n100% of our precipitation recordings live below 10.20”\n\nWe can adjust the quantiles calculated:\n\nquantile(joined_precip_us_counties$precip, \n         probs = seq(from = 0, to = 1, by = 0.10),\n         na.rm = TRUE)\n\n    0%    10%    20%    30%    40%    50%    60%    70%    80%    90%   100% \n 0.000  0.640  1.050  1.340  1.600  2.010  2.490  3.040  3.610  4.478 10.200 \n\n\nWe see here that 10% of all our precipitation recordings live below 0.65”! And 90% live below 4.47”.\n\n# define palette ----\n# define palette ----\nmy_palette &lt;- c(\"#543006\", \"#975F1C\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n                 \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#16726B\", \"#003C30\") \n# my_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n#                  \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n\n# define breaks ----\nmy_breaks = c(0, 0.65, 1.05, 1.35, 1.61, 2.02, 2.51, 3.05, 3.61, 4.47, 10.20)\n\n# plot ----\nbase_map +\n  scale_fill_stepsn(trans = scales::pseudo_log_trans(),\n                    colors = my_palette,\n                    breaks = my_breaks) +\n  custom_guide(type = \"b\")\n\n\n\n\n\n\n\n\n# mean(na.omit(joined_precip_us_counties$precip)) # 2.4\n# sd(na.omit(joined_precip_us_counties$precip)) # 1.6\n\n\n\n# # define palette ----\n# my_palette &lt;- c(\"#543006\", \"#AC7E42\", \"#C09C66\", \"#E8E8E8\",\n#                 \"#64A7A1\", \"#3B8E86\", \"#003C30\")\n# \n# # define breaks ----\n# my_breaks &lt;- c(0, 0.8, 2.4, 4, 5.6, 7.2, 8.8, 10.4)\n# \n# # plot ----\n# base_map_proj + \n#   scale_fill_stepsn(colors = my_palette,\n#                     breaks = my_breaks) +\n#   custom_guide(type = \"b\")\n\n\n\n# # define palette ----\n# my_palette &lt;- c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",\"#E8E8E8\",\n#                  \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\")\n# \n# # define breaks ----\n# my_breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)\n# \n# # plot ----\n# base_map +\n#     scale_fill_stepsn(trans = \"log\",\n#                       colors = my_palette,\n#                       breaks = my_breaks) \n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method3 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # # OPTION 1: update colors with pre-fab palette ----\n#   # scale_fill_viridis_c(option = \"D\") +\n#   # scale_fill_distiller(palette = 'Purples')\n#   # scale_fill_viridis_c(trans = \"log\", breaks=c(0.1, 0.5, 2,4,6, 8, 10, 12, 15, 20, 25), \n#   #                  name=\"Number of restaurant\", \n#   #                  guide = guide_legend( \n#   #                                        label.position = \"bottom\", \n#   #                                        title.position = 'top',\n#   #                                        nrow=1))\n#   # \n#   # OPTION 2: manually create a color gradient ----\n#   # scale_fill_gradient(low = \"#C8ECE6\", high = \"#213943\") +\n#   \n#   # OPTION 2: manually create a color gradient ----\n#   #scale_fill_gradient2(low = \"#77A8B9\", mid = \"#FFFFFF\", high = \"#213943\") +\n#   scale_fill_steps2(#trans = \"log\",\n#                     low = \"#543006\", mid = \"#E8E8E8\", high = \"#003C30\",\n#                     midpoint = 4) +\n#                     # colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                     #            \"#E8E8E8\", \n#                     #            \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"), \n#                     # breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)) +\n#   \n#   # update legend ----\n#   guides(fill = guide_coloursteps(title = \"Precipitation (inches)\", \n#                                   title.position = \"top\",\n#                                   barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n# \n# method3\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# original &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient; nice.breaks = TRUE by default ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#EBD9B0\",\n#                                \"#E8E8E8\", \"#B2DDD7\", \"#8BC2BC\", \"#3B8E86\", \"#16726B\", \"#003C30\")) +\n#                     #breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)) +\n# \n# \n#   # update legend ----\n#   # guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#   #                               title.position = \"top\",\n#   #                               barwidth = 15, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# original\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method1 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                                \"#E8E8E8\", \n#                                \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"),\n#                     breaks = c(0, 1.7, 3.4, 5.1, 6.8, 8.5, 10.2, 11.9, 13.6, 15.3, 17, 18.7)) +\n#                    \n# \n#   # update legend ----\n#   guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#                                 title.position = \"top\",\n#                                 barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# method1\n\n\n# # 'group' controls whether adjacent points are connected by lines (each county is a \"group,\" therefore points are connected) ----\n# method2 &lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + \n#   \n#   # plot precip values by county; geom_polygon() drawn lines between points and “closes them up” (i.e. draws a line from the last point back to the first point) ----\n#   geom_polygon(data = joined_precip_us_counties, aes(fill = precip)) + \n#   \n#   # darken state lines ----\n#   geom_polygon(color = \"#2F2D2C\", fill = NA, linewidth = 0.1) +\n#   \n#   # to fix the relationship between one unit in the y direction and one unit in the x direction; may need different values for different regions depending on where they are on the globe (e.g. close to the poles)\n#   coord_fixed(1.3) +\n#   \n#   # manually create a binned color gradient ----\n#   scale_fill_stepsn(colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#D6BB8C\", \"#EBD9B0\",  \n#                                \"#E8E8E8\", \n#                                \"#B2DDD7\", \"#8BC2BC\", \"#64A7A1\", \"#3B8E86\", \"#16726B\", \"#003C30\"),\n#                     breaks = c(0, 1, 4, 7, 10, 13, 16, 19)) +\n#                    \n# \n#   # update legend ----\n#   guides(fill = guide_colourbar(title = \"Precipitation (inches)\",\n#                                 title.position = \"top\",\n#                                 barwidth = 25, barheight = 1)) +\n#   \n#   # update labels ----\n#   labs(title = \"Total Precipitation, by County\",\n#        subtitle = \"January 2023\") +\n#   \n#   # set theme to clean up appearance ----\n#   theme_void() + \n#   \n#   # theme adjustments ----\n#   theme(\n#     legend.position = \"bottom\"\n#   )\n#   \n# method2\n\n\n  # # OPTION 2: manually create a color gradient ----\n  # #scale_fill_gradient2(low = \"#77A8B9\", mid = \"#FFFFFF\", high = \"#213943\") +\n  # scale_fill_stepsn(trans = \"log\",\n  #                   colors = c(\"#543006\", \"#975F1C\", \"#AC7E42\", \"#C09C66\", \"#EBD9B0\", \"#B2DDD7\", \"#8BC2BC\", \"#3B8E86\", \"#16726B\", \"#003C30\"), \n  #                   breaks = c(0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 12, 15, 20, 25)) +\n  # \n  # # update legend ----\n  # guides(fill = guide_coloursteps(title = \"Precipitation (inches)\", \n  #                                 title.position = \"top\",\n  #                                 barwidth = 15, barheight = 1)) +\n  # \n  # # update labels ----\n  # labs(title = \"Total Precipitation, by County\",\n  #      subtitle = \"January 2023\") +\n  # \n  # # set theme to clean up appearance ----\n  # theme_void() + \n  # \n  # # theme adjustments ----\n  # theme(\n  #   legend.position = \"bottom\"\n  # )"
  },
  {
    "objectID": "slides/sections/delete/choropleth-practice.html#data-wrangling-2-usmap",
    "href": "slides/sections/delete/choropleth-practice.html#data-wrangling-2-usmap",
    "title": "EDS 240",
    "section": "—————– Data wrangling 2 ({usmap}) —————–",
    "text": "—————– Data wrangling 2 ({usmap}) —————–\n\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# ##                                    setup                                 ----\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# \n# #..........................load packages.........................\n# library(tidyverse)\n# library(usmap)\n# \n# #.........................get shape data.........................\n# county_map &lt;- us_map(regions = \"counties\") |&gt; \n#   rename(state_abb = abbr, state_name = full)\n# \n# #....................import precipitation data...................\n# precip_counties &lt;- read_csv(here::here(\"slides\", \"data\", \"county-precip-oct2023.csv\"), skip = 4) |&gt; \n#   janitor::clean_names() |&gt; \n#   rename(county = name, state_name = state, precip_in = value) |&gt; \n#   mutate(precip_in = as.numeric(precip_in))\n# \n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# ##                                  join dfs                                ----\n# ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# \n# precip_counties_wrangled &lt;- full_join(precip_counties, county_map)\n\n\n# # empty map ----\n# plot_usmap(regions = c(p),\n#            exclude = c(\"AK\", \"HI\"))\n# \n# # fill counties ----\n# precip_counties_wrangled |&gt; \n#   select(fips, precip_in) |&gt; \n#   plot_usmap(regions = \"counties\", exclude = c(\"AK\", \"HI\"),\n#              data = precip_counties_wrangled, values = \"precip_in\") + \n#   scale_fill_viridis_c() +\n#   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/sections/3.3-lyme.html",
    "href": "slides/sections/3.3-lyme.html",
    "title": "EDS 240",
    "section": "",
    "text": "Warning: package 'tidycensus' was built under R version 4.3.1\n\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\nWarning: package 'stringr' was built under R version 4.3.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\nRows: 3143 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Ctyname, Stname, ststatus\ndbl (22): STCODE, CTYCODE, Cases2001, Cases2002, Cases2003, Cases2004, Cases...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\nJoining with `by = join_by(state)`"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#title-slide",
    "href": "slides/week1.1-logistics-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 1.1\nCourse logistics & syllabus\n\nWeek 1 | January 8th, 2024"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#welcome",
    "href": "slides/week1.1-logistics-slides.html#welcome",
    "title": "EDS 240",
    "section": "",
    "text": "Welcome to EDS 240!\n\nThis course will focus on the basic principles for effective communication through data visualization and using technical tools and workflows for creating and sharing data visualizations with diverse audiences.\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#logistics",
    "href": "slides/week1.1-logistics-slides.html#logistics",
    "title": "EDS 240",
    "section": "",
    "text": "Meeting times & locations\n\n\nClass: Mondays 1:00-4:00pm PT (attendance is mandatory)\nDiscussion Sections: Wednesdays 10:00-10:50am PT & 11:00-11:50am PT\n\n\n\nClass & Discussion Sections meet in the NCEAS 1st floor classroom"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#instructor",
    "href": "slides/week1.1-logistics-slides.html#instructor",
    "title": "EDS 240",
    "section": "",
    "text": "Teaching team\n\n\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\n\nSam Csik\nEmail: scsik@ucsb.edu\nLearn more: samanthacsik.github.io\nStudent hours: M 4-5pm @ NCEAS\n\n\n\nTA\n\n\n\n\n\n\n\n\n\n\n\nSevan Esaian\nEmail: sevan.esaian@lifesci.ucsb.edu\nLearn more: linkedin.com/in/sevan-esaian Student hours: W 9-10am @ NCEAS"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#meet-one-another",
    "href": "slides/week1.1-logistics-slides.html#meet-one-another",
    "title": "EDS 240",
    "section": "",
    "text": "Meet one another!\n\n\nSpend the next few minutes getting to know your Learning Partners! Below are some conversation starters:\n\n\nWhere do you feel most at home?\n\n\nWhat parts of Santa Barbara have you enjoyed exploring?\n\n\nWhat’s the most exciting thing you’ve learned this year, so far?\n\n\nWhat’s your favorite color or typeface?\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#student-resources",
    "href": "slides/week1.1-logistics-slides.html#student-resources",
    "title": "EDS 240",
    "section": "",
    "text": "Student Resources\n\n\nBasic Needs Resources & Food Security: https://basicneeds.ucsb.edu/ (schedule a CalFresh Appoinment or Basic Needs Advising Session)\nCounseling & Psychological Services (CAPS): http://caps.sa.ucsb.edu\nResource Center for Sexual and Gender Diversity (RCSGD): https://rcsgd.sa.ucsb.edu/\nUndocumented Student Services (USS) Program: https://uss.sa.ucsb.edu/\nCampus Learning Assistance Services (CLAS): http://clas.sa.ucsb.edu\nStudent Resource Building (SRB): http://www.sa.ucsb.edu/student-resource-building/home\nMulticultural Center (MCC): http://mcc.sa.ucsb.edu/\nCampus Advocacy, Resources, & Education (CARE): http://wgse.sa.ucsb.edu/care/home\nFinancial Crisis Response Team: financialcrisis@sa.ucsb.edu (contact)\nHealth and Wellness: https://wellbeing.ucsb.edu/\n\n\n\nYour mental and physical health is more important than your grade in any course.\nI’m always happy to help you identify resources or help on campus – DM or email me!"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#conduct",
    "href": "slides/week1.1-logistics-slides.html#conduct",
    "title": "EDS 240",
    "section": "",
    "text": "Conduct, Inclusion, Accommodations\n\n \nCourse Conduct: We are committed to actively creating, modeling, and maintaining an inclusive climate and supportive learning environment for all – harassment of any kind will not be tolerated. Everyone is expected read and adhere to the Bren School Code of Conduct and the UCSB Code of Conduct\n\n\nAccess & accommodations: It’s never too late to apply for DSP accommodations\n\n\n\nNames & pronouns: Everyone has the right to be addressed and referred by to name and pronouns in accordance with their identity – you can add your pronouns to your UCSB Registrar profile\n\nApplying for DSP accommodations is a multi-step process and students should begin this as soon as possible as it can take 10 days to process applications.\nStep 1: Submit an application with DSP, upload documentation and select the services needed.\nStep 2: For exam accommodations (more time, private setting, etc.) students need to submit a proctor request for each exam in each course that they need accommodations for. DSP has instructions on their website for completing these tasks and students can login to the DSP portal to check the status of their application and requests."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#course-website",
    "href": "slides/week1.1-logistics-slides.html#course-website",
    "title": "EDS 240",
    "section": "",
    "text": "Everything you’ll need lives on the course website!\n\n\nhttps://samanthacsik.github.io/EDS-240-data-viz\n\n\n\nLink is also bookmarked at the top of the #eds-240-data-viz Slack channel and linked on the Courses page of the MEDS website."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#tentative-schedule",
    "href": "slides/week1.1-logistics-slides.html#tentative-schedule",
    "title": "EDS 240",
    "section": "",
    "text": "Tentative Schedule & Materials\n\n\n\n\n\n\n\n\n\n\n\nDate\nTentative Topic\n\n\n\n\n1/8\ncourse logistics, intro, {ggplot2} review\n\n\n1/15\nno class\n\n\n1/22\ngraphic forms, fundamental chart types (part I)\n\n\n1/29\nfundamental chart types (part II), good vs. bad viz\n\n\n2/5\nenhancing visualizations\n\n\n2/12\ndata communication\n\n\n2/19\nno class\n\n\n2/26\nvisualizing uncertainty & avoiding the misrepresentation of data\n\n\n3/4\nOJS with Dr. Allison Horst\n\n\n3/11\ngrab bag & catch up\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion sections are held every week"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#pre-class-prep",
    "href": "slides/week1.1-logistics-slides.html#pre-class-prep",
    "title": "EDS 240",
    "section": "",
    "text": "Complete all items under Pre-class Prep before lecture\n\nPlease be sure to carefully complete all required prep (e.g. installing packages, downloading data) under the Pre-class Prep section (organized by week) before lecture – be mindful that some items may take time to download/install.\n\n\nIt is highly recommended that you do this well in advance of attending lecture."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#assignments",
    "href": "slides/week1.1-logistics-slides.html#assignments",
    "title": "EDS 240",
    "section": "",
    "text": "Assignments\n\n\n\nYour course grade will be based off the following:\n\n\n\n3 Self-reflections - a place to reflect on your learning plan / goals, challenges, etc. (5 days to complete each)\n4 Homework Assignments - longer assignments where you’ll apply conceptual knowledge & technical skills to data viz tasks (10+ days to complete each)\n8 End-of-class surveys - short surveys to help me better understand your weekly class experience (due by EOD each day there is lecture)\n8 Lectures - a mix of slide-based lectures, live-coding, and individual / group-based critical thinking and technical exercises (attendance mandatory, Mondays 1:00-4:00pm PT)"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#grading",
    "href": "slides/week1.1-logistics-slides.html#grading",
    "title": "EDS 240",
    "section": "",
    "text": "How will I be evaluated?\n\n\nThis class will implement an alternative grading approach called specifications (specs) grading.\n\n\n\n\n“an alternative grading method where instructors create a list of specifications that describe the qualities and characteristics of a successful submission for an assignment. Student work is graded holistically based on those specifications, earning a single mark: “Satisfactory” or “Not Yet”. Students have the chance to use feedback by revisiting and resubmitting for full credit.”\n\n\n\n-expert from “Grading for Growth: A Guide to Alternative Grading Practices That Promote Authentic Learning and Student Engagement in Higher Education”, by David Clark & Robert Talbert"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#why-specs",
    "href": "slides/week1.1-logistics-slides.html#why-specs",
    "title": "EDS 240",
    "section": "",
    "text": "Why Specs grading?\n\n\n“Traditional” grading can come with some challenges:\n\n\n\nlacks feedback loops\nbenefits those who learn fast or have prior experience\nbias-prone (e.g. awarding points, granting extensions)\ncan discourage learning for its own sake\ncan promote unhealthy student-instructor relationships\n\n\n\nTraditional grading = points are awarded for correct answers on assessments; graded assessments contribute some percentage towards your overall course grade; course score (typically a percentage) is convered to a letter grade"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#how-does-specs-look",
    "href": "slides/week1.1-logistics-slides.html#how-does-specs-look",
    "title": "EDS 240",
    "section": "",
    "text": "How does specs grading look in practice for this course?\n\n\nTL;DR: assignments receive either “Satisfactory” or “Not Yet” marks; tokens can be used to revise / resubmit assignments, for assignment extensions, or to miss class; earn tokens by attending discussions\n\n\n\nassignments receive either a “Satisfactory” or “Not Yet” mark\neach assignment will have a clear rubric (containing specifications) which outline what must be completed and how in order to receive a “Satisfactory” mark; not meeting all specifications results in a “Not Yet” mark\nstudents can trade “tokens” for the opportunity to:\n\nrevise / resubmit assignments that receive a “Not Yet” mark (within a week)\nassignment extensions (24 or 72 hours)\nto miss class\n\nstudents earn tokens (primarily) by attending discussion section"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#why-tokens",
    "href": "slides/week1.1-logistics-slides.html#why-tokens",
    "title": "EDS 240",
    "section": "",
    "text": "Why tokens?\n\n\nEveryone has different responsibilities & demands – tokens give you the power and freedom to ask for the accommodations you need.\n\n\nYou do not need to provide a reason to request an extension, resubmission, or to miss class, but you must have enough tokens to do so.\n\n\n\n\nTokens are not limitless and they accrue weekly (i.e. you don’t receive them all at the start), so use them wisely!"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#tokens",
    "href": "slides/week1.1-logistics-slides.html#tokens",
    "title": "EDS 240",
    "section": "",
    "text": "Earning & using tokens\n\n\nEarn tokens:\n\n\neveryone starts with 0 tokens\nearn your first token by attending discussion section on Wednesday 1/10\nearn 2 more tokens by submitting Self-reflection #1\nearn 1 token per week by attending discussion section (full 50 min)\n\n\n\n\nUse tokens:\nFill out this Google form: https://forms.gle/6FdV9g5KA9GgrxXBA and email Sam & Sevan to let them know"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#grade-tracker",
    "href": "slides/week1.1-logistics-slides.html#grade-tracker",
    "title": "EDS 240",
    "section": "",
    "text": "Use the Grade Tracker to determine your course grade"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#GenAI",
    "href": "slides/week1.1-logistics-slides.html#GenAI",
    "title": "EDS 240",
    "section": "",
    "text": "Policy on Generative AI (GenAI)\n\nGenAI tools (such as ChatGPT) are strongly discouraged for the following reasons:\n\n\ncore competencies are built through practice\nbuilding your own programming proficiency will help you engage with GenAI tools more productively\nsubscription versions of GenAI tools may induce an inequitable learning environment\n\n\n\nPlease adhere to these guidelines:\n\n\nyou may use spell / grammar check and / or synonym identification tools\nbe prepared to explain each line of code in your assignments and exercises\nif you use GenAI in assignments, you must include a statement of which GenAI platform used and why, along with a copy of your initial prompt(s) and ensuing “conversation(s)”\n\n\n\n\n\nPlease read the full policy on the course syllabus"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#help",
    "href": "slides/week1.1-logistics-slides.html#help",
    "title": "EDS 240",
    "section": "",
    "text": "Getting unstuck\n\nTroubleshooting, deciphering code, and trying (and failing at) new things is a large part of being a data scientist. Grad school is a safe space to get comfy with and practice these! Here’s how you should approach getting unstuck:\n\nCheck out the getting unstuck page (under “resources”) on the course website for more tips – particularly a reminder of how to ask a question."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#sucking-less",
    "href": "slides/week1.1-logistics-slides.html#sucking-less",
    "title": "EDS 240",
    "section": "",
    "text": "A note on pushing through the challenges\n\n\n\n \n\n\n“There is no way of [going from] knowing nothing about a subject to knowing something about a subject without going through a period of much frustration and suckiness.” “Push through. You’ll suck less.”\n\n\n\n-Hadley Wickham, author of {ggplot2}\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nSlide adapted from Andrew Heiss’ lesson, Truth, beauty, and data (PMAP 8101: Data Visualization)"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#slack",
    "href": "slides/week1.1-logistics-slides.html#slack",
    "title": "EDS 240",
    "section": "",
    "text": "A note on using Slack\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll course-related content questions should be asked in the #eds-240-data-viz channel – oftentimes there are others who have the same question and will benefit from seeing the discussion!\n\nAny questions sent as DMs will be copied into #eds-240-data-viz and answered there.\n\nOf course, please direct message or email with any personal questions or concerns."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#expectations",
    "href": "slides/week1.1-logistics-slides.html#expectations",
    "title": "EDS 240",
    "section": "",
    "text": "A note on expectations\n\nReminders:\n\nWe are not mind-readers (as helpful as that would be!). Please help us help you by bringing any issues to our attention (EOC surveys are a great place to do this, or via DM / email) – the earlier the better!\n\n\nPromises:\n\n\nWe are working, and will continue to work, really hard to make this a great class!\nWe are super passionate about teaching, but doesn’t mean it’s easy or that we’re infallible. We will do our best to adapt to student / class needs as the quarter progresses. There may be times where we won’t or can’t make changes to the course plan – if so, we will be transparent in our reasoning why.\n\n\n\n\nBoundaries:\n\n\nThis course (unfortunately) isn’t our only professional responsibility this quarter – we will not be available at all times to respond to requests / questions. Here’s what you can expect:\n\nWe will try our best to respond to Slack questions within 24hr (during the week)\nA response after-hours (5pm - 9am) is not guaranteed (we will try our best, as our personal lives allow for)\nWe will not be responding to questions over the weekend"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#this-course1",
    "href": "slides/week1.1-logistics-slides.html#this-course1",
    "title": "EDS 240",
    "section": "",
    "text": "What is EDS 240?\n\n\n\nEDS 240: Data Visualization and Communication is about two related, but distinct things:\n\n\n\n1. The theory of effective communication and data design\n How people perceive and interpret graphical information\n Human-centered design as it relates to data visualizations\n\n\n\n2. The physical act of building effective data visualizations using software and data science tools\n Using the Grammar of Graphics / {ggplot2} framework to create effective, truthful, and beautiful data visualizations"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#this-course2",
    "href": "slides/week1.1-logistics-slides.html#this-course2",
    "title": "EDS 240",
    "section": "",
    "text": "What is EDS 240?\n\n\n\nThe topic of data visualization is pretty darn massive.\n\n\n\nWe cannot and will not cover every data visualization type, consideration, package, etc.\n\n\n\n\n\nWe will work towards a conceptual and technical understanding of data viz fundamentals.\n\n\n\n\n\nData viz is a science and technical skill, but there’s also a lot of space for creativity.\n\n\n\n\n\nWhat you create can be used in your professional portfolio! The more you put in, the more you’ll get out."
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#LOs",
    "href": "slides/week1.1-logistics-slides.html#LOs",
    "title": "EDS 240",
    "section": "",
    "text": "Course Learning Objectives\n\n Identify which types of visualizations are most appropriate for your data and your audience\n\n\n Prepare (e.g. clean, explore, wrangle) data so that it’s appropriately formatted for building data visualizations\n\n\n\n Build effective, responsible, accessible, and aesthetically-pleasing, visualizations using the R programming language, and specifically ggplot2 + ggplot2 extension packages\n\n\n\n Write code from scratch and read and adapt code written by others\n\n\n\n Apply a DEI (Diversity, Equity & Inclusion) lens to the process of designing data visualizations\n\n\n\n Assess, critique, and provide constructive feedback on data visualizations"
  },
  {
    "objectID": "slides/week1.1-logistics-slides.html#end-break",
    "href": "slides/week1.1-logistics-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 3) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#title-slide",
    "href": "slides/week8.2-people-as-data-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 8.2\nPeople as data\n\nWeek 8 | February 26th, 2024"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#good-design",
    "href": "slides/week8.2-people-as-data-slides.html#good-design",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#LA-map1",
    "href": "slides/week8.2-people-as-data-slides.html#LA-map1",
    "title": "EDS 240",
    "section": "",
    "text": "Can anyone take a guess at what this map depicts?"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#LA-map2",
    "href": "slides/week8.2-people-as-data-slides.html#LA-map2",
    "title": "EDS 240",
    "section": "",
    "text": "Redlining Los Angeles, 1939\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Mapping Inequality: Redlining in New Deal America (v3)\n\n\n\nRedlining: the practice of categorically withholding financial services, especially mortgages, from neighborhoods that have a significant number of racial or ethnic minorities\nBetween 1935-1940, the Home Owners’ Loan Corporation (HOLC) graded “residential security” (i.e. financial risk) of neighborhoods in most major metropolitan areas across the US\nColor-coded maps depict grades, where green represents the “best” neighborhoods and safest investments. Red represents “hazardous” neighborhoods and riskiest investments.\nNeighborhoods earned a red grade if African Americans lived in it, even if it was a middle-class neighborhood of single-family homes (Rothstein 2017)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#our-job",
    "href": "slides/week8.2-people-as-data-slides.html#our-job",
    "title": "EDS 240",
    "section": "",
    "text": "Our job as data scientists . . .\n\n…is to actively incorporate equity awareness when working with data and generating data products (e.g. visualizations). Not all visuals are overtly racist or discriminatory, but we as data practitioners must recognize and work against misusing or misrepresenting data in ways that can harm communities and perpetuate systemic discrimination.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban Institute’s Do No Harm Guide, by Jonathan Schwabish and Alice Feng (2021)\n\n\nguidelines on how to apply a DEI lens to not just words, colors, icons, etc., but also the process of crafting communication products\nincludes checklists & tool kits that focus on the often hidden / subtle ways that data analysts and communicators fail to incorporate equitable awareness in the data they use and they products they create"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#kirk",
    "href": "slides/week8.2-people-as-data-slides.html#kirk",
    "title": "EDS 240",
    "section": "",
    "text": "Our choices affect how viewers perceive and interpret information\n\n\n\n\n\nScheme by Andy Kirk from his book Data Visualisation: A Handbook for Data Driven Design, recreated by Cédric Scherer"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-original1",
    "href": "slides/week8.2-people-as-data-slides.html#migration-original1",
    "title": "EDS 240",
    "section": "",
    "text": "Design choices influence viewers’ perception\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\nDiscuss how you perceive, interpret, and comprehend this map with your learning partner(s). What thoughts or emotions does it invoke? Why do you think you feel those emotions?\n\n\n\n\nThe above map was recreated by folks at The Correspondent, based on migration maps commonly published by the European Border and Coast Guard Agency (Frontex).\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-original2",
    "href": "slides/week8.2-people-as-data-slides.html#migration-original2",
    "title": "EDS 240",
    "section": "",
    "text": "Design choices influence viewers’ perception\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nArrows reminiscent of battle map\nRed = color of danger\nLARGE, direct arrows (larger than most countries)\nTitle language portrays criminal activity\nDoesn’t show where migrants actually come from\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum\n\n\n\nlarge direct arrows make it look as if migrants are heading straight for Europe, but many tkae a long, dangerous, and detour-filled journey.\n“illegal border crossings” portrayts migrants as criminals. It does not show that asylum seekers have hardly any legal options to enter the EU\nappears to be a uniform group coming into Europe from the “great unknown”"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-original3",
    "href": "slides/week8.2-people-as-data-slides.html#migration-original3",
    "title": "EDS 240",
    "section": "",
    "text": "Design choices influence viewers’ perception\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nDiscuss how you might redesign this map to make us feel less\n\n“like we are being overrun by huge numbers of anonymous enemies, coming at us en masse from all corners of the globe to disrupt our orderly lives”\n\n\n-Vermulen, De Korte, Van Houtum\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-blue",
    "href": "slides/week8.2-people-as-data-slides.html#migration-blue",
    "title": "EDS 240",
    "section": "",
    "text": "Use different colors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-title",
    "href": "slides/week8.2-people-as-data-slides.html#migration-title",
    "title": "EDS 240",
    "section": "",
    "text": "Change the title\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-sm-arrows",
    "href": "slides/week8.2-people-as-data-slides.html#migration-sm-arrows",
    "title": "EDS 240",
    "section": "",
    "text": "Adjust the size of the arrows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#migration-blue-circles",
    "href": "slides/week8.2-people-as-data-slides.html#migration-blue-circles",
    "title": "EDS 240",
    "section": "",
    "text": "Don’t use arrows altogether\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#num-2018",
    "href": "slides/week8.2-people-as-data-slides.html#num-2018",
    "title": "EDS 240",
    "section": "",
    "text": "Consider format and information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#num-all-years",
    "href": "slides/week8.2-people-as-data-slides.html#num-all-years",
    "title": "EDS 240",
    "section": "",
    "text": "Consider format and information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum\n\n\nEven now, we still only see a small percentage of all asylum migration. How many asylum seekers are actually headed towards the EU?"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#context-origins",
    "href": "slides/week8.2-people-as-data-slides.html#context-origins",
    "title": "EDS 240",
    "section": "",
    "text": "Provide context\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#context-dest",
    "href": "slides/week8.2-people-as-data-slides.html#context-dest",
    "title": "EDS 240",
    "section": "",
    "text": "Provide context\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#all-migration",
    "href": "slides/week8.2-people-as-data-slides.html#all-migration",
    "title": "EDS 240",
    "section": "",
    "text": "Provide context\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow maps in the media make us more negative about migrants, by Maite Vermulen, Leon De Korte, and Henk Van Houtum"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#takeaways",
    "href": "slides/week8.2-people-as-data-slides.html#takeaways",
    "title": "EDS 240",
    "section": "",
    "text": "Some important takeaways\n\n\n\nQuotes from Vermulen, De Korte, and Van Houtum\n\n\n\n“As journalists and illustrators, there is no way around simplifying the world for the sake of readability. Whether in maps or in text. But we can be much more aware of the consequences of those simplifications – and be honest about what’s happening.”\n\n\n\n\n“… take a moment to contemplate who authored this visual story and what message the author wants to convey. And why.”"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy",
    "href": "slides/week8.2-people-as-data-slides.html#empathy",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy – for both the communities whose data we are visualizing and the readers / target audiences of our work (Schwabish & Feng 2021)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-def",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-def",
    "title": "EDS 240",
    "section": "",
    "text": "Empathy is defined as:\n\n \n\n“the action of understanding, being aware of, being sensitive to, and vicariously experiencing the feelings, thoughts, and experience of another”\n\n\n-Merriam-Webster\n\n\n\n\nThe Do No Harm Guide lists six themes for considering empathy as it applies to communicating data…"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes1",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes1",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n\n\n“if your data [are] about people, make it extremely clear who they are or were”\n\n\n-Jacob Harris in Connecting with the Dots\n\n\n\n\n\n\n\n\n\n\n\n\nEach square represents US service member who died in Iraq or Afghanistan. Source: Faces of Death (New York Times); (Note: this is an archived page and a bit glitchy)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes2",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes2",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n\nPair data-driven charts with personal stories, or help readers understand the “far vs. near” (i.e. overall metrics + smaller ranges / groups of data)\n\n\n\n\n\n\n\n\n\n\n\nThis map focuses on one of the deadliest days in Baghdad, with 114 separate episodes of violence resulting in the deaths of 160 Iraqi citizens and police officers | Source: A Deadly Day In Baghdad (New York Times)\n\n\n\n\nThese graphics illustrate a common and successful technique for bringing the reader back down to earth by focusing on a smaller range of data. In the case of Baghdad’s dead, we focused on a single day to show the near of what years of violence looked like day after day. (Harris 2015)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes3",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes3",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n Use a mix of quantitative and qualitative approaches to tell a story\n\n\nFocusing on just numbers without context can overlook important aspects of a story, such as the “why” and “how”\n\n\n\n\n\n\n\n\n\n\n\nMapping the theme of EV charging convenience, which was most tied to specific places. Above, transcript snippets around positive associations with convenience. | Source: Attitudes and Experiences with Electric Vehicles, by Diana Lavery\n\n\n\n\nCheck out Mapping Quotes, Stories, Sentiments, and Experiences, by Diana Lavery & Clinton Johnson, which explores the use of qualitative data to explore the complexities in peoples’ behaviors, attitudes, and concerns.\n\n\nThe US needs ~500k more EV charging stations by 2030. Selecting locations is a complex spatial problem. Esri’s Living Atlas Policy Maps team conducted in-depth interviews with current EV drivers about their attitudes, experiences, and concerns with EV charging."
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes4",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes4",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n Use a mix of quantitative and qualitative approaches to tell a story\n\n Create a platform for engagement\n\n\n\nInteractivity allows users to find themselves in the data or discover stories.\n\n\n\n\n\n\n\n\n\n\n\nExplore reports by region and officer. | Source: Citizens Police Data Project, by Invisible Institute\n\n\n\n\nThe Citizens Police Data Project is an interactive online database and dashboard that empowers anyone to explore and analyze police misconduct data from Chicago. Trina Reynolds-Tyler, Data Director at Invisible Institute, spoke about this work at WiDS 2023 (~1:05:00)."
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes5a",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes5a",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n Use a mix of quantitative and qualitative approaches to tell a story\n\n Create a platform for engagement\n\n Consider how your framing of an issue can create a biased emotional response\n\n\nCrime maps are designed to show the frequency and location of crime incidents.\n\n\n\n\n\n\n\n\n\n\n\nTrulia crime map (San Francisco) | Source: When the Designer Shows Up In the Design, by Lena V. Groeger (ProPublica)\n\n\n\n\nTrulia removed it’s crime tab in 2022 after Redfin spoke out against the practice: “[G]iven the long history of redlining and racist housing covenants in the United States there’s too great a risk of this inaccuracy reinforcing racial bias. We believe that Redfin–and all real estate sites–should not show neighborhood crime data.” | Source: GeekWire | For more on biases in crime statistics, check out Buil-Gil et al. (2021)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes5b",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes5b",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n Use a mix of quantitative and qualitative approaches to tell a story\n\n Create a platform for engagement\n\n Consider how your framing of an issue can create a biased emotional response\n\n\n\n“Rather than looking at where crimes are committed, we looked at where prisoners live, and the maps that resulted showed the urban costs of incarceration and suggested how those dollars might be better spent on investing in communities.”\n\n\n-Laura Kurgan\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Million Dollar Blocks, by Columbia’s Center for Spatial Research"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#empathy-themes6",
    "href": "slides/week8.2-people-as-data-slides.html#empathy-themes6",
    "title": "EDS 240",
    "section": "",
    "text": "Connecting readers with content requires empathy\n\n\n\n Put people first\n\n Use personal connections to help readers and users connect with the material\n\n Use a mix of quantitative and qualitative approaches to tell a story\n\n Create a platform for engagement\n\n Consider how your framing of an issue can create a biased emotional response\n\n Recognize the needs of your audience\n\n\n\nMake sure visualizations are accessible so that folks with disabilities can view and use content online. Similarly, avoid overly technical or jargon-heavy language that make information inaccessible to a broad audience.\n\n\n\n\n\n\n\n\n\n\n\nImage sources: NCEAS, Design102, call focus"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#icons-good",
    "href": "slides/week8.2-people-as-data-slides.html#icons-good",
    "title": "EDS 240",
    "section": "",
    "text": "Use icons to embed empathy into data design\n\nSome chart types (e.g. bar, line, pie) abstract content by collapsing all people represented into one shape. Instead, try using individual points or even icons (i.e. anthropomorphize your data graphics)."
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#icons-bad",
    "href": "slides/week8.2-people-as-data-slides.html#icons-bad",
    "title": "EDS 240",
    "section": "",
    "text": "But using icons doesn’t guarantee empathy . . .\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Sabah Ibrahim (@reina_sabah), on X (formerly known as Twitter)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Design Your Way"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#aggregation",
    "href": "slides/week8.2-people-as-data-slides.html#aggregation",
    "title": "EDS 240",
    "section": "",
    "text": "How you (dis)aggregate your data can tell drastically different and important stories"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#take-aim",
    "href": "slides/week8.2-people-as-data-slides.html#take-aim",
    "title": "EDS 240",
    "section": "",
    "text": "“Take AIM”\n\n \n\n“Take AIM…Aggregate at intersections that matter”\n\n\n-Clinton Johnson in his keynote talk, Toward an Equitable and Just Geography, at the 2024 NCEAS Environmental Data Science Summit\n\n \nDecisions on how to aggregate data begin with the data collection stage, and continue through the analytical and communication stages.\n\nLooking for more? Check out A primer on an intersectional approach to data, by Global Partnership for Sustainable Development Data."
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#covid-unemployment",
    "href": "slides/week8.2-people-as-data-slides.html#covid-unemployment",
    "title": "EDS 240",
    "section": "",
    "text": "Variation in unemployment data at different intersections\n\nScreenshot from ProPublica’s graphic that allows you to visualize unemployment data aggregated at any three of the following intersections: race, gender, age class, education level, income level:\n\n\nSource: What Coronavirus Job Losses Reveal About Racism in America, by Lena V. Groeger (ProPublica)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#poverty-varitation",
    "href": "slides/week8.2-people-as-data-slides.html#poverty-varitation",
    "title": "EDS 240",
    "section": "",
    "text": "Variation in poverty rates across race categories\n\nThe US Census Bureau’s annual American Community Survey collects social, economic, housing, and demographic data which help to inform how trillions of dollars in federal funds are distributed each year.\nWhile the official U.S. poverty rate in 2019 was 12.3%, the plot below, by Schwabish & Feng (2021) (figure 08) shows the large variation in estimated poverty rates for each of the 139 racial groups from the American Community Survey. The overall poverty rate for each major racial groupings are included as well."
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#small-groups",
    "href": "slides/week8.2-people-as-data-slides.html#small-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Consider how to be inclusive of small groups\n\nAggregation is sometimes used to combine multiple (or many) groups when samples sizes are too small to display them individually. Consider adding a message / reference to small or missing groups to be inclusive:\n\n\nSource: What Coronavirus Job Losses Reveal About Racism in America, by Lena V. Groeger (ProPublica)"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#gender-identity1",
    "href": "slides/week8.2-people-as-data-slides.html#gender-identity1",
    "title": "EDS 240",
    "section": "",
    "text": "Telling nuanced stories begins at data collection\n\n\n\nSource: Do No Harm Guide, Figure 09 | I also encourage you to give @theannalytical a follow!!"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#gender-identity2",
    "href": "slides/week8.2-people-as-data-slides.html#gender-identity2",
    "title": "EDS 240",
    "section": "",
    "text": "Consider inclusive alternatives for “other”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Screenshot from a UCSB-administered survey (Feb 2024)\n\n\n\n“Collecting inclusive data and building inclusive tools and visualizations can make the experience better for all users.”\n\n\nSchwabish & Feng (2021)\n\nSome alternatives:\n\nAnother race (or gender, etc.)\nAdditional groups\nAll other self-descriptions\nPeople identifying as other or multiple races\nIdentity not listed\nIdentity not listed in this survey"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#data-humanism",
    "href": "slides/week8.2-people-as-data-slides.html#data-humanism",
    "title": "EDS 240",
    "section": "",
    "text": "Communicating data (in general, but particularly) about people is complicated. How can we translate numbers into concepts that people are drawn to and relate to?"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#tbd",
    "href": "slides/week8.2-people-as-data-slides.html#tbd",
    "title": "EDS 240",
    "section": "",
    "text": "“reconnect numbers to what they really stand for”\n\n\n\n“I started to work with data in 2010, 2011, and I saw that most of the approach to data at the time was very much based on a statistician’s background, and that’s fantastic. But I was also interested in using data myself as an anchoring point to tell stories. I thought that there’s just more that we could do to actually represent our reality if we include context, anecdotal details, if we embrace the imperfections that are inherent to how we collect data. And so, I started to just use these ideas in my practice, and I felt that I needed to just come up with an umbrella term for that. Data humanism was a good one, and data humanism is an approach to data that tries to reconnect numbers to what they really stand for by adding less factual and more anecdotal information.”\n\n\n-Giorgia Lupi in her interview with Fast Company"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#lupi-covid",
    "href": "slides/week8.2-people-as-data-slides.html#lupi-covid",
    "title": "EDS 240",
    "section": "",
    "text": "“Visualization is not about simplifying reality; it’s about providing an access to complexity”\n\n\n\nImage Source: 1374 Days - My Journey with Long Covid / NYT Visual OpED | Quote Source: Giorgia Lupi in her interview with Fast Company"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#happy-data",
    "href": "slides/week8.2-people-as-data-slides.html#happy-data",
    "title": "EDS 240",
    "section": "",
    "text": "Hopeful views of the world through data and drawings\n\n\n\nhttps://happy-data.co/, A project by Pentagram: Giorgia Lupi, with Ting Fang Cheng, Talia Cotton, Phil Cox, and Sarah Kay Miller"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#lupi-wft",
    "href": "slides/week8.2-people-as-data-slides.html#lupi-wft",
    "title": "EDS 240",
    "section": "",
    "text": "“in some cases, a warmer depiction of data can make people relate”\n\n\n\nSource: Happy Data, by Giorgia Lupi, with Ting Fang Cheng, Talia Cotton, Phil Cox, and Sarah Kay Miller | Quote Source: Giorgia Lupi in her interview with Fast Company"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#lupi-blm",
    "href": "slides/week8.2-people-as-data-slides.html#lupi-blm",
    "title": "EDS 240",
    "section": "",
    "text": "“if you get people to an emotional level, you might get them interested in learning more and spending more time”\n\n\n\nHappy Data, by Giorgia Lupi, with Ting Fang Cheng, Talia Cotton, Phil Cox, and Sarah Kay Miller | Quote Source: Giorgia Lupi in her interview with Fast Company"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#lupi-streets",
    "href": "slides/week8.2-people-as-data-slides.html#lupi-streets",
    "title": "EDS 240",
    "section": "",
    "text": "“beauty is such an entry point for everything”\n\n\n\nHappy Data, by Giorgia Lupi, with Ting Fang Cheng, Talia Cotton, Phil Cox, and Sarah Kay Miller | Quote Source: Giorgia Lupi in her interview with Fast Company"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#consider-examples",
    "href": "slides/week8.2-people-as-data-slides.html#consider-examples",
    "title": "EDS 240",
    "section": "",
    "text": "Consider the following examples of “people as data.” How do your perceive / interpret / comprehend the information across each version of the visualizations?"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#chalabi1",
    "href": "slides/week8.2-people-as-data-slides.html#chalabi1",
    "title": "EDS 240",
    "section": "",
    "text": "Destruction of Gaza, by Mona Chalabi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenshots taken on 2023-11-21 from @monachalabi, here in reverse order\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#chalabi2",
    "href": "slides/week8.2-people-as-data-slides.html#chalabi2",
    "title": "EDS 240",
    "section": "",
    "text": "Destruction of Gaza, by Mona Chalabi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenshots taken on 2023-11-21 from @monachalabi, here in reverse order\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#chalabi3",
    "href": "slides/week8.2-people-as-data-slides.html#chalabi3",
    "title": "EDS 240",
    "section": "",
    "text": "Destruction of Gaza, by Mona Chalabi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenshots taken on 2023-11-21 from @monachalabi, here in reverse order\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#ipcc1",
    "href": "slides/week8.2-people-as-data-slides.html#ipcc1",
    "title": "EDS 240",
    "section": "",
    "text": "Global temperatures, by the IPCC\n\n\n\n\nSource: The Climate Change 2023 Synthesis Report, by the Intergovernmental Panel on Climate Change (IPCC) | Also see This visual shows how climate change will affect generations, by Kasha Patel (Washington Post)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#ipcc2",
    "href": "slides/week8.2-people-as-data-slides.html#ipcc2",
    "title": "EDS 240",
    "section": "",
    "text": "Global temperatures, by the IPCC\n\n\n\n\nSource: The Climate Change 2023 Synthesis Report, by the Intergovernmental Panel on Climate Change (IPCC) | Also see This visual shows how climate change will affect generations, by Kasha Patel (Washington Post)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.2-people-as-data-slides.html#end-break",
    "href": "slides/week8.2-people-as-data-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 2 (of 2) ~"
  },
  {
    "objectID": "slides/week10.1-grab-bag-slides.html#title-slide",
    "href": "slides/week10.1-grab-bag-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 8.3\ntbd\n\nWeek 8 | February 26th, 2024"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#title-slide",
    "href": "slides/week1.3-ggplot-review-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 1.3\n{ggplot2} review\n\nWeek 1 | January 8th, 2024"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#ggplot2-advantages",
    "href": "slides/week1.3-ggplot-review-slides.html#ggplot2-advantages",
    "title": "EDS 240",
    "section": "",
    "text": "Advantages of {ggplot2}\n\n\n\n\n\n\n\nconsistent underlying “grammar of graphics” (Wilkinson 2005)\nsuper flexible, layered plot specification (see Wickham 2008)\ntheme system for polishing plot appearance\nlots of additional functionality thanks to extensions\nactive and helpful community\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nadapted from Cédric Scherer’s rstudio::conf(2022) workshop, Graphic Design with ggplot2\n\n\nGrammar of graphics: provides a structure to combine graphical elements into figures that display data in a meaningful way.\n\n–"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#grammar-of-graphics",
    "href": "slides/week1.3-ggplot-review-slides.html#grammar-of-graphics",
    "title": "EDS 240",
    "section": "",
    "text": "{ggplot2} is based on the Grammar of Graphics\n\n\n“A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g. the “scatterplot”) and gain insight into the deep structure that underlies statistical graphics.”\n\n\n-from Hadley Wickham’s A layered grammar of graphics in Journal of Computational and Graphical Statistics, vol. 19, no. 1 pp. 3-28, 2010.\n\n\n\n\n“In the grammar of a language, words have different parts of speech, which perform different roles in the sentence. Analagously, the grammar of graphics separates a graphic into different layers”\n\n\n-from Liz Sander’s post Telling stories with data using the grammar of graphics"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#graphic-layers",
    "href": "slides/week1.3-ggplot-review-slides.html#graphic-layers",
    "title": "EDS 240",
    "section": "",
    "text": "{ggplot2} graphic layers\n\n\nFirst these:\n1. data – in tidy format + define aesthetics (how variables map onto a plot e.g. axes, shape, color, size)\n2. geometric objects (aka geoms) – define the type of plot(s)\n\n\nThen these:\n3. statistical transformations – algorithm used to calculate new values for a graph\n4. position adjustments – control the fine details of position when geoms might otherwise overlap\n5. coordinate system – change what x and y axes mean (e.g. Cartesian (default), polar, flipped)\n6. facet – create subplots that each display one subset of the data\n\nNote: You many not apply or customize all of the above layers (or in this exact order) for every plot you build"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#comm-layers",
    "href": "slides/week1.3-ggplot-review-slides.html#comm-layers",
    "title": "EDS 240",
    "section": "",
    "text": "Enhance communication using additional layers\n\n\n1. labels – add / update titles, axis / legend labels\n2. annotations – add textual labels (e.g. to highlight specific data points or trend lines, etc.)\n3. scales – update how the aesthetic mappings manifest visually (e.g. colors scales, axis ticks, legends)\n4. themes – customize the non-data elements of your plot\n5. layout – combine multiple plots into the same graphic\n\nNote: You many not apply or customize all of the above layers (or in this exact order) for every plot you build"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#aside-tidy-data",
    "href": "slides/week1.3-ggplot-review-slides.html#aside-tidy-data",
    "title": "EDS 240",
    "section": "",
    "text": "An aside . . .\n\n\n\nArt by Allison Horst"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#tidy-data",
    "href": "slides/week1.3-ggplot-review-slides.html#tidy-data",
    "title": "EDS 240",
    "section": "",
    "text": "What is tidy data?\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#untidy-data",
    "href": "slides/week1.3-ggplot-review-slides.html#untidy-data",
    "title": "EDS 240",
    "section": "",
    "text": "Untidy data can take many different formats\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#untidy-temps",
    "href": "slides/week1.3-ggplot-review-slides.html#untidy-temps",
    "title": "EDS 240",
    "section": "",
    "text": "An example: untidy temperatures\n\nTake this tibble (a lazy / surly data.frame) of temperature recordings at three stations on three dates:\n\ntemp_data_wide &lt;- tribble(\n  ~date, ~station1, ~station2,  ~station3,\n  \"2023-10-01\", 30.1, 29.8,  31.2,\n  \"2023-11-01\", 28.6, 29.1,  33.4,\n  \"2023-12-01\", 29.9, 28.5,  32.3\n)\n\nprint(temp_data_wide)\n\n# A tibble: 3 × 4\n  date       station1 station2 station3\n  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2023-10-01     30.1     29.8     31.2\n2 2023-11-01     28.6     29.1     33.4\n3 2023-12-01     29.9     28.5     32.3\n\n\n\n\nThis tibble is in wide or untidy format."
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#make-temps-tidy",
    "href": "slides/week1.3-ggplot-review-slides.html#make-temps-tidy",
    "title": "EDS 240",
    "section": "",
    "text": "Make tidy temperatures!\n\n\nWith your learning partners, discuss the following:\n\n\n1.) What makes temp_data_wide untidy?\n\n\n2.) Sketch out on paper or talk through what temp_data_wide would look like in long aka tidy format. Why?\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#why-untidy-temps",
    "href": "slides/week1.3-ggplot-review-slides.html#why-untidy-temps",
    "title": "EDS 240",
    "section": "",
    "text": "An example: untidy temperatures\n\n\n\nMultiple observations (temperature recordings) per row\n\n\n\n\nWant more examples of untidy data? Check out these teaching materials from the NCEAS Learning Hub showcasing real-world examples of very untidy data."
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#tidy-temps",
    "href": "slides/week1.3-ggplot-review-slides.html#tidy-temps",
    "title": "EDS 240",
    "section": "",
    "text": "An example: tidy temperatures\n\nWe can use tidyr::pivot_longer() to “lengthen” our data aka convert it from wide / untidy to long / tidy:\n\ntemp_data_long &lt;- temp_data_wide |&gt; \n  pivot_longer(cols = starts_with(\"station\"),\n               names_to = \"station_id\",\n               values_to = \"temp_c\")\n\nprint(temp_data_long)\n\n# A tibble: 9 × 3\n  date       station_id temp_c\n  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;\n1 2023-10-01 station1     30.1\n2 2023-10-01 station2     29.8\n3 2023-10-01 station3     31.2\n4 2023-11-01 station1     28.6\n5 2023-11-01 station2     29.1\n6 2023-11-01 station3     33.4\n7 2023-12-01 station1     29.9\n8 2023-12-01 station2     28.5\n9 2023-12-01 station3     32.3"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#tidy-data-benefits",
    "href": "slides/week1.3-ggplot-review-slides.html#tidy-data-benefits",
    "title": "EDS 240",
    "section": "",
    "text": "Benefits of tidy data\n\n\n\nArtwork by Allison Horst"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#wrangling-fxns",
    "href": "slides/week1.3-ggplot-review-slides.html#wrangling-fxns",
    "title": "EDS 240",
    "section": "",
    "text": "Data viz almost always begins with data wrangling\n\nThe {tidyverse} is an “opinionated” set of packages – meaning they share similar philosophies, grammar, and data structures – that are incredibly useful for data wrangling, cleaning, and manipulation (and of course, visualization).\n\n\n\n\n\n\n\n\n\n\n\n\nCheck out the tidyverse website to learn more about each of these packages\n\n\n\n\n\n\n\n\n\n\n\n\nThe best resource for learning all things R for Data Science!"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#moving-on",
    "href": "slides/week1.3-ggplot-review-slides.html#moving-on",
    "title": "EDS 240",
    "section": "",
    "text": "Okay, moving on . . .\n\n\nLet’s make some ggplots using data from {palmerpenguins} (which are already tidy)!\n\n\n\nArtwork by Allison Horst\n\n\nThe examples on the following slides were adapted from R for Data Science, Chapters 2 and 10."
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#plot1",
    "href": "slides/week1.3-ggplot-review-slides.html#plot1",
    "title": "EDS 240",
    "section": "",
    "text": "Plot #1\n\n\nWe’ll start by exploring the relationship between penguin bill length and bill depth. For this example, we’ll focus on understanding the following layers of a ggplot (bolded):\n\n Graphic layers:\n1. data – in tidy format + define aesthetics (how variables map onto a plot e.g. axes, shape, color, size)\n2. geometric objects (aka geoms) – define the type of plot(s)\n3. statistical transformations – algorithm used to calculate new values for a graph\n4. position adjustments – control the fine details of position when geoms might otherwise overlap\n5. coordinate system – change what x and y axes mean (e.g. Cartesian (default), polar, flipped)\n6. facet – create subplots that each display one subset of the data\n “Enhancing communication” layers:\n1. labels – add / update titles, axis / legend labels\n2. annotations – add textual labels (e.g. to highlight specific data points or trend lines, etc.)\n3. scales – update how the aesthetic mappings manifest visually (e.g. colors scales, axis ticks, legends)\n4. themes– customize the non-data elements of your plot\n5. layout – combine multiple plots into the same graphic"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#initialize",
    "href": "slides/week1.3-ggplot-review-slides.html#initialize",
    "title": "EDS 240",
    "section": "",
    "text": "Initialize a plot object\n\nInitialize your plot object using ggplot() – this creates a graph that’s primed to display the penguins data set, but empty since we haven’t told ggplot how to map our data onto the graph yet (in other words: we haven’t told ggplot what variables to display and where, as well as what type of plot to create):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(data = penguins)\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#aesthetics",
    "href": "slides/week1.3-ggplot-review-slides.html#aesthetics",
    "title": "EDS 240",
    "section": "",
    "text": "Initialize a plot object + map aesthetics\n\nThe mapping argument defines how variables in your data set are mapped to visual properties (aesthetics) of your plot. Here, we specify which variables map to our x and y axes:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet\n\n\nWe’ve specified which variables map onto the x & y axes but still have not yet articulated how to represent the observations"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#omitting-arg-names",
    "href": "slides/week1.3-ggplot-review-slides.html#omitting-arg-names",
    "title": "EDS 240",
    "section": "",
    "text": "Omitting argument names\n\nThe data and mapping arguments are often not explicitly written in ggplot(), as in the example below (makes for more concise code):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#piping-in",
    "href": "slides/week1.3-ggplot-review-slides.html#piping-in",
    "title": "EDS 240",
    "section": "",
    "text": "Piping into a ggplot\n\nYou can also pipe (using %&gt;% or |&gt;) directly from a data set into a ggplot() call (we’ll use more of this in future lessons). When doing so, omit the data argument from ggplot():\n\npenguins |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#geom",
    "href": "slides/week1.3-ggplot-review-slides.html#geom",
    "title": "EDS 240",
    "section": "",
    "text": "Define a geom to represent data\n\nNext, we’ll layer on a geometric object (aka geom) that our plot will use to represent our penguin data. There are many geoms (geom_*()) that are built into {ggplot2} already (and more when you use extension packages). To create a scatterplot:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point()\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#dat-map-in-geom",
    "href": "slides/week1.3-ggplot-review-slides.html#dat-map-in-geom",
    "title": "EDS 240",
    "section": "",
    "text": "Defining data & mappings in geom_*()\n\nYou can also define the data and mapping layers within a geom_*() (rather than ggplot()) – this is helpful if you plan to have multiple geoms with different mappings:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot() +\n  geom_point(data = penguins, mapping = aes(x = bill_length_mm, y = bill_depth_mm))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#color-points-by-spp",
    "href": "slides/week1.3-ggplot-review-slides.html#color-points-by-spp",
    "title": "EDS 240",
    "section": "",
    "text": "Use color to differentiate species\n\nIf we’d like to represent species using another aesthetic (e.g. color, shape, size), we need to modify our plot’s aesthetic (i.e. inside aes()) – any time we want to modify the appearance of our plotted data based on a variable in our dataset, we do so within aes(). This process is known as scaling. A legend will automatically be added to indicate which values (in this case, colors) correspond to which level of our variable (in this case, species):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point()\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#color-points-by-spp-local",
    "href": "slides/week1.3-ggplot-review-slides.html#color-points-by-spp-local",
    "title": "EDS 240",
    "section": "",
    "text": "Mapping color at a local level\n\nAlternatively, map color at a local (i.e. within a specific geom) rather than global (i.e. within ggplot()) layer:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(aes(color = species))\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#why-local-mapping",
    "href": "slides/week1.3-ggplot-review-slides.html#why-local-mapping",
    "title": "EDS 240",
    "section": "",
    "text": "Why map locally?\n\nHere, we use geom_smooth() to add a best fit line (based on a linear model, using method = \"lm\") to our plot:\n\n\nGlobal mappings are passed down to each subsequent geom layer. Therefore, the color = species mapping is also passed to geom_smooth(), resulting in a best fit line for each species.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nLocal mappings (e.g. within geom_point()) only apply to that particular layer. Therefore, the color = species mapping is only applied to geom_point(), and geom_smooth() fits a best fit line to the entire data set.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#one-color",
    "href": "slides/week1.3-ggplot-review-slides.html#one-color",
    "title": "EDS 240",
    "section": "",
    "text": "What if we just want to color all points the same?\n\nDo so within the corresponding geom_*() and outside of the aes() function! Color is no longer being mapped to a variable.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(color = \"blue\")"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#scale-color-manual",
    "href": "slides/week1.3-ggplot-review-slides.html#scale-color-manual",
    "title": "EDS 240",
    "section": "",
    "text": "We can also map our own colors\n\nHere, we use scale_color_manual() to update the colors of our data points. Colors will be mapped from the levels in our data (i.e. Adelie, Chinstrap, Gentoo) to the order of the aethetic values supplied (\"#FF8302\", \"#C35CCA\", \"#067575\"):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  scale_color_manual(values = c(\"#FF8302\", \"#C35CCA\", \"#067575\"))\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#color-points-by-mass",
    "href": "slides/week1.3-ggplot-review-slides.html#color-points-by-mass",
    "title": "EDS 240",
    "section": "",
    "text": "Use color to describe a continuous variable\n\nIn the previous example, we mapped color to a categorical variable (species). We can also map color to continuous variables (e.g. body_mass_g):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, color = body_mass_g)) +\n  geom_point() +\n  scale_color_gradient(low = \"#132B43\", high = \"#F7DD4C\")\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#plot2",
    "href": "slides/week1.3-ggplot-review-slides.html#plot2",
    "title": "EDS 240",
    "section": "",
    "text": "Plot #2\n\n\nIn this next example, we’ll explore penguin species counts. For this example, we’ll focus on understanding the following layers of a ggplot (bolded):\n\n Graphic layers:\n1. data – in tidy format + define aesthetics (how variables map onto a plot e.g. axes, shape, color, size)\n2. geometric objects (aka geoms) – define the type of plot(s)\n3. statistical transformations – algorithm used to calculate new values for a graph\n4. position adjustments – control the fine details of position when geoms might otherwise overlap\n5. coordinate system – change what x and y axes mean (e.g. Cartesian (default), polar, flipped)\n6. facet – create subplots that each display one subset of the data\n “Enhancing communication” layers:\n1. labels – add / update titles, axis / legend labels\n2. annotations – add textual labels (e.g. to highlight specific data points or trend lines, etc.)\n3. scales – update how the aesthetic mappings manifest visually (e.g. colors scales, axis ticks, legends)\n4. themes– customize the non-data elements of your plot\n5. layout – combine multiple plots into the same graphic"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#basic-barplot",
    "href": "slides/week1.3-ggplot-review-slides.html#basic-barplot",
    "title": "EDS 240",
    "section": "",
    "text": "Initialize + map aesthetics + define geom\n\nSimilar to our first scatterplot, we start by initializing our plot object with data, mapping our aesthetics, and defining a geometric object:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#stat-transformation",
    "href": "slides/week1.3-ggplot-review-slides.html#stat-transformation",
    "title": "EDS 240",
    "section": "",
    "text": "What is a statistical transformation?\n\nSome geoms, like scatterplots, plot the raw values of your data set. Other geoms, like bar charts, histograms, boxplots, smoothers, etc. calculate new values to plot.\n\n\nEach point on our scatterplot represents a raw observation value (one point = one penguin)\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nEach bar represents a species count (note the y-axis, count, which is not a variable in our penguins data set)\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#default-stat",
    "href": "slides/week1.3-ggplot-review-slides.html#default-stat",
    "title": "EDS 240",
    "section": "",
    "text": "The default stat for geom_bar() is “count”\n\nEvery geom has a default stat – meaning you can typically use geoms without worrying about the underlying statistical transformation.\nThe default statistical transformation used in geom_bar() is count, which first groups our categorical variable (species), then calculates a count for each unique level (Adelie, Chinstrap, Gentoo).\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar(stat = \"count\") # you don't need to explicitly include `stat = \"count\"` since it's the default\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#override-default-stat",
    "href": "slides/week1.3-ggplot-review-slides.html#override-default-stat",
    "title": "EDS 240",
    "section": "",
    "text": "We can override the default stat\n\nLet’s say we have a data frame with calculated count values (e.g. penguins_summary) that we’d like to plot using geom_bar(). We can change stat = \"count\" (default) to stat = \"identity\" to generate bar heights based off the “identity” of values in the n column of penguin_summary.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\npenguin_summary &lt;- penguins |&gt; \n  count(species) # calculate number of observations (rows) for each species\n\nggplot(penguin_summary, aes(x = species, y = n)) + \n  geom_bar(stat = \"identity\")\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#stat-mapping",
    "href": "slides/week1.3-ggplot-review-slides.html#stat-mapping",
    "title": "EDS 240",
    "section": "",
    "text": "We can override the default stat mapping\n\nNow let’s say we’d like to display the same bar chart with y-axis values as proportions, rather than counts. We can override the default mapping from transformed variables to aesthetics by doing the following:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species, y = after_stat(prop), group = 1)) +\n  geom_bar()\n\n\nNOTE: Including group = 1 overrides the default behavior of geom_bar() to group by the x variable. The default behavior of geom_bar() is to group by the x variable (for us, that’s species) to separately count the number of rows in each level (Adelie, Chinstrap, Gentoo). If we want proportions, we need to consider all levels of species together to calculate the proportion of each level of species relative to all levels of species.\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#stat-summary",
    "href": "slides/week1.3-ggplot-review-slides.html#stat-summary",
    "title": "EDS 240",
    "section": "",
    "text": "We can use stat_summary() to compute & plot any aggregate\n\nHere, we plot the min, mean, and max values of penguin body_mass_g by species:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins) +\n  stat_summary(\n    aes(x = species, y = body_mass_g),\n    fun.max = max, \n    fun.min = min,\n    fun = mean\n  )\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#pos-adj",
    "href": "slides/week1.3-ggplot-review-slides.html#pos-adj",
    "title": "EDS 240",
    "section": "",
    "text": "What is a position adjustment?\n\nPosition adjustments apply minor tweaks to the position of elements to resolve overlapping geoms. For example, let’s say we would like to visualize penguin counts by species (bar height) and by island (color) using our bar chart from earlier. We could add the fill aesthetic:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar()\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#pos-default-bar",
    "href": "slides/week1.3-ggplot-review-slides.html#pos-default-bar",
    "title": "EDS 240",
    "section": "",
    "text": "The default position for geom_bar() is “stack”\n\nEvery geom has a default position. The default position used in geom_bar() is stack, which stacks bars on top of one another, based on the fill value (here, that’s island):\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") # you don't need to explicitly include `position = \"stack\"` since it's the default\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#pos-alts",
    "href": "slides/week1.3-ggplot-review-slides.html#pos-alts",
    "title": "EDS 240",
    "section": "",
    "text": "Alternative position adjustments for geom_bar()\n\nBelow are a few position options available for use with geom_bar():\n\n\nposition = \"fill\" creates a set of stacked bars but makes each set the same height (easier to compare proportions across groups)\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\nposition = \"dodge\" places overlapping bars directly beside one another (easier to compare individual values)\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#pos-alt",
    "href": "slides/week1.3-ggplot-review-slides.html#pos-alt",
    "title": "EDS 240",
    "section": "",
    "text": "Alternatively, use position = position_*()\n\nInstead of position = \"X\", you can use functions to update and further adjust your geom’s positions. Here, we’ll use position_dodge2() to also ensure the widths of each of our bars are equal:\n\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = position_dodge2(preserve = \"single\"))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#default-coord",
    "href": "slides/week1.3-ggplot-review-slides.html#default-coord",
    "title": "EDS 240",
    "section": "",
    "text": "What is a coordinate system?\n\nA Coordinate System is a system that uses one or more numbers (coordinates), to uniquely determine the position of points or other geometric elements. By default, ggplots are constructed in a Cartesian coordinate system, consisting of a horizontal x-axis and vertical y-axis.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  coord_cartesian() # you don't need to explicitly include `coord_cartesian()` since it's the default\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#coord",
    "href": "slides/week1.3-ggplot-review-slides.html#coord",
    "title": "EDS 240",
    "section": "",
    "text": "Changing coordinate systems\n\nDepending on the type of data, axis label length, etc. it may make sense to change this coordinate system. Two options for our bar plot:\n\n\ncoord_flip() switches the x and y axes.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() + \n  coord_flip()\n\n\n\n\n\n\n\n\n\ncoord_polar() uses polar coordinates.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() + \n  coord_polar()\n\n\n\n\n\n\n\n\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#prebuilt-themes",
    "href": "slides/week1.3-ggplot-review-slides.html#prebuilt-themes",
    "title": "EDS 240",
    "section": "",
    "text": "Use pre-made themes to update plot appearance\n\n{ggplot2} comes with a number of complete themes, which control all non-data display. See two examples below:\n\n\ndisplays x and y axis lines and no gridlines\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\ndisplays light grey lines and axes\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#custom-themes",
    "href": "slides/week1.3-ggplot-review-slides.html#custom-themes",
    "title": "EDS 240",
    "section": "",
    "text": "Further customize plot appearance using theme()\n\nFurther modify nearly any non-data element of your plot using theme().\n\n\nStart with theme_light():\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  theme_light()\n\n\n\n\n\n\n\n\n\nFurther modify with theme():\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  theme_light() +\n  theme(\n    axis.title = element_text(size = 17, color = \"purple\")\n  )\n\n\n\n\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#plot3",
    "href": "slides/week1.3-ggplot-review-slides.html#plot3",
    "title": "EDS 240",
    "section": "",
    "text": "Plot #3\n\n\nIn this next example, we’ll explore penguin flipper lengths. For this example, we’ll focus on understanding the following layers of a ggplot (bolded):\n\n Graphic layers:\n1. data – in tidy format + define aesthetics (how variables map onto a plot e.g. axes, shape, color, size)\n2. geometric objects (aka geoms) – define the type of plot(s)\n3. statistical transformations – algorithm used to calculate new values for a graph\n4. position adjustments – control the fine details of position when geoms might otherwise overlap\n5. coordinate system – change what x and y axes mean (e.g. Cartesian (default), polar, flipped)\n6. facet – create subplots that each display one subset of the data\n “Enhancing communication” layers:\n1. labels – add / update titles, axis / legend labels\n2. annotations – add textual labels (e.g. to highlight specific data points or trend lines, etc.)\n3. scales – update how the aesthetic mappings manifest visually (e.g. colors scales, axis ticks, legends)\n4. themes– customize the non-data elements of your plot\n5. layout – combine multiple plots into the same graphic"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#basic-histogram",
    "href": "slides/week1.3-ggplot-review-slides.html#basic-histogram",
    "title": "EDS 240",
    "section": "",
    "text": "Initialize + map aesthetics + define geom\n\nWe’ll again start by initializing our plot object with data, mapping our aesthetics, and defining a geometric object. Note that the default statistical transformation for geom_histogram() is stat = \"bin\":\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm)) + \n  geom_histogram()\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#color-bins-by-spp",
    "href": "slides/week1.3-ggplot-review-slides.html#color-bins-by-spp",
    "title": "EDS 240",
    "section": "",
    "text": "Use color to differentiate species\n\nJust like in our scatterplot (Plot #1), we’ll modify our plot’s aesthetics (i.e. inside aes()) to color our histrogram bins according to the species variable. Unlike our scatterplot (which uses the color argument), we’ll use the fill argument to fill the bars with color (rather than outline them with color). We’ll also manually define our fill scale:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) + \n  geom_histogram() +\n  scale_fill_manual(values = c(\"#FF8302\", \"#C35CCA\", \"#067575\"))\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#pos-default-hist",
    "href": "slides/week1.3-ggplot-review-slides.html#pos-default-hist",
    "title": "EDS 240",
    "section": "",
    "text": "Update the default position to \"identity\"\n\nLet’s update the position of our binned bars from \"stack\" to \"identity\" and also increase the transparency (using alpha) so that we can see overlapping bars:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) + \n  geom_histogram(position = \"identity\", alpha = 0.5) +\n  scale_fill_manual(values = c(\"#FF8302\", \"#C35CCA\", \"#067575\"))\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#labels",
    "href": "slides/week1.3-ggplot-review-slides.html#labels",
    "title": "EDS 240",
    "section": "",
    "text": "Update / add plot labels\n\nUpdate axis and legend titles and add a plot title using labs():\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) + \n  geom_histogram(position = \"identity\", alpha = 0.5) +\n  scale_fill_manual(values = c(\"#FF8302\", \"#C35CCA\", \"#067575\")) +\n  labs(x = \"Flipper length (mm)\", y = \"Frequency\", fill = \"Species\",\n       title = \"Penguin Flipper Lengths\")\n\n\n\nlabels | annotations | scales | themes | layout"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#faceting",
    "href": "slides/week1.3-ggplot-review-slides.html#faceting",
    "title": "EDS 240",
    "section": "",
    "text": "Create subplots using facets\n\nSometimes (particularly during the data exploration phase) it’s helpful to create subplots (i.e. separate panels) of your data. Here we use facet_wrap() to separate our data by the species variable. By default, it creates a 1 x 3 matrix of plots. We can manually specify how many rows or columns we’d like using nrow or ncol:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) + \n  geom_histogram(position = \"identity\", alpha = 0.5) +\n  scale_fill_manual(values = c(\"#FF8302\", \"#C35CCA\", \"#067575\")) +\n  labs(x = \"Flipper length (mm)\", y = \"Frequency\", fill = \"Species\",\n       title = \"Penguin Flipper Lengths\") + \n  facet_wrap(~species, ncol = 1)\n\n\n\ndata | geometric object | statistical transformation | position adjustment | coordinate system | facet"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#evo-ggplot",
    "href": "slides/week1.3-ggplot-review-slides.html#evo-ggplot",
    "title": "EDS 240",
    "section": "",
    "text": "Building a data viz is an iterative process!\n\nWe’ll spend the next two weeks learning how to build some basic fundamental charts and talking about important considerations when choosing a graphic form for presenting your data. Then, we’ll move into graphic design theory and the tools and packages in the {ggplot2} ecosystem that make it possible.\n\n\nVisualization by Cédric Scherer, from his blog post, The Evolution of a ggplot (Ep.1) – create your own ggplot evolution gif using the {camcorder} package"
  },
  {
    "objectID": "slides/week1.3-ggplot-review-slides.html#end-break",
    "href": "slides/week1.3-ggplot-review-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 3 (of 3) ~"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#title-slide",
    "href": "slides/week8.1-data-stories-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 8.1\nData storytelling\n\nWeek 8 | February 26th, 2024"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#good-design",
    "href": "slides/week8.1-data-stories-slides.html#good-design",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#data-storytelling-job",
    "href": "slides/week8.1-data-stories-slides.html#data-storytelling-job",
    "title": "EDS 240",
    "section": "",
    "text": "Our job is to turn values and analyses into insights and narratives – doing so truthfully, effectively, and compellingly is all a part of data storytelling."
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#nothing-new",
    "href": "slides/week8.1-data-stories-slides.html#nothing-new",
    "title": "EDS 240",
    "section": "",
    "text": "We won’t be covering anything new, per se\n\n \n\nFrom a technical perspective, you have the tools in your tool kit to build data viz that tell stories.\n\n\n\n\nWe’ve seen many examples of data visualizations that are constructed around a narrative (whether or not we explicitly called attention to it).\n\n\n\n\n\nYou have all listened to, read, and told stories (in this class, in other classes, in life)."
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#why-storytelling",
    "href": "slides/week8.1-data-stories-slides.html#why-storytelling",
    "title": "EDS 240",
    "section": "",
    "text": "Why is storytelling important?\n\n\n\n“…the very act of telling a story makes people trust you more… Data doesn’t change behavior, emotions do”\n\n\n-Karen Eber in her TED talk, Why storytelling is more trustworthy than presenting data (2:45-7:07)\n\n \n\n\n“Stories are inherent to us. We’ve been told stories since we were children. Stories are how we learn and how we make decisions.”\n\n\n-Mike Bugembe in his TED talk, Lies, racism and sexism: The power of data stories (13:00-17:50)\n\n\nI also recommend watching The Power in Effective Data Storytelling, by Malavica Sridhar and Why Data Storytelling Matters to All of Us, by Jia Hwei Ng"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#how-to-storytell",
    "href": "slides/week8.1-data-stories-slides.html#how-to-storytell",
    "title": "EDS 240",
    "section": "",
    "text": "Telling a story involves . . .\n\n\n\nadding context\n\n\nmakes it relevant / mean something to your audience\n\n\n\nadding narrative\n\n\nyou want stories to be told in a way that everyone can understand\n\n\n\ncreating visuals\n\n\nbrings your narrative to life / makes it real"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#practice-storytelling",
    "href": "slides/week8.1-data-stories-slides.html#practice-storytelling",
    "title": "EDS 240",
    "section": "",
    "text": "Let’s practice storytelling\n\n\n\nDon’t advance the slides until I say so!\n\n\nOn the next few slides, we’ll see a series of data visualizations. First basic, then with additional layers added. These are data you’ve seen many times before.\n\n\n\n\nFor each version, consider the following questions:\n\n\nwho / what is the subject?\nwho might the audience be?\nwhat message / narrative pops out, if any?\nwhat context is needed to better tell this story?"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#tell-story1",
    "href": "slides/week8.1-data-stories-slides.html#tell-story1",
    "title": "EDS 240",
    "section": "",
    "text": "Tell a story about this plot\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#tell-story2",
    "href": "slides/week8.1-data-stories-slides.html#tell-story2",
    "title": "EDS 240",
    "section": "",
    "text": "Tell a story about this plot\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#tell-story3",
    "href": "slides/week8.1-data-stories-slides.html#tell-story3",
    "title": "EDS 240",
    "section": "",
    "text": "Tell a story about this plot\n\n\n\n\n\n−+\n03:00\n\n\n\n\nRecreated based on Cédric Scherer’s visualization as showcased in his talk, ggplot Wizardry: My Favorite Tricks and Secrets for Beautiful Plots in R"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#plot-code",
    "href": "slides/week8.1-data-stories-slides.html#plot-code",
    "title": "EDS 240",
    "section": "",
    "text": "Complete code (in case you’re interested)\n\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(showtext)\n\n#...........................load fonts...........................\nfont_add_google(name = \"Montserrat\", family = \"montserrat\")\nshowtext_auto()\n\n#.................get and assemble penguin image.................\n# only need to run these first two lines once to download image: \n# url &lt;- \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/culmen_depth.png\"\n# utils::download.file(url = url, destfile =  here::here(\"week8\", \"images\", \"penguin.png\"))\nmy_img &lt;- png::readPNG(here::here(\"week8\", \"images\", \"penguin.png\"))\nmy_raster_img &lt;- grid::rasterGrob(my_img)\n\n#...........................build plot...........................\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = body_mass_g)) +\n  geom_point(alpha = 0.8, size = 2) +\n  ggforce::geom_mark_ellipse(aes(group = species, label = species),\n                    color = \"black\") +\n  scale_color_gradientn(colors = c(\"#F3E5B1\", \"#6C7B1A\", \"#044148\")) +\n  guides(color = guide_colorbar(barwidth = 20, barheight = 0.5, \n                                title.position = \"top\", title.hjust = 0.5,\n                                ticks = FALSE)) +\n  scale_x_continuous(breaks = seq(25, 65, 5),\n                     limits = c(25, 65),\n                     expand = c(0,0)) +\n  scale_y_continuous(breaks = seq(12, 24, 2),\n                     limits = c(12, 24),\n                     expand = c(0,0)) +\n  labs(x = \"**Bill Length** (mm)\",\n       y = \"**Bill Depth** (mm)\",\n       color = \"Body Mass (g)\",\n       title = \"**Bill Dimensions of Brush-Tailed Penguins (*Phygoscelis*)**\",\n       caption = \"Data: Gorman, Williams, Fraser (2014) PLoS ONE | Illustration: Allison Horst\") +\n  theme_light() +\n  theme(\n    plot.title.position = \"plot\",\n    legend.position = \"top\",\n    text = element_text(family = \"montserrat\"),\n    plot.title = ggtext::element_textbox_simple(size = 20,\n                                                margin = margin(0.5, 0, 1, 0.25, \"lines\")),\n    axis.title.x = ggtext::element_markdown(size = 15,\n                                            margin = margin(1, 0, 0, 0, \"lines\")),\n    axis.title.y = ggtext::element_markdown(size = 15,\n                                            margin = margin(0, 1, 0, 0, \"lines\")),\n    axis.text = element_text(size = 10),\n    axis.ticks = element_blank(),\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 10),\n    plot.caption = element_text(face = \"italic\",\n                                margin = margin(2, 0, 0, 0, \"lines\")),\n    panel.grid.minor = element_blank()\n  ) +\n  coord_cartesian(clip = \"off\") +\n  annotation_custom(my_raster_img, \n                    xmin = 56.8, xmax = 65.8,\n                    ymin = 22, ymax = 30) \n\n\nNote: The positioning / size of text, penguin image, etc. was chosen based on how it looked as rendered in the slides. You may need to modify for viewing on your own device."
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#scroll-stories",
    "href": "slides/week8.1-data-stories-slides.html#scroll-stories",
    "title": "EDS 240",
    "section": "",
    "text": "Scrollable data stories help to weave longer narratives\n\n\nTake some time to explore these with your learning partners and be prepared to share out some thoughts.\n\n\nA fishery in a sea of change, by Amalia Harrington, Jennie Rheuban, and Carolina Bastidas\nWhat’s that bug?, by Esri’s StoryMaps Team\nWhy Arctic fires are releasing more carbon, by Simon Scarr\nThe collapse of insects, by Julia Janicki, Gloria Dickie, Simon Scarr and Jitesh Chowdhury\nPlastic Air, by Giorgia Lupi\nThe fry universe, by Chris Williams\nU.S. Gun Deaths in 2013, by Periscopic\nBussed Out: How American moves its homeless, by the Outside in America team\nThe unexpected link between imperiled whales and Greenland’s melting ice, by NPR\nReuters graphics (a collection)\n20 Best Data Storytelling Examples (Updated for 2023), by Zach Gemignani\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#static-viz-stories",
    "href": "slides/week8.1-data-stories-slides.html#static-viz-stories",
    "title": "EDS 240",
    "section": "",
    "text": "We’ve shown that static viz can also tell stories\n\n\nThe next ten slides (14 - 23) each have a different static visualization. With your learning partner(s), discuss the following:\n\n\nwhat story(ies) is the viz being used to tell?\nwhat design elements (e.g. text, color, images) do they authors use to help tell the story?\nhow do the authors provide context (may be related to your above answer)?\nwhat is the purpose of this viz (e.g. to answer a question, spark additional questions, etc.)?\nwhat do you find effective? what don’t you find effective?\n\n\nNote: You don’t need to get to every viz! There are lots of options so you can explore those that peak your interest most.\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#jan6",
    "href": "slides/week8.1-data-stories-slides.html#jan6",
    "title": "EDS 240",
    "section": "",
    "text": "The Jan. 6 inquiry, by the numbers (New York Times)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#china-pop",
    "href": "slides/week8.1-data-stories-slides.html#china-pop",
    "title": "EDS 240",
    "section": "",
    "text": "China’s population continues to shrink as deaths outnumber births (New York Times)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#can-fires",
    "href": "slides/week8.1-data-stories-slides.html#can-fires",
    "title": "EDS 240",
    "section": "",
    "text": "Wildfires in Canada burned this much land so far this year (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#ca-oil",
    "href": "slides/week8.1-data-stories-slides.html#ca-oil",
    "title": "EDS 240",
    "section": "",
    "text": "‘Catastrophic’ California oil spill kills fish, damaages wetlands (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#clean-fuel",
    "href": "slides/week8.1-data-stories-slides.html#clean-fuel",
    "title": "EDS 240",
    "section": "",
    "text": "Access to clean fuels and technologies for cooking (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#cacti",
    "href": "slides/week8.1-data-stories-slides.html#cacti",
    "title": "EDS 240",
    "section": "",
    "text": "Almost half of U.S. cacti are vulnerable to extinction (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#messi",
    "href": "slides/week8.1-data-stories-slides.html#messi",
    "title": "EDS 240",
    "section": "",
    "text": "Lionel Messi: all 672 goals for Barcelona by season (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#refugees",
    "href": "slides/week8.1-data-stories-slides.html#refugees",
    "title": "EDS 240",
    "section": "",
    "text": "Refugees resettled in the United States (Reuters)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#employed",
    "href": "slides/week8.1-data-stories-slides.html#employed",
    "title": "EDS 240",
    "section": "",
    "text": "How employed people spend their day (New York Times)"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#hockey-stick",
    "href": "slides/week8.1-data-stories-slides.html#hockey-stick",
    "title": "EDS 240",
    "section": "",
    "text": "“Hockey Stick” graph, by Mann et al. (1999)\n\n\nData from thermometers (red) and from tree rings, corals, ice cores, and historical records (blue)."
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#storytelling-forms",
    "href": "slides/week8.1-data-stories-slides.html#storytelling-forms",
    "title": "EDS 240",
    "section": "",
    "text": "Anytime we present data, we have the opportunity to tell a story\n\n\n oral talks\n\n academic journal articles\n\n blog posts\n\n dashboards\n\n infographics / static visualizations"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#reminders",
    "href": "slides/week8.1-data-stories-slides.html#reminders",
    "title": "EDS 240",
    "section": "",
    "text": "A few last important reminders before you jump back into storytelling. . ."
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#id-audience",
    "href": "slides/week8.1-data-stories-slides.html#id-audience",
    "title": "EDS 240",
    "section": "",
    "text": "Identify your audience\n\n\n\nTo tell a clear story, you need to know your audience\n\n\n\n\nWhich story is interesting for them?\nWhat are relevant details to include?\nWhich variables are meaningful to them?\nHow will they encounter the visualization?\nDo I need a visualization at all?\n\n\n\n\n\n\nData viz can look wildly different depending on how you answer the above questions!\n\n\nFrom Cédric Scherer’s talk, Effective Data Visualization and Graphic Design with ggplot2 workshop"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#chalabi",
    "href": "slides/week8.1-data-stories-slides.html#chalabi",
    "title": "EDS 240",
    "section": "",
    "text": "Consider the audience\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeven endangered species that could (almost) fit in a single train carriage, by Mona Chalabi (two of seven shown here)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#ingeman",
    "href": "slides/week8.1-data-stories-slides.html#ingeman",
    "title": "EDS 240",
    "section": "",
    "text": "Consider the audience\n\n\n\n\nFig. 3, by Ingeman et al. 2022: Glimmers of hope and critical cases. Find figure caption online.\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#scherer",
    "href": "slides/week8.1-data-stories-slides.html#scherer",
    "title": "EDS 240",
    "section": "",
    "text": "Consider the audience\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlants in Danger, by Cédric Scherer (code)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#data-samples1",
    "href": "slides/week8.1-data-stories-slides.html#data-samples1",
    "title": "EDS 240",
    "section": "",
    "text": "Understand your data & be accurate\n\nThis has less to do with the physical act of creating data viz / telling a story and everything to do with your own critical examination of your data and domain expertise. Two important reminders:\n\n\n\n\nOur data is never a perfect reflection of the real world – our data is always a sample\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Cédric Scherer’s talk, Effective Data Visualization and Graphic Design with ggplot2 workshop"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#data-samples2",
    "href": "slides/week8.1-data-stories-slides.html#data-samples2",
    "title": "EDS 240",
    "section": "",
    "text": "Understand your data & be accurate\n\nThis has less to do with the physical act of creating data viz / telling a story and everything to do with your own critical examination of your data and domain expertise. Two important reminders:\n\n\n\nOur data is never a perfect reflection of the real world – our data is always a sample\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Cédric Scherer’s talk, Effective Data Visualization and Graphic Design with ggplot2 workshop"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#what-isnt-true",
    "href": "slides/week8.1-data-stories-slides.html#what-isnt-true",
    "title": "EDS 240",
    "section": "",
    "text": "Understand your data & be accurate\n\nThis has less to do with the physical act of creating data viz / telling a story and everything to do with your own critical examination of your data and domain expertise. Two important reminders:\n\n\n\nOur data is never a perfect reflection of the real world – our data is always a sample\n\n\n\nThe best use of data is to teach us what isn’t true – you should be challenging yourself to find out something with your data, not to show that your assumptions about what you’ll find are true\n\n\n\n\n\n\n\n\n\n\n\n\nAvoiding Data Pitfalls, by Ben Jones\n\n\n\n\nFrom Cédric Scherer’s talk, Effective Data Visualization and Graphic Design with ggplot2 workshop"
  },
  {
    "objectID": "slides/week8.1-data-stories-slides.html#break",
    "href": "slides/week8.1-data-stories-slides.html#break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 2) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#title-slide",
    "href": "slides/week6.2-annotations-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 6.2\nAnnotations\n\nWeek 6 | February 12th, 2024"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#good-design",
    "href": "slides/week6.2-annotations-slides.html#good-design",
    "title": "EDS 240",
    "section": "",
    "text": "Good data visualization design considers:\n\n\ndata-ink ratio (less is more, within reason)\nhow to reduce eye movement and improve readability / interpretability (e.g. through alternative legend positions, direct annotations)\nputting things in context\nhow to draw the main attention to the most important info\nconsistent use of colors, spacing, typefaces, weights\ntypeface / font choices and how they affect both readability and emotions and perceptions\nusing visual hierarchy to guide the reader\ncolor choices (incl. palette types, emotions, readability)\nhow to tell an interesting story\nhow to center the people and communities represented in your data\naccessibility through colorblind-friendly palettes & alt text (see week 2 discussion)\n\n\nThis lesson will focus on the use of annotations in a good data visualization."
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#why-annotate",
    "href": "slides/week6.2-annotations-slides.html#why-annotate",
    "title": "EDS 240",
    "section": "",
    "text": "Why annotate?\n\n\n\nclarify meaning / significance of data (especially particular data points or groups)\nfacilitate interpretation\nbuild a narrative\n\n\n\nThe average attention span of an internet user is ~8 seconds (shorter than a goldfish!). It’s imperative that we respect our readers’ time.\n\n\nAim to:\n\ntell your readers what you want them to see\nguide your readers eyes & attention\nremind your readers what they’re looking at\n\nThe more time you spend making your visualization crystal clear, the more time you save your readers needing to decipher it.\n\nRead these two great posts: What to consider when using text in data visualizations & Respect your readers’ time, both by Lisa Charlotte Muth"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#plots-to-annotate",
    "href": "slides/week6.2-annotations-slides.html#plots-to-annotate",
    "title": "EDS 240",
    "section": "",
    "text": "We’ll be annotating these plots\n\n\n\n\n\nMetabolism Effects on Foraging Across Temperatures\n\n\n\n\n\n\n\n\n\n\n\nAdapted from Csik et al. 2023, Figure 5\n\n\n\nMono Lake levels\n\n\n\n\n\n\n\n\n\n\n\nBorrowed from Allison Horst’s Customized Data Visualization in {ggplot2} materials"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#custom-annotations",
    "href": "slides/week6.2-annotations-slides.html#custom-annotations",
    "title": "EDS 240",
    "section": "",
    "text": "These two plots (and likely many others that you’ll create moving forward) will benefit from some custom annotations."
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#lob-plot",
    "href": "slides/week6.2-annotations-slides.html#lob-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Lobster plot starter code\n\n\nNote that this starter code incorporates many of the strategies we’ve discussed in past lectures: turning a theme into a function, creating a color palette (and also point shape and size scales), and axis labels outside of the ggplot code, and using {ggtext} to apply markdown to plot text:\n\n\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#.........................load libraries.........................\nlibrary(tidyverse)\n\n#..........................read in data..........................\n\n# read in Google Sheet ----\nlobs &lt;- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1DkDVcl_9rlaqznHfa_v1V1jtZqcuL75Q6wvAHpnCHuk/edit#gid=2143433533\") |&gt;\n  mutate(temp = as.factor(temp))\n\n# alternatively, read in csv file ----\nlobs &lt;- read_csv(here::here(\"week6\", \"data\", \"metabolism-foraging-data.csv\")) |&gt;\n  mutate(temp = as.factor(temp))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            create lobster plot                           ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................create theme..........................\nlob_theme &lt;- function(){\n  theme_light() +\n    theme(\n      axis.title.x = ggtext::element_markdown(size = 13,\n                                              margin = margin(t = 1, r = 0, b = 0, l = 0, unit = \"lines\")),\n      axis.title.y = ggtext::element_markdown(size = 13,\n                                              margin = margin(t = 0, r = 1, b = 0, l = 0, unit = \"lines\")),\n      axis.text = element_text(color = \"black\", size = 12),\n      panel.border = element_rect(colour = \"black\", size = 0.7),\n      panel.grid = element_blank(),\n      legend.title = element_text(size = 11),\n      legend.text = element_text(size = 10),\n      legend.position = c(0.95, 0.95),\n      legend.justification = c(0.95, 0.95),\n      legend.box.background = element_rect(color = \"black\", size = 1.1)\n\n    )\n}\n\n#..........................create scales.........................\nlob_palette &lt;- c(\"11\" = \"#7B8698\",\n                 \"16\" = \"#BAD7E5\",\n                 \"21\" = \"#DC7E7C\",\n                 \"26\" = \"#7D3E40\")\n\nlob_shapes &lt;-  c(\"11\" = 15,\n                 \"16\" = 16,\n                 \"21\" = 17,\n                 \"26\" = 18)\n\nlob_sizes &lt;- c(\"11\" = 6,\n               \"16\" = 6,\n               \"21\" = 6,\n               \"26\" = 7)\n\n#........................create plot text........................\nx_axis_lab &lt;- glue::glue(\"Resting Metabolic Rate&lt;br&gt;\n                         (mg O&lt;sub&gt;2&lt;/sub&gt; kg&lt;sup&gt;-1&lt;/sup&gt; min&lt;sup&gt;-1&lt;/sup&gt;)\")\n\ny_axis_lab &lt;- glue::glue(\"Maximum Consumption Rate&lt;br&gt;\n                         (prey consumed predator&lt;sup&gt;-1&lt;/sup&gt; 24hr&lt;sup&gt;-1&lt;/sup&gt;)\")\n\n#............................plot data...........................\nlob_plot &lt;- ggplot(lobs, aes(x = SMR, y = avg_eaten,\n                 color = temp, shape = temp, size = temp)) +\n  geom_point() +\n  scale_color_manual(values = lob_palette, name = \"Temperature (ºC)\") +\n  scale_shape_manual(values = lob_shapes, name = \"Temperature (ºC)\") +\n  scale_size_manual(values = lob_sizes, name = \"Temperature (ºC)\") +\n  scale_x_continuous(breaks = seq(0, 1.5, by = 0.2)) +\n  scale_y_continuous(breaks = seq(0, 35, by = 5)) +\n  labs(x = x_axis_lab,\n       y = y_axis_lab) +\n  lob_theme()\n\nlob_plot"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#build-custom-annotations",
    "href": "slides/week6.2-annotations-slides.html#build-custom-annotations",
    "title": "EDS 240",
    "section": "",
    "text": "Building custom annotations\n\n\nThere are two primary ways to add custom text annotations:\n\n\n\ngeom_text() (for plain text) & geom_label() (adds a rectangle behind text), which take aesthetics mappings; these draw the geom once per each row of the data frame\nannotate(), which does not take aesthetics mappings and instead draws only the information provided to it\n\n\n\n\nLet’s try to add an annotation to our plot using both approaches to better understand the difference.\n\n\n\n\nOur goal: add a rectangle that bounds / highlights a subset of points, add text nearby that reads Important lobsters, and draw an arrow from the text pointing to the box.\n\n\nI’ve found the Annotation FAQ super helpful!"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#geom-text-issues",
    "href": "slides/week6.2-annotations-slides.html#geom-text-issues",
    "title": "EDS 240",
    "section": "",
    "text": "geom_text() + geom_rect() doesn’t look right . . .\n\nHere, we use geom_text() + geom_rect() to add text and a rectangle to our plot. We need to supply coordinates to place each on our plot.\n\n\nlob_plot +\n  geom_text(\n    x = 0.1,\n    y = 25,\n    label = \"Important lobsters\",\n    size = 4,\n    color = \"black\",\n    hjust = \"inward\",\n  ) +\n  geom_rect(\n    xmin = 0.25, xmax = 0.85,\n    ymin = 8.5, ymax = 18,\n    alpha = 0.5,\n    fill = \"gray40\", color = \"black\",\n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\n\n\nNotice that our text looks oddly blurry and bold, and our rectangle is opaque (despite adjusting alpha) and has a weird, thick border."
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#geom-text-aes",
    "href": "slides/week6.2-annotations-slides.html#geom-text-aes",
    "title": "EDS 240",
    "section": "",
    "text": "geom_text() inherits aesthetic mappings from ggplot()\n\nLike all other geom_*() functions we’ve worked with, geom_text() & geom_label() take aesthetic mappings. You can either define aes() within the geom, or it’ll inherit global mappings from ggplot() (as in our case).\n\n\nHere, geom_text() is plotting our label (Important lobsters) and box 22 times each (once for each of the 22 observations in our data frame).\n\nstr(lobs)\n\ntibble [22 × 7] (S3: tbl_df/tbl/data.frame)\n $ lobster_id: chr [1:22] \"N18\" \"L4\" \"N14\" \"L3\" ...\n $ temp      : Factor w/ 4 levels \"11\",\"16\",\"21\",..: 3 3 3 3 3 3 1 1 1 1 ...\n $ SMR       : num [1:22] 0.709 0.551 0.582 1.084 0.575 ...\n $ MMR       : num [1:22] 4.5 3.75 5.64 4.66 4.85 ...\n $ AAS       : num [1:22] 3.79 3.2 5.06 3.58 4.28 ...\n $ FAS       : num [1:22] 6.35 6.81 9.69 4.3 8.44 ...\n $ avg_eaten : num [1:22] 23.3 11 21.3 9 14.3 ...\n\n\n\n\n\nIt’s also inheriting the size aesthetic for our box border.\n\n# from our `lob_plot` code\nscale_size_manual(values = lob_sizes, name = \"Temperature (ºC)\")"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#use-annotate",
    "href": "slides/week6.2-annotations-slides.html#use-annotate",
    "title": "EDS 240",
    "section": "",
    "text": "This is exactly the situation annotate() was made for\n\nUnlike geom_text(), annotate() requires that we define a geom type (e.g. \"text\", \"rect\"). We can also remove the show.lengend argument, since annotate() doesn’t produce a legend.\n\n\nlob_plot +\n  annotate(\n    geom = \"text\",\n    x = 0.1,\n    y = 25,\n    label = \"Important lobsters\",\n    size = 4,\n    color = \"black\",\n    hjust = \"inward\"\n  ) +\n  annotate(\n    geom = \"rect\",\n    xmin = 0.25, xmax = 0.85,\n    ymin = 8.5, ymax = 18,\n    alpha = 0.5,\n    fill = \"gray70\", color = \"black\"\n  )\n\n\n\n\n\n\n\n\n\n\nNote: Determining coordinates for any annotation requires a lot of trial and error. Pick values that you think are close and then tweak from there."
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#draw-arrow",
    "href": "slides/week6.2-annotations-slides.html#draw-arrow",
    "title": "EDS 240",
    "section": "",
    "text": "Draw an arrow between our label and rectangle\n\nWe can specify the \"curve\" geom type to draw a curved line. Use the arrow argument + arrow() function to add an arrow tip on the end:\n\n\nlob_plot +\n  annotate(\n    geom = \"text\",\n    x = 0.1,\n    y = 25,\n    label = \"Important lobsters\",\n    size = 4,\n    color = \"black\",\n    hjust = \"inward\"\n  ) +\n  annotate(\n    geom = \"rect\",\n    xmin = 0.25, xmax = 0.85,\n    ymin = 8.5, ymax = 18,\n    alpha = 0.5,\n    fill = \"gray70\", color = \"black\"\n  ) +\n  annotate(\n    geom = \"curve\",\n    x = 0.3, xend = 0.5,\n    y = 23.8, yend = 19,\n    curvature = -0.15,\n    arrow = arrow(length = unit(0.3, \"cm\"))\n  )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#use-geoms",
    "href": "slides/week6.2-annotations-slides.html#use-geoms",
    "title": "EDS 240",
    "section": "",
    "text": "Use geom_text/label() to annotate each point\n\n\n\n\ngeom_text() adds plain text\n\n\nlob_plot +\n  geom_text(aes(label = lobster_id),\n            size = 6,\n            show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\ngeom_label() adds a rectangle behind text\n\n\nlob_plot +\n  geom_label(aes(label = lobster_id),\n             size = 6,\n             show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nAnnotations sit on top of data points, which may be undesirable…"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#use-ggrepel",
    "href": "slides/week6.2-annotations-slides.html#use-ggrepel",
    "title": "EDS 240",
    "section": "",
    "text": "Use {ggrepel} to repel annotations\n\n\n\n\ngeom_text() adds plain text\n\n\nlob_plot +\n  ggrepel::geom_text_repel(aes(label = lobster_id),\n                           size = 4,\n                           color = \"gray10\",\n                           nudge_x = 0.1, nudge_y = 0.3,\n                           arrow = arrow(length = unit(0.25, \"cm\")))\n\n\n\n\n\n\n\n\n\n\ngeom_label() adds a rectangle behind text\n\n\nlob_plot +\n  ggrepel::geom_label_repel(aes(label = lobster_id),\n                           size = 4,\n                           color = \"gray10\",\n                           nudge_x = 0.1, nudge_y = 0.3,\n                           arrow = arrow(length = unit(0.25, \"cm\")))"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#manually-label-iv10",
    "href": "slides/week6.2-annotations-slides.html#manually-label-iv10",
    "title": "EDS 240",
    "section": "",
    "text": "Manually label just a few important points\n\nIf we have just a few lobsters that we want to call attention to, we can use annotate() to label them. Let’s start with lobster IV10:\n\n\nlob_plot +\n  annotate(\n    geom = \"text\",\n    x = 0.3, y = 20.1,\n    label = \"IV10\",\n    hjust = \"left\",\n    size = 5\n    ) +\n  annotate(\n    geom = \"curve\",\n    x = 0.29, xend = 0.184,\n    y = 20, yend = 9.43,\n    arrow = arrow(length = unit(0.3, \"cm\")),\n    linewidth = 0.6\n    )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#manually-label-iv19",
    "href": "slides/week6.2-annotations-slides.html#manually-label-iv19",
    "title": "EDS 240",
    "section": "",
    "text": "Manually label just a few important points\n\nYour turn! Create another text label and arrow pointing to lobster IV19 (the farthest dark red diamond to the right). You don’t need to choose this exact location for your text and arrow:\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#manually-label-iv19-solution",
    "href": "slides/week6.2-annotations-slides.html#manually-label-iv19-solution",
    "title": "EDS 240",
    "section": "",
    "text": "Manually label just a few important points\n\nA solution (you may have chosen a different placement for your text and arrow):\n\n\nlob_plot +\n  annotate(\n    geom = \"text\",\n    x = 0.3, y = 20.1,\n    label = \"IV10\",\n    hjust = \"left\",\n    size = 5\n    ) +\n  annotate(\n    geom = \"curve\",\n    x = 0.29, xend = 0.184,\n    y = 20, yend = 9.43,\n    arrow = arrow(length = unit(0.3, \"cm\")),\n    linewidth = 0.6\n    ) +\n  annotate(\n    geom = \"text\",\n    x = 1.19,\n    y = 5.25,\n    label = \"IV19\",\n    hjust = \"right\",\n    size = 5\n    ) +\n  annotate(\n    geom = \"curve\",\n    x = 1.2, xend = 1.31,\n    y = 5, yend = 14,\n    arrow = arrow(length = unit(0.3, \"cm\")),\n    linewidth = 0.6\n    )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#mono-plot",
    "href": "slides/week6.2-annotations-slides.html#mono-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Mono Lake plot starter code\n\n\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#.........................load libraries.........................\nlibrary(tidyverse)\n\n#..........................read in data..........................\n\n# read in Google Sheet ----\nmono &lt;- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1o0-89RFp2rI2y8hMQWy-kquf_VIzidmhmVDXQ02JjCA/edit#gid=164128885\")\n\n# alternatively, read in csv ----\nmono &lt;- read_csv(here::here(\"week6\", \"data\", \"mono.csv\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            create Mono Lake plot                         ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nggplot(data = mono, aes(x = year, y = lake_level)) +\n  geom_line() +\n  labs(x = \"\\nYear\",\n       y = \"Lake surface level\\n(feet above sea level)\\n\",\n       title = \"Mono Lake levels (1850 - 2017)\\n\",\n       caption = \"Data: Mono Basin Clearinghouse\") +\n  scale_x_continuous(limits = c(1850, 2020),\n                     expand = c(0,0),\n                     breaks = seq(1850, 2010, by = 20)) +\n  scale_y_continuous(limits = c(6350, 6440),\n                     breaks = c(6370, 6400, 6430),\n                     expand = c(0,0),\n                     labels = scales::label_comma()) +\n  theme_light() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(size = 16),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10),\n    plot.caption = element_text(face = \"italic\")\n    )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#highlight-years",
    "href": "slides/week6.2-annotations-slides.html#highlight-years",
    "title": "EDS 240",
    "section": "",
    "text": "Highlight years of interest\n\nLet’s say we want to call particular attention to the sharp decline in lake surface level between 1941 - 1983 as a result of unrestricted water diversions. Let’s do so using annotate() (note the order of our annotation layers matters!).\n\n\nggplot(data = mono, aes(x = year, y = lake_level)) +\n  annotate(\n    geom = \"rect\",\n    xmin = 1941, xmax = 1983,\n    ymin = 6350, ymax = 6440,\n    fill = \"gray90\"\n  ) +\n  geom_line() +\n  labs(x = \"\\nYear\",\n       y = \"Lake surface level\\n(feet above sea level)\\n\",\n       title = \"Mono Lake levels (1850 - 2017)\\n\",\n       caption = \"Data: Mono Basin Clearinghouse\") +\n  scale_x_continuous(limits = c(1850, 2020),\n                     expand = c(0,0),\n                     breaks = seq(1850, 2010, by = 20)) +\n  scale_y_continuous(limits = c(6350, 6440),\n                     breaks = c(6370, 6400, 6430),\n                     expand = c(0,0),\n                     labels = scales::label_comma()) +\n  annotate(\n    geom = \"text\", \n    x = 1962, y = 6425,\n    label = \"unrestricted diversions\\n(1941 - 1983)\",\n    size = 3\n  ) +\n  theme_light() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(size = 16),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10),\n    plot.caption = element_text(face = \"italic\")\n    )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#add-context",
    "href": "slides/week6.2-annotations-slides.html#add-context",
    "title": "EDS 240",
    "section": "",
    "text": "Add other important context\n\nWe can add any other important information to provide better context for our readers. Let’s say we’re also interested in shrimp abundances, which decline above 6,360 feet. Here, we add a baseline at that elevation, along with text:\n\n\nggplot(data = mono, aes(x = year, y = lake_level)) +\n  annotate(\n    geom = \"rect\",\n    xmin = 1941, xmax = 1983,\n    ymin = 6350, ymax = 6440,\n    fill = \"gray90\"\n  ) +\n  geom_line() +\n  labs(x = \"\\nYear\",\n       y = \"Lake surface level\\n(feet above sea level)\\n\",\n       title = \"Mono Lake levels (1850 - 2017)\\n\",\n       caption = \"Data: Mono Basin Clearinghouse\") +\n  scale_x_continuous(limits = c(1850, 2020),\n                     expand = c(0,0),\n                     breaks = seq(1850, 2010, by = 20)) +\n  scale_y_continuous(limits = c(6350, 6440),\n                     breaks = c(6370, 6400, 6430),\n                     expand = c(0,0),\n                     labels = scales::label_comma()) +\n  annotate(\n    geom = \"text\", \n    x = 1962, y = 6425,\n    label = \"unrestricted diversions\\n(1941 - 1983)\",\n    size = 3\n  ) +\n  geom_hline(yintercept = 6360, \n             linetype = \"dashed\") +\n  annotate(\n    geom = \"text\",\n    x = 1910, y = 6366,\n    label = \"Decreased shrimp abundance expected\\n(6,360 feet above sea level)\",\n    size = 3\n    ) +\n  theme_light() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(size = 16),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10),\n    plot.caption = element_text(face = \"italic\")\n    )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#facet-annotations",
    "href": "slides/week6.2-annotations-slides.html#facet-annotations",
    "title": "EDS 240",
    "section": "",
    "text": "Bonus: Annotating facets requires some patience and mapping. We’ll demonstrate on our occupations plot from the last lesson."
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#occupation-plot",
    "href": "slides/week6.2-annotations-slides.html#occupation-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Add annotations to separate facet panels\n\nHere, we create a separate data frame with all necessary information (e.g. labels, label positions, arrow positions, etc.) for building our annotations. Then, we use in geom_label() to map this information onto the appropriate facet. This requires a lot of manual adjustment! It helps to focus on one small piece (e.g. one label or one arrow) at a time.\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(showtext)\n\n#..........................import data...........................\njobs &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv\")\n\n#..........................import fonts..........................\nfont_add_google(name = \"Josefin Sans\", family = \"josefin\")\nfont_add_google(name = \"Sen\", family = \"sen\")\n\n#....................import Font Awesome fonts...................\nfont_add(family = \"fa-brands\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Brands-Regular-400.otf\"))\nfont_add(family = \"fa-regular\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Regular-400.otf\")) \nfont_add(family = \"fa-solid\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Solid-900.otf\"))\n\n#................enable {showtext} for rendering.................\nshowtext_auto()\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                wrangle data                              ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\njobs_clean &lt;- jobs |&gt;\n\n  # add cols (needed for dumbbell plot) ----\n  mutate(percent_male = 100 - percent_female, # % of females within each industry was already included\n       difference_earnings = total_earnings_male - total_earnings_female) |&gt;  # diff in earnings between M & F\n\n  # rearrange columns ----\n  relocate(year, major_category, minor_category, occupation,\n           total_workers, workers_male, workers_female,\n           percent_male, percent_female,\n           total_earnings, total_earnings_male, total_earnings_female, difference_earnings,\n           wage_percent_of_male) |&gt;\n\n  # drop rows with missing earning data ----\n  drop_na(total_earnings_male, total_earnings_female) |&gt;\n\n  # make occupation a factor ----\n  mutate(occupation = as.factor(occupation)) |&gt;\n\n# ---- this next step is for creating our dumbbell plots ----\n\n# classify jobs by percentage male or female ----\n  mutate(group_label = case_when(\n    percent_female &gt;= 75 ~ \"Occupations that are 75%+ female\",\n    percent_female &gt;= 45 & percent_female &lt;= 55 ~ \"Occupations that are 45-55% female\",\n    percent_male &gt;= 75 ~ \"Occupations that are 75%+ male\"\n  ))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                              create subset df                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#....guarantee the same random samples each time we run code.....\nset.seed(0)\n\n#.........get 10 random jobs that are 75%+ female (2016).........\nf75 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 75%+ female\") |&gt;\n  slice_sample(n = 10)\n\n#..........get 10 random jobs that are 75%+ male (2016)..........\nm75 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 75%+ male\") |&gt;\n  slice_sample(n = 10)\n\n#........get 10 random jobs that are 45-55%+ female (2016).......\nf50 &lt;- jobs_clean |&gt;\n  filter(year == 2016, group_label == \"Occupations that are 45-55% female\") |&gt;\n  slice_sample(n = 10)\n\n#.......combine dfs & relevel factors (for plotting order).......\nsubset_jobs &lt;- rbind(f75, m75, f50) |&gt;\n  mutate(group_label = fct_relevel(group_label, \n                                   \"Occupations that are 75%+ female\",\n                                   \"Occupations that are 45-55% female\", \n                                   \"Occupations that are 75%+ male\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                create plot                               ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................build palette.........................\nearnings_pal &lt;- c(\"males\" = \"#2D7787\",\n                  \"females\" = \"#FC6B4B\",\n                  dark_text = \"#0C1509\",\n                  light_text = \"#4E514D\") \n\n#.........................create caption.........................\ngithub_icon &lt;- \"&#xf09b\"\ngithub_username &lt;- \"samanthacsik\"\n\ncaption &lt;- glue::glue(\n  \"Data Source: TidyTuesday (March 5, 2019) |\n  &lt;span style='font-family:fa-brands;'&gt;{github_icon};&lt;/span&gt;\n  {github_username}\"\n)\n\n#........................create subtitle.........................\nmoney_icon &lt;- \"&#xf3d1\"\n\nsubtitle &lt;- glue::glue(\"Median earnings &lt;span style='font-family:fa-regular;'&gt;{money_icon};&lt;/span&gt;\n                       of full-time\n                       &lt;span style='color:#2D7787;font-size:20pt;'&gt;**male**&lt;/span&gt;\n                       versus &lt;span style='color:#FC6B4B;font-size:20pt;'&gt;**female**&lt;/span&gt;\n                       workers by occupation in 2016\")\n\n#.................create df with annotation info.................\nfacet_labs &lt;- data.frame(my_text = c(\"Males make $23,644 than\\nfemales in this female-\\ndominated occupation\",\n                                     \"Male & female probation officers &\\ncorrectional treatment specialists\\nmake about the same\",\n                                     \"Here's another annotation\\nwith a horizontal arrow\"),\n                         group_label = c(\"Occupations that are 75%+ female\", \"Occupations that are 45-55% female\", \"Occupations that are 75%+ male\"),\n                         text_x = c(70000, 45000, 60000),\n                         text_y = c(5, 3, 5),\n                         arrow_x = c(80000, 48500, 60000),\n                         arrow_xend = c(80000, 48500, 37500),\n                         arrow_y = c(6, 4, 5),\n                         arrow_yend = c(10, 6.5, 5)) |&gt;\n  \n  # need to reset factor levels so that facets are ordered as before ----\n  mutate(group_label = fct_relevel(group_label, \"Occupations that are 75%+ female\",\n                                   \"Occupations that are 45-55% female\", \"Occupations that are 75%+ male\"))\n\n#..........................create plot...........................\nggplot(subset_jobs) +\n  geom_segment(aes(x = total_earnings_female, xend = total_earnings_male,\n                   y = fct_reorder(occupation, total_earnings), yend = occupation)) +\n  geom_point(aes(x = total_earnings_male, y = occupation),\n             color = earnings_pal[\"males\"], size = 3.25) +\n  geom_point(aes(x = total_earnings_female, y = occupation),\n             color = earnings_pal[\"females\"], size = 3.25) +\n  facet_wrap(~group_label, nrow = 3, scales = \"free_y\") +\n  scale_x_continuous(labels = scales::label_dollar(scale = 0.001, suffix = \"k\"),\n                     breaks = c(25000, 50000, 75000, 100000, 125000)) +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = subtitle,\n       caption = caption) +\n  geom_segment(\n    data = facet_labs,\n    mapping = aes(x = arrow_x, xend = arrow_xend,\n                  y = arrow_y, yend = arrow_yend),\n    linewidth = 1, arrow = arrow(length = unit(0.3, \"cm\"))\n    ) +\n  geom_label(\n    data = facet_labs,\n    mapping = aes(x = text_x, y = text_y, label = my_text),\n    size = 3,\n    hjust = \"left\"\n    ) +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(family = \"josefin\",\n                              face = \"bold\",\n                              size = 25,\n                              color = earnings_pal[\"dark_text\"]),\n    plot.subtitle = ggtext::element_textbox_simple(family = \"sen\",\n                                                   size = 17,\n                                                   color = earnings_pal[\"light_text\"],\n                                                   margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = ggtext::element_textbox(family = \"sen\",\n                                           face = \"italic\",\n                                           color = earnings_pal[\"light_text\"],\n                                           margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(family = \"josefin\",\n                                face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(x = 1, \"lines\"),\n    axis.text = element_text(family = \"sen\",\n                             color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#geom-textbox",
    "href": "slides/week6.2-annotations-slides.html#geom-textbox",
    "title": "EDS 240",
    "section": "",
    "text": "Use geom_textbox() to apply Markdown to annotations\n\nThe {ggtext} package provides geom_textbox(), which allows for Markdown styling and font family specification. Note that we had to adjust the box coordinates slightly:\n\n#.................create df with annotation info.................\nfacet_labs &lt;- data.frame(my_text = c(\"&lt;span style='color:#2D7787;'&gt;**Males**&lt;/span&gt; **make $23,644 more than** &lt;span style='color:#FC6B4B;'&gt;**females**&lt;/span&gt; in this female-dominated occupation\",\n                                     \"Male & female probation officers & correctional treatment specialists make about the same\",\n                                     \"Here's another annotation with a horizontal arrow\"), \n                         group_label = c(\"Occupations that are 75%+ female\", \"Occupations that are 45-55% female\", \"Occupations that are 75%+ male\"),\n                         x = c(70000, 55000, 65000),\n                         y = c(5, 3, 5),\n                         arrow_x = c(80000, 48500, 60000),\n                         arrow_xend = c(80000, 48500, 37500),\n                         arrow_y = c(6, 4, 5),\n                         arrow_yend = c(10, 6.5, 5)) |&gt;\n  mutate(group_label = fct_relevel(group_label, \"Occupations that are 75%+ female\",\n                                   \"Occupations that are 45-55% female\", \"Occupations that are 75%+ male\"))\n\n#..........................create plot...........................\nggplot(subset_jobs) +\n  geom_segment(aes(x = total_earnings_female, xend = total_earnings_male,\n                   y = fct_reorder(occupation, total_earnings), yend = occupation)) +\n  geom_point(aes(x = total_earnings_male, y = occupation),\n             color = earnings_pal[\"males\"], size = 3.25) +\n  geom_point(aes(x = total_earnings_female, y = occupation),\n             color = earnings_pal[\"females\"], size = 3.25) +\n  facet_wrap(~group_label, nrow = 3, scales = \"free_y\") +\n  scale_x_continuous(labels = scales::label_dollar(scale = 0.001, suffix = \"k\"),\n                     breaks = c(25000, 50000, 75000, 100000, 125000)) +\n  labs(title = \"Males earn more than females across most occupations\",\n       subtitle = subtitle,\n       caption = caption) +\n  geom_segment(data = facet_labs,\n               mapping = aes(x = arrow_x, xend = arrow_xend,\n                             y = arrow_y, yend = arrow_yend),\n               linewidth = 1, arrow = arrow(length = unit(0.3, \"cm\"))) +\n  ggtext::geom_textbox(data = facet_labs,\n                       mapping = aes(x = x, y = y, label = my_text),\n                       size = 3,\n                       family = \"sen\") +\n  theme_minimal() +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_text(family = \"josefin\",\n                              face = \"bold\",\n                              size = 25,\n                              color = earnings_pal[\"dark_text\"]),\n    plot.subtitle = ggtext::element_textbox_simple(family = \"sen\",\n                                                   size = 17,\n                                                   color = earnings_pal[\"light_text\"],\n                                                   margin = margin(t = 0.5, r = 0, b = 1, l = 0, unit = \"lines\")),\n    plot.caption = ggtext::element_textbox(family = \"sen\",\n                                           face = \"italic\",\n                                           color = earnings_pal[\"light_text\"],\n                                           margin = margin(t = 3, r = 0, b = 0, l = 0, unit = \"lines\")),\n    strip.text.x = element_text(family = \"josefin\",\n                                face = \"bold\",\n                                size = 12,\n                                hjust = 0),\n    panel.spacing.y = unit(x = 1, \"lines\"),\n    axis.text = element_text(family = \"sen\",\n                             color = earnings_pal[\"light_text\"]),\n    axis.text.x = element_text(size = 10),\n    axis.title = element_blank()\n  )"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#additional-tools",
    "href": "slides/week6.2-annotations-slides.html#additional-tools",
    "title": "EDS 240",
    "section": "",
    "text": "Keep these additional tips, tools & tutorials in mind!\n\nTools & packages:\n\nuse clip = \"off\" inside a coord_*() function to allow drawing outside the plot panel (see this tweet for one example)\nthe {ggfittext} package is a ggplot2 extension for fitting text into boxes\nthe {ggtext} package includes two geoms for annotating plots, geom_richtext() & geom_textbox() – both permit Markdown styling\nthe {ggforce} package has so many awesome functions, including a series of annotation functions (e.g. check out geom_mark_ellipse(), demoed in lecture 5.1), and facet_zoom(), for zooming into a subset of data; Tuo Wang also has some great examples in this blog post\n\nTutorials:\n\nLevel Up Your Labels: Tips and Tricks for Annotating Plots, by Cara Thompson\nRecreating the Storytelling with Data look with ggplot, by Albert Rapp\n4 Ways to use colors in ggplot more efficiently, by Albert Rapp (includes some great annotation examples)"
  },
  {
    "objectID": "slides/week6.2-annotations-slides.html#end-break",
    "href": "slides/week6.2-annotations-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 2 (of 2) ~"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#title-slide",
    "href": "slides/week4.1-rankings-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 4.1\nVisualizing rankings\n\nWeek 4 | January 29th, 2024"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#data-ranking",
    "href": "slides/week4.1-rankings-slides.html#data-ranking",
    "title": "EDS 240",
    "section": "",
    "text": "Visualizing data rankings?\n\n \nShowing the relationship between a numeric and categorical variable, i.e. comparing categorical groups based on their numeric values."
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#roadmap",
    "href": "slides/week4.1-rankings-slides.html#roadmap",
    "title": "EDS 240",
    "section": "",
    "text": "Roadmap\n\n\nIn this lesson, we’ll explore two (highly interchangeable) chart types:\n\n1. bar plots\n2. lollipop plots\n\n\nWe’ll discuss:\n\n\nhandling long x-axis labels\nreordering groups\nadding labels\ncomparing multiple groups\ncritical considerations when creating bar / lollipop plots"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#job-data",
    "href": "slides/week4.1-rankings-slides.html#job-data",
    "title": "EDS 240",
    "section": "",
    "text": "The data: women in the workforce\n\nAccording to the American Association of University Women (AAUW), the gender pay gap is defined as “…the gap between what men and women are paid. Most commonly, it refers to the median annual pay of all women who work full time and year-round, compared to the pay of a similar cohort of men.” We’ll explore income data from the Bureau of Labor Statistics and the Census Bureau, which has been moderately pre-processed by TidyTuesday organizers for the March 5, 2021 data set.\n\n\n\nWe’ll use these data to explore a two different questions: (1) What are the top 10 occupations with the highest median earnings (across males and females)? (2) How do median earnings differ between males and females in those same occupations?"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#data-wrangling",
    "href": "slides/week4.1-rankings-slides.html#data-wrangling",
    "title": "EDS 240",
    "section": "",
    "text": "Data wrangling\n\nBe sure to check out the data dictionary on the TidyTuesday repo for information about each variable in this data set.\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\njobs &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv\")\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                wrangle data                              ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\njobs_clean &lt;- jobs |&gt; \n  \n  # add cols (needed for dumbbell plot) ----\n  mutate(percent_male = 100 - percent_female, # % of females within each industry was already included\n         difference_earnings = total_earnings_male - total_earnings_female) |&gt;  # diff in earnings between M & F\n  \n  # rearrange columns ----\n  relocate(year, major_category, minor_category, occupation,\n          total_workers, workers_male, workers_female,\n          percent_male, percent_female,\n          total_earnings, total_earnings_male, total_earnings_female, difference_earnings,\n          wage_percent_of_male) |&gt; \n  \n  # drop rows with missing earning data ----\n  drop_na(total_earnings_male, total_earnings_female) |&gt; \n  \n  # make occupation a factor ----\n  mutate(occupation = as.factor(occupation)) |&gt; \n  \n  # ---- this next step is for creating our dumbbell plots ----\n\n  # classify jobs by percentage male or female ----\n  mutate(group_label = case_when(\n    percent_female &gt;= 75 ~ \"Occupations that are 75%+ female\",\n    percent_female &gt;= 45 & percent_female &lt;= 55 ~ \"Occupations that are 45-55% female\",\n    percent_male &gt;= 75 ~ \"Occupations that are 75%+ male\"\n  ))"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#bar-lolli-1group",
    "href": "slides/week4.1-rankings-slides.html#bar-lolli-1group",
    "title": "EDS 240",
    "section": "",
    "text": "Bar & lollipop plots to visualize rankings\n\nLet’s first explore the top ten occupations with the highest median earnings in 2016 (full-time workers &gt; 16 years old). The heights of both the bars and lollipops represent the total estimated median earnings (total_earnings).\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; # keep top 10 jobs with most `total_earnings`\n  ggplot(aes(x = occupation, y = total_earnings)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = occupation, y = total_earnings)) +\n  ggalt::geom_lollipop()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#coord-flip-theme",
    "href": "slides/week4.1-rankings-slides.html#coord-flip-theme",
    "title": "EDS 240",
    "section": "",
    "text": "Make space for long x-axis labels\n\nGive those long x-axis labels some breathing room using coord_flip(), which flips cartesian (x,y) coordinates so that the horizontal becomes the vertical and vice versa.\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = occupation, y = total_earnings)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = occupation, y = total_earnings)) +\n  ggalt::geom_lollipop() +\n  coord_flip()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#arrange-bars",
    "href": "slides/week4.1-rankings-slides.html#arrange-bars",
    "title": "EDS 240",
    "section": "",
    "text": "Reordering groups helps readers derive insight\n\nHere, we use forcats::fct_reorder() to reorder the levels of our x-axis variable, occupation, based on a numeric variable, total_earnings (NOTE: we do not have to reorder based on the same numeric variable that’s plotted on the y-axis; here it makes sense to do so; also see this blog post):\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  ggalt::geom_lollipop() +\n  coord_flip()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#scales-pkg",
    "href": "slides/week4.1-rankings-slides.html#scales-pkg",
    "title": "EDS 240",
    "section": "",
    "text": "{scales}: a true label-editing hero\n\nWhile we’re on the topic of making things easier to read, let’s use the {scales} package to update our labels so that they read more like dollar values:\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  geom_col() +\n  scale_y_continuous(labels = scales::label_currency(accuracy = 1, scale = 0.001, suffix = \"k\")) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  ggalt::geom_lollipop() +\n  scale_y_continuous(labels = scales::label_currency(accuracy = 1, scale = 0.001, suffix = \"k\")) + \n  coord_flip()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#add-labels",
    "href": "slides/week4.1-rankings-slides.html#add-labels",
    "title": "EDS 240",
    "section": "",
    "text": "Add direct labels if the exact values are important\n\ngeom_text() is useful for labeling plots. Here, we pair it with the {scales} package to format dollar values:\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  geom_col() +\n  geom_text(aes(label = scales::dollar(total_earnings)), hjust = 1.2, color = \"white\") + \n  scale_y_continuous(labels = scales::label_currency(accuracy = 1, scale = 0.001, suffix = \"k\")) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +\n  ggalt::geom_lollipop() +\n  geom_text(aes(label = scales::dollar(total_earnings)), hjust = -0.2) + \n  scale_y_continuous(labels = scales::label_currency(accuracy = 1, scale = 0.001, suffix = \"k\"),\n                     limits = c(0, 250000)) + # expand axis to make room for values\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nFor some more advanced label manipulation, see A Quick How-to on Labelling Bar Graphs in ggplot2, by Cédric Scherer | Also, see this Posit Community post regarding the use of scales::dollar()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#col-vs-bar",
    "href": "slides/week4.1-rankings-slides.html#col-vs-bar",
    "title": "EDS 240",
    "section": "",
    "text": "An aside: geom_col() vs. geom_bar()\n\n\n\nUse geom_col() when your data is already summarized or you have a variable in your data set that includes y-axis values, which will map to the height of the bars. E.g. we already have a numeric variable in our data set called, total_earnings – those numeric values are mapped to the height of each bar in our plot.\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  ggplot(aes(x = occupation, y = total_earnings)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nUse geom_bar() if you want to ggplot to count up numbers of rows and map those counts to the height of bars in your plot. E.g. we want to know how many occupations are included for each major category in our jobs_gender_clean data set (NOTE: we don’t have a count column in our data frame):\n\nggplot(jobs_clean, aes(x = major_category)) +\n  geom_bar() + \n  coord_flip()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#more-cat-groups",
    "href": "slides/week4.1-rankings-slides.html#more-cat-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Plotting 2+ groups (e.g. male vs. female earnings)\n\nWe’ll need to transform our data from wide to long format, where total earning for males and females are in the same column (we’ll name this earnings_by_group), and a secondary column denotes which group those earnings are associated with (total_earnings_female, total_earnings_male). Also note that because geom_lollipop() doesn’t accept a position parameter, we’ll instead use geom_linerange() + geom_point():\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = \"group\", values_to = \"earnings_by_group\") |&gt; \n  mutate(sex = str_remove(group, pattern = \"total_earnings_\")) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, fill = sex)) + \n  geom_col() + # default `position = \"stack\"`\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = \"group\", values_to = \"earnings_by_group\") |&gt; \n  mutate(sex = str_remove(group, pattern = \"total_earnings_\")) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, color = sex)) +\n  geom_point() + # default `position = \"stack\"`\n  geom_linerange(aes(xmin = occupation, xmax = occupation, \n                     ymin = 0, ymax = earnings_by_group)) + # default `position = \"stack\"`\n  coord_flip()"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#dodge",
    "href": "slides/week4.1-rankings-slides.html#dodge",
    "title": "EDS 240",
    "section": "",
    "text": "Plot groups side-by-side\n\nUpdate position = \"dodge\" or position = position_dodge() (which allows you to specify additional arguments about how dodging occurs):\n\n\n\njobs_clean |&gt; \n  filter(year == 2016) |&gt; \n  slice_max(order_by = total_earnings, n = 10) |&gt; \n  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = \"group\", values_to = \"earnings_by_group\") |&gt; \n  mutate(sex = str_remove(group, pattern = \"total_earnings_\")) |&gt; \n  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, fill = sex)) +\n  geom_col(position = position_dodge()) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\njobs_clean |&gt;\n  filter(year == 2016) |&gt;\n  slice_max(order_by = total_earnings, n = 10) |&gt;\n  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = \"group\", values_to = \"earnings_by_group\") |&gt;\n  mutate(sex = str_remove(group, pattern = \"total_earnings_\")) |&gt;\n  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, color = sex)) +\n  geom_point(position = position_dodge(width = 0.5)) +\n  geom_linerange(aes(xmin = occupation, xmax = occupation, \n                     ymin = 0, ymax = earnings_by_group),\n                 position = position_dodge(width = 0.5)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\n@Nancy You can think of geom_linerange as a convenient version of geom_segment for a specific use case. geom_segment is for when you need to draw arbitrary line segments in a fairly non-systematic way. geom_linerange is for the specific case of a collection of vertical bars at specified x values with different lengths (e.g. error bars, etc).\n\nfrom StackOverflow\nAlso note from ggplot2: Elegant Graphics for Data Analysis (3e) that geom_segment() is used to draw a line segment, specified by a start and end position, while geom_linerange() is used to draw a vertical line, often for displaying uncertainty"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#truncated-axis",
    "href": "slides/week4.1-rankings-slides.html#truncated-axis",
    "title": "EDS 240",
    "section": "",
    "text": "IMPORTANT: Avoid truncated axes\n\n\nThe axis of a bar (or related) plot must start at zero\n\nTruncated axes leads viewers to perceive illustrated differences as larger or more important than they actually are (i.e. a truncation effect). Yang et al. (2021) empirically tested this effect and found that this truncation effect persisted even after viewers were taught about the effects of y-axis truncation.\n\n\n\nFigure 2 from Yang et al. 2021. The left-most plot without a truncated y-axis was presented to the control group of viewers. The right-most plot with a truncated y-axis was presented to the test group of viewers.\n\n\n\nYang et al. (2021) Truncating bar graphs persistently misleads viewers. Journal of Applied Research in Memory and Cognition 10:2, 298-311. https://doi.org/10.1016/j.jarmac.2020.10.002"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#cat-not-cont",
    "href": "slides/week4.1-rankings-slides.html#cat-not-cont",
    "title": "EDS 240",
    "section": "",
    "text": "Be cautious when using bar plots to summarize continuous data\n\nBar plots shine when you need to compare counts (e.g. populations size of different countries, total earnings by group, etc.). However, you should proceed with caution when using bar plots to visualize the distribution of / summarize your data. Doing so can be misleading, particularly when you have small sample sizes. Why?\n\nbar plots hide the distribution of the underlying data (many different distributions can lead to the same plot)\nwhen used this way, the height of the bar (typically) represents the mean of the data, which can cause readers to incorrectly infer that the data are normally distributed with no outliers (this of course may be true in certain cases, but certainly not always)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft: Figure 1 from Weissgerber et al. (2015) Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm. PLOS Biology 13:e1002128. https://doi.org/10.1371/journal.pbio.1002128 | Right: Artwork by Allison Horst\n\n\n\nIt’s okay to use bar (or related) plots anytime you’re comparing counts (e.g. population size of different countries, total earnings by group) — this is really where bar plots shine! If you are using a bar plot to visualize the distribution/summarize of your data, you should consider if there are better alternative options (e.g. box plots) — if you are inclined to include some sort of error bar / standard deviation on your bar plot, you are likely attempting to use your bar plot to visualize a distribution. Why is this wrong?\nIt’s not necessarily wrong, but it can be misleading, particularly when dealing with small sample sizes because (1) it’s impossible to know the distribution of the underlying data, and many different data distributions can lead to the same bar plot (see figure on lecture 4.1 slide 15). (2) When used this way, the height of the bar (typically) represents the mean of the data, which can cause readers to incorrectly infer that the data are normally distributed with no outliers (this of course may be true in certain cases, but certainly is not always true…particularly when dealing with small sample sizes where outliers are common)\n\nBar plots are very commonly used in both ways (comparing counts and visualizing distributions) — for example, see this online resource that reviews how to interpret both forms of a bar plot. However, you should proceed with extreme caution when using bar plots to summarize your data for the reasons outlined above. If you do choose to use a bar plot, consider layering on the raw data points as well (this isn’t always feasible with larger data sets)."
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#dumbbell-plot",
    "href": "slides/week4.1-rankings-slides.html#dumbbell-plot",
    "title": "EDS 240",
    "section": "",
    "text": "Lollipop variant: dumbbell plot\n\nDumbbell plots can be a really simple and intuitive way to visualize a change or difference in two sets of data points:\n\nWe can make dumbbell plots using a combination of geom_segment() and geom_point().\n\nSee note: https://stackoverflow.com/questions/35322919/grouped-data-by-factor-with-geom-segment\n“You can think of geom_linerange() as a convenient version of geom_segment for a specific use case. geom_segment() is for when you need to draw arbitrary line segments in a fairly non-systematic way. geom_linerange() is for the specific case of a collection of vertical bars at specified x values with different lengths (e.g. error bars, etc)”"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#dumbbell-plot-subset",
    "href": "slides/week4.1-rankings-slides.html#dumbbell-plot-subset",
    "title": "EDS 240",
    "section": "",
    "text": "Subset occupation data\n\nLet’s say we want to explore differences in male vs. female median salaries across occupations that are female dominated (75%+ female), male dominated (75%+ male), and those that are a relatively even split (45-55% female). Let’s first randomly select 10 occupations from each of those categories:\n\n#....guarantee the same random samples each time we run code.....\nset.seed(0)\n\n#.........get 10 random jobs that are 75%+ female (2016).........\nf75 &lt;- jobs_clean |&gt; \n  filter(year == 2016, group_label == \"Occupations that are 75%+ female\") |&gt; \n  slice_sample(n = 10)\n\n#..........get 10 random jobs that are 75%+ male (2016)..........\nm75 &lt;- jobs_clean |&gt; \n  filter(year == 2016, group_label == \"Occupations that are 75%+ male\") |&gt; \n  slice_sample(n = 10)\n\n#........get 10 random jobs that are 45-55%+ female (2016).......\nf50 &lt;- jobs_clean |&gt; \n  filter(year == 2016, group_label == \"Occupations that are 45-55% female\") |&gt; \n  slice_sample(n = 10)\n\n#.......combine dfs & relevel factors (for plotting order).......\nsubset_jobs &lt;- rbind(f75, m75, f50) |&gt; \n  mutate(group_label = fct_relevel(group_label, \"Occupations that are 75%+ female\", \n                                   \"Occupations that are 45-55% female\", \"Occupations that are 75%+ male\"))"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#dumbbell-plot-create",
    "href": "slides/week4.1-rankings-slides.html#dumbbell-plot-create",
    "title": "EDS 240",
    "section": "",
    "text": "Create dumbbell plot\n\nSee the output on the next slide.\n\n# initialize plot (we'll map our aesthetics locally for each geom, below) ----\nggplot(subset_jobs) +\n  \n  # create dumbbells ----\n  geom_segment(aes(x = total_earnings_female, xend = total_earnings_male, \n                   y = fct_reorder(occupation, total_earnings), yend = occupation)) + # reorder occupation by avg_salary here\n  geom_point(aes(x = total_earnings_male, y = occupation), \n             color = \"#CD93D8\", size = 2.5) +\n  geom_point(aes(x = total_earnings_female, y = occupation), \n             color = \"#6A1E99\", size = 2.5) +\n  \n  # facet wrap by group ----\n  facet_wrap(~group_label, nrow = 3, scales = \"free_y\") + # \"free_y\" plots only the axis labels that exist in each group\n  \n  # axis breaks & $ labels ----\n  scale_x_continuous(labels = scales::label_dollar(scale = 0.001, suffix = \"k\"),\n                     breaks = c(25000, 50000, 75000, 100000, 125000))"
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#dumbbell-plot-output",
    "href": "slides/week4.1-rankings-slides.html#dumbbell-plot-output",
    "title": "EDS 240",
    "section": "",
    "text": "Dumbbell plot output\n\nThere are definitely some additional modifications we would need to make before calling this plot done (e.g. adding a title, legend information, theme) – we’ll come back to that in a later lecture."
  },
  {
    "objectID": "slides/week4.1-rankings-slides.html#end-break",
    "href": "slides/week4.1-rankings-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 1 (of 2) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#title-slide",
    "href": "slides/week3.2-distributions-slides.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 3.2\nVisualizing distributions\n\nWeek 3 | January 22nd, 2024"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#what-is-dist",
    "href": "slides/week3.2-distributions-slides.html#what-is-dist",
    "title": "EDS 240",
    "section": "",
    "text": "Visualizing data distribution?\n\n  \n\n\nVisualizing the spread of a numeric variable(s)"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#viz-dist",
    "href": "slides/week3.2-distributions-slides.html#viz-dist",
    "title": "EDS 240",
    "section": "",
    "text": "“Core” distribution chart types\n\n\n\n\nHistograms\n\n\n\n\n\n\n\n\n\n\n\n\nDensity plots\n\n\n\n\n\n\n\n\n\n\n\n\nRidgeline plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBox plots\n\n\n\n\n\n\n\n\n\n\n\n\nViolin plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples show the distribution of penguin body masses (g) for Adelie, Chinstrap & Gentoo penguins."
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#mko-temps-intro",
    "href": "slides/week3.2-distributions-slides.html#mko-temps-intro",
    "title": "EDS 240",
    "section": "",
    "text": "The data: bottom temperatures at Mohawk Reef\n\nThe Santa Barbara Coastal Long Term Ecolgical Research (SBC LTER) site was established in 2000 to understand the ecology of coastal kelp forest ecosystems. A number of coastal rocky reef sites are outfitted with instrumentation that collect long-term monitoring data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll be exploring bottom temperatures recorded at Mohawk Reef, a near-shore rocky reef and one of the Santa Barbara Coastal (SBC) LTER research sites."
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#mko-temps-wrangling",
    "href": "slides/week3.2-distributions-slides.html#mko-temps-wrangling",
    "title": "EDS 240",
    "section": "",
    "text": "Data wrangling\n\nData are imported directly from the EDI Data Portal. Explore the metadata package online to learn more about these data.\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(chron)\nlibrary(naniar)\n\n#..........................import data...........................\nmko &lt;- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2007.17&entityid=02629ecc08a536972dec021f662428aa\")\n\n#..........................wrangle data..........................\nmko_clean &lt;- mko |&gt;\n\n  # keep only necessary columns ----\n  select(year, month, day, decimal_time, Temp_bot, Temp_top, Temp_mid) |&gt;\n\n  # create datetime column (not totally necessary for our plots, but it can helpful to know how to do this!) ----\n  unite(date, year, month, day, sep = \"-\", remove = FALSE) |&gt;\n  mutate(time = chron::times(decimal_time)) |&gt;\n  unite(date_time, date, time, sep = \" \") |&gt;\n\n  # coerce data types ----\n  mutate(date_time = as.POSIXct(date_time, \"%Y-%m-%d %H:%M:%S\", tz = \"GMT\"), # see &lt;https://www.neonscience.org/resources/learning-hub/tutorials/dc-convert-date-time-posix-r&gt; for overview of POSIXct vs POSIXlt\n         year = as.factor(year),\n         month = as.factor(month),\n         day = as.numeric(day)) |&gt;\n\n  # add month name by indexing the built-in `month.name` vector ----\n  mutate(month_name = as.factor(month.name[month])) |&gt;\n\n  # replace 9999s with NAs ----\n  naniar::replace_with_na(replace = list(Temp_bot = 9999, \n                                         Temp_top = 9999, \n                                         Temp_mid = 9999)) |&gt;\n\n  # select/reorder desired columns ----\n  select(date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)\n\n#......................explore missing data......................\n\n# counts and percentage of missing data by year ----\nsee_NAs &lt;- mko_clean |&gt; \n  group_by(year) |&gt; \n  naniar::miss_var_summary() |&gt;\n  filter(variable == \"Temp_bot\")\n\n# visualize missing Temp_bot ----\nbottom &lt;- mko_clean |&gt; select(Temp_bot)\nmissing_temps &lt;- naniar::vis_miss(bottom)"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#hist-overview",
    "href": "slides/week3.2-distributions-slides.html#hist-overview",
    "title": "EDS 240",
    "section": "",
    "text": "Histograms - ggplot2::geom_histogram()\n\nWhat are they?\n\nHistograms are used to represent the distribution of a numeric variable(s), which is cut into several bins. The number of observations per bin is represented by the height of the bar.\n\n\n\nNeed:\n\na numeric variable with lots of values\nmeaningful differences between values\n\nImportant considerations:\n\nbin width (30 bins by default)\ntoo few / too many bins"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#hist-group-num",
    "href": "slides/week3.2-distributions-slides.html#hist-group-num",
    "title": "EDS 240",
    "section": "",
    "text": "Histograms - avoid plotting too many groups\n\nTwelve groups (month_name) is too many groups – especially when the range of temperature values for each of our groups largely overlap:\n\nmko_clean |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) +\n  geom_histogram(position = \"identity\", alpha = 0.5)"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#hist-updates",
    "href": "slides/week3.2-distributions-slides.html#hist-updates",
    "title": "EDS 240",
    "section": "",
    "text": "Histograms - adjustments\n\n\nSmall multiplesFewer groupsAdjust colorsModify bin widths\n\n\nIf you want to plot all groups, consider splitting them into small multiples. If so, does color add any valuable information? Remove if not:\n\nmko_clean |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  ggplot(aes(x = Temp_bot)) +\n  geom_histogram() +\n  facet_wrap(~month_name)\n\n\n\n\n\n\n\n\n\n\nLet’s instead compare just three months: April (generally the coldest month), October (generally a hot month), June (somewhere in between):\n\nmko_clean |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  filter(month_name %in% c(\"April\", \"June\", \"October\")) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) + # piping data into ggplot, so don't need to define `data` arg\n  geom_histogram(position = \"identity\", alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nUse fill to fill bars with a specified color(s) and color to outline bars with a specified color(s):\n\nmko_clean |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  filter(month_name %in% c(\"April\", \"June\", \"October\")) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) + \n  geom_histogram(position = \"identity\", alpha = 0.5,  color = \"black\") +\n  scale_fill_manual(values = c(\"#2C5374\", \"#ADD8E6\", \"#8B3A3A\"))\n\n\n\n\n\n\n\n\n\n\nModify binwidth (30 bins by default) – does a bin width of 1 (degree Celsius) actually make sense? Consider scale of interest. Also be mindful when using bins – too few bins will result in loss of distribution shape.\n\nmko_clean |&gt; \n  filter(month_name %in% c(\"April\", \"June\", \"October\")) |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, binwidth = 1) +\n  scale_fill_manual(values = c(\"#2C5374\", \"#ADD8E6\", \"#8B3A3A\"))"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#density-overview",
    "href": "slides/week3.2-distributions-slides.html#density-overview",
    "title": "EDS 240",
    "section": "",
    "text": "Density plots - ggplot2::geom_density()\n\nWhat are they?\n\nA smoothed version of a histogram. Density plots are representations of the distribution of a numeric variable(s), which uses a kernel density estimate (KDE) to show the probability density function of the variable. The area under each curve is equal to 1. Use a density plot when you are most concerned with the shape of the distribution.\n\n\n\nNeed:\n\na numeric variable with lots of values\n\nImportant considerations:\n\nuseful when you want to visualize the shape of your data (not affected by bin number)\ndoes not indicate sample size\ncan be misleading with small data sets\nband width, which affects level of smoothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck out this cool interactive tool, by Matthew Conlen, for a succinct and clear explanation of KDE.\n\n\nThe PDF is used to specify the probability of the random variable falling within a particular range of values, as opposed to taking on any one value https://en.wikipedia.org/wiki/Probability_density_function"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#density-group-num",
    "href": "slides/week3.2-distributions-slides.html#density-group-num",
    "title": "EDS 240",
    "section": "",
    "text": "Density plots - avoid plotting too many groups\n\nSimilar to the histogram, twelve groups (month_name) is too many groups! Consider small multiples (using facet_wrap()) if you want to keep all groups.\n\nmko_clean |&gt; \n  mutate(month_name = factor(x = month_name, levels = month.name)) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#density-updates",
    "href": "slides/week3.2-distributions-slides.html#density-updates",
    "title": "EDS 240",
    "section": "",
    "text": "Density plots - adjustments\n\n\nSmall multiplesFewer groupsModify band widths\n\n\nIf you want to plot all groups, consider splitting them into small multiples. If so, does color add any valuable information? Remove if not:\n\nmko_clean |&gt; \n  mutate(month_name = factor(month_name, levels = month.name)) |&gt; \n  ggplot(aes(x = Temp_bot)) +\n  geom_density(fill = \"gray30\") +\n  facet_wrap(~month_name)\n\n\n\n\n\n\n\n\n\n\nLet’s instead compare three months: April (generally the coldest month), October (generally a hot month), June (somewhere in between):\n\nmko_clean |&gt; \n  filter(month_name %in% c(\"April\", \"June\", \"October\")) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) +\n  geom_density(alpha = 0.5) + \n  scale_fill_manual(values = c(\"#2C5374\", \"#ADD8E6\", \"#8B3A3A\"))\n\n\n\n\n\n\n\n\n\n\nModify bandwidth by declaring a multiplier of the default bandwidth adjustment. Reducing the adjust argument reduces the amount of smoothing (default adjust = 1):\n\nmko_clean |&gt; \n  filter(month_name %in% c(\"April\", \"June\", \"October\")) |&gt; \n  ggplot(aes(x = Temp_bot, fill = month_name)) +\n  geom_density(alpha = 0.5, adjust = 1/2) + \n  scale_fill_manual(values = c(\"#2C5374\", \"#ADD8E6\", \"#8B3A3A\"))"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#hist-vs-dens1",
    "href": "slides/week3.2-distributions-slides.html#hist-vs-dens1",
    "title": "EDS 240",
    "section": "",
    "text": "An important distinction\n\nHistograms show us the counts (frequency) of values in each range (bin), represented by the height of the bars.\n\nDensity plots show the proportion of values in each range (area under the curve equal 1; peaks indicate where more values are concentrated, but it does not tell us anything about the the number of observations).\n\n\n\nWe’ll use some dummy data to demonstrate how this differs visually:\n\ndummy_data &lt;- data.frame(value = c(rnorm(n = 100, mean = 5),\n                                   rnorm(n = 200, mean = 10)),\n                         group = rep(c(\"A\", \"B\"),\n                                     times = c(100, 200)))\n\nHere, we have two groups (A, B) of values which are normally distributed, but with different means. Group A also has a smaller sample size (100) than group B (200)."
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#hist-vs-dens2",
    "href": "slides/week3.2-distributions-slides.html#hist-vs-dens2",
    "title": "EDS 240",
    "section": "",
    "text": "An important distinction\n\n\n\nIt’s easy to see that group B has a larger sample size than group A when looking at our histogram. Additionally, we can get a good sense of our data distribution. But what happens when you reduce the number of bins (e.g. set bins = 4)?\n\nggplot(dummy_data, aes(x = value, fill = group)) +\n  geom_histogram(position = \"identity\", alpha = 0.7) +\n  geom_rug(aes(color = group), alpha = 0.75)\n\n\n\n\n\n\n\n\n\nWe lose information about sample size in our density plot (note that both curves are ~the same height, despite group B having 2x as many observations). However, they’re great for visualizing the shape of our distributions since they are unaffected by the number of bins.\n\nggplot(dummy_data, aes(x = value, fill = group)) +\n  geom_density(alpha = 0.7) +\n  geom_rug(aes(color = group), alpha = 0.75)\n\n\n\n\n\n\n\n\n\n\n\nRug plots added as an alternative way to visualize the data distribution and also as an indicator of sample size.\n\n\nIn the histogram, group B has higher bars; difference in height disappears in density plot"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#density-hist-combo",
    "href": "slides/week3.2-distributions-slides.html#density-hist-combo",
    "title": "EDS 240",
    "section": "",
    "text": "Combining geoms - histogram & density plot\n\nOverlaying a histogram and density plot requires scaling down the histogram to match the density curve scale. Adding y = after_stat(density) within the aes() function rescales the histogram counts so that bar areas integrate to 1:\n\nggplot(mko_clean, aes(x = Temp_bot, y = after_stat(density))) + # scale down hist to match density curve\n  geom_histogram(fill = \"gray\", color = \"black\", alpha = 0.75) +\n  geom_density(size = 1) \n\n\n\nCheck out this great blog post on the after_stat() function, by June Choe\n\n\nSee https://stackoverflow.com/questions/46734555/ggplot2-histogram-why-do-y-density-and-stat-density-differ"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#scaled-density",
    "href": "slides/week3.2-distributions-slides.html#scaled-density",
    "title": "EDS 240",
    "section": "",
    "text": "Scaled density plots for comparing groups to a whole\n\nIn a normal density plot, the area under the curve(s) is equal to 1. In a scaled density plot, the area under the curve reflects the number of observations for each group.\nWe can use scaled density plots to compare individual group distributions to the total distribution. We’ll do so using the palmerpenguins::penguins data set.\n\n\n# use `after_stat(count)` to plot density of observations ----\nggplot(penguins, aes(x = body_mass_g, y = after_stat(count))) +\n \n  # plot full distribution curve with label \"all penguins\"; remove 'species' col so that this doesn't get faceted later on ----\n  geom_density(data = select(penguins, -species), \n               aes(fill = \"all penguins\"), color = \"transparent\") +\n  \n  # plot second curve with label \"species\" ----\n  geom_density(aes(fill = \"species\"), color = \"transparent\") +\n  \n  # facet wrap by species ----\n  facet_wrap(~species, nrow = 1) +\n  \n  # update colors, x-axis label, legend position ----\n  scale_fill_manual(values = c(\"grey\",\"#0C8346\"), name = NULL) +\n  labs(x = \"Body Mass (g)\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nExample adapted from Meghan Hall’s CMU 36-315 Lecture 7. For more on scaled density plots, check out this post, by Andrew Collier."
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#ridgeline-overview",
    "href": "slides/week3.2-distributions-slides.html#ridgeline-overview",
    "title": "EDS 240",
    "section": "",
    "text": "Ridgeline plots - {ggridges}\n\nWhat are they?\n\nRidgeline plots show the distribution of a numeric variable for multiple groups.\n\n\n\nNeed:\n\na numeric variable with lots of values\n\nImportant considerations:\n\nwork best when you have &gt; 6 groups\nworks well when there is a clear pattern in the result (e.g. if there is an obvious ranking in groups) and / or when visualizing changes in distributions over time or space"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#ridgeline-groups",
    "href": "slides/week3.2-distributions-slides.html#ridgeline-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Ridgeline plots - good for multiple groups\n\nThe {ggridges} package has a number of different geoms for creating ridgeline plots that work well for data sets with larger group numbers (e.g. months). Two great geoms to explore (to start):\n\n\ngeom_density_ridges() to create a basic ridgeline plot:\n\nggplot(mko_clean, aes(x = Temp_bot, y = month_name)) +\n  ggridges::geom_density_ridges()\n\n\n\n\n\n\n\n\n\ngeom_density_ridges_gradient() to fill with a color gradient:\n\nggplot(mko_clean, aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +\n  ggridges::geom_density_ridges_gradient() +\n  scale_fill_gradientn(colors = c(\"#2C5374\",\"#849BB4\", \"#D9E7EC\", \"#EF8080\", \"#8B3A3A\"))"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#ridgeline-adjustments",
    "href": "slides/week3.2-distributions-slides.html#ridgeline-adjustments",
    "title": "EDS 240",
    "section": "",
    "text": "Ridgeline plots - adjustments\n\n\nGroup orderOverlap & tailsQuantilesJitter raw data\n\n\n\n\nOrder by month (ideal, since months have an inherent order):\n\nggplot(mko_clean, aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +\n  ggridges::geom_density_ridges_gradient() +\n  scale_y_discrete(limits = rev(month.name)) +\n  scale_fill_gradientn(colors = c(\"#2C5374\",\"#849BB4\", \"#D9E7EC\", \"#EF8080\", \"#8B3A3A\"))\n\n\n\n\n\n\n\n\n\nOrder by mean or median (makes more sense when you have unordered groups):\n\nmko_clean |&gt; \n  mutate(month_name = fct_reorder(month_name, Temp_bot, .fun = mean)) |&gt; \n  ggplot(mko_clean, mapping = aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +\n  ggridges::geom_density_ridges_gradient() +\n  scale_fill_gradientn(colors = c(\"#2C5374\",\"#849BB4\", \"#D9E7EC\", \"#EF8080\", \"#8B3A3A\"))\n\n\n\n\n\n\n\n\n\n\n\n\nrel_min_height adjusts trailing tails and scale controls the extent to which the different densities overlap)\n\nggplot(mko_clean, aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +\n  ggridges::geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) +\n  scale_y_discrete(limits = rev(month.name)) +\n  scale_fill_gradientn(colors = c(\"#2C5374\",\"#849BB4\", \"#D9E7EC\", \"#EF8080\", \"#8B3A3A\"))\n\n\n\n\n\n\n\n\n\n\nInclude a median line by using the stat_density_ridges() geom and setting the number of quantiles to 2:\n\nggplot(mko_clean, aes(x = Temp_bot, y = month_name)) +\n  ggridges::stat_density_ridges(rel_min_height = 0.01, scale = 3,\n                                quantile_lines = TRUE, quantiles = 2) +\n  scale_y_discrete(limits = rev(month.name))\n\n\n\n\n\n\n\n\n\n\nVisualize the raw data underlying the density ridges (since our temperature data is too large (&gt;473,000 rows), so we’ll use the palmerpenguins::penguins data set to demo):\n\n\n\nJittered points\n\n\nggplot(penguins, aes(x = body_mass_g, y = species)) +\n  ggridges::geom_density_ridges(jittered_points = TRUE, \n                                alpha = 0.5, point_size = 0.5)\n\n\n\n\n\n\n\n\n\n\nRaincloud plot:\n\n\nggplot(penguins, aes(x = body_mass_g, y = species)) +\n  ggridges::geom_density_ridges(jittered_points = TRUE, alpha = 0.5, \n                                point_size = 0.5, scale = 0.6,\n                                position = \"raincloud\")"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#boxplot-overview",
    "href": "slides/week3.2-distributions-slides.html#boxplot-overview",
    "title": "EDS 240",
    "section": "",
    "text": "Box plots - ggplot2::geom_boxplot()\n\nWhat are they?\n\nBox plots summarize the distribution of a numeric variable for one or several groups.\n\n\n\nNeed:\n\na numeric variable, often with multiple groups\n\nImportant considerations:\n\nbox plots summarize data, meaning we can’t see the underlying shape of the distribution or sample size\nadd jittered points on top, or if large sample size, consider a violin plot"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#boxplot-groups",
    "href": "slides/week3.2-distributions-slides.html#boxplot-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Box plots - good for multiple groups\n\nBox plots are great for a few to multiple groups (too many boxes just results in a lot of information to synthesize, as a viewer). If your x-axis text is long, consider flipping your axes to make them less crunched:\n\nggplot(mko_clean, aes(x = month_name, y = Temp_bot)) +\n  geom_boxplot() +\n  scale_x_discrete(limits = rev(month.name)) +\n  coord_flip()"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#boxplot-adjustments",
    "href": "slides/week3.2-distributions-slides.html#boxplot-adjustments",
    "title": "EDS 240",
    "section": "",
    "text": "Box plots - adjustments\n\n\nOutliersHighlight a group(s)Jitter raw dataDodged groupsOverlay beeswarm\n\n\nYou can modify outlier aesthetics inside geom_boxplot():\n\nggplot(mko_clean, aes(x = month_name, y = Temp_bot)) +\n  geom_boxplot(outlier.color = \"purple\", outlier.shape = \"circle open\", outlier.size = 5) +\n  scale_x_discrete(limits = rev(month.name)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nHighlight a group of interest – one easy way to do so is by using the {gghighlight} package. Here, we specify a specific month (\"October\") to highlight:\n\nmko_clean |&gt; \n  ggplot(aes(x = month_name, y = Temp_bot, fill = month_name)) +\n  geom_boxplot() +\n  scale_x_discrete(limits = rev(month.name)) +\n  gghighlight::gghighlight(month_name == \"October\") +\n  coord_flip() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nSince box plots hide sample size, consider overlaying raw data points using geom_jitter() (since our temperature data is too large (&gt;473,000 rows), we’ll use the palmerpenguins::penguins data set to demo):\nNOTE: Be sure to remove outliers, since plotting raw data will result in those data points being a second time:\n\nggplot(na.omit(penguins), aes(x = species, y = body_mass_g)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(alpha = 0.5, width = 0.2) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nYou may have data where you want to include an additional grouping variable – for example, let’s say we want to plot penguin body masses by species and year. We’ll need to at least dodge our overlaid points so that they sit on top of the correct box. Preferably, we both jitter and dodge our points:\n\npenguins |&gt; \n  mutate(year = as.factor(year)) |&gt; \n  ggplot(aes(x = species, y = body_mass_g, color = year)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_point(alpha = 0.5, position = position_jitterdodge(jitter.width = 0.2)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nSimilar to overlaying the raw jittered data points, we can combine our box plot with a beeswarm plot using {ggbeeswarm}. Beeswarm plots visualize the density of data at each point, as well as arrange points that would normally overlap so that they fall next to one another instead. Consider using a standalone beeswarm plot here as well! We’ll again use the palmerpenguins::penguins data set to demo:\n\nggplot(na.omit(penguins), aes(x = species, y = body_mass_g)) +\n  geom_boxplot(outlier.shape = NA) +\n  ggbeeswarm::geom_beeswarm(size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#violin-plot-overview",
    "href": "slides/week3.2-distributions-slides.html#violin-plot-overview",
    "title": "EDS 240",
    "section": "",
    "text": "Violin plots - ggplot2::geom_violin()\n\nWhat are they?\n\nViolin plots visualize the distribution of a numeric variable for one or several groups, where the shape of the violin represents the density estimate of the variable (i.e. the more data points in a specific range, the larger the violin is for that range). They provide more information about the underlying distribution than a box plot.\n\n\n\nNeed:\n\na numeric variable, often with multiple groups\n\nImportant considerations:\n\nordering groups by median value can make it easier to understand\n\nshow sample size when comparing groups with very different distributions (e.g. half violin plot)"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#violin-plot-groups",
    "href": "slides/week3.2-distributions-slides.html#violin-plot-groups",
    "title": "EDS 240",
    "section": "",
    "text": "Violin plots - good for multiple groups with lots of data\n\nViolin plots are great for a few to multiple groups, and are often a better choice than box plots when you have a very large data set (and overlaying jittered points looks busy or downright unreasonable). If your x-axis text is long, consider flipping your axes to make them less crunched:\n\nggplot(mko_clean, aes(x = month_name, y = Temp_bot)) +\n  geom_violin() +\n  scale_x_discrete(limits = rev(month.name)) +\n  coord_flip()"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#box-violin-combo",
    "href": "slides/week3.2-distributions-slides.html#box-violin-combo",
    "title": "EDS 240",
    "section": "",
    "text": "Combining geoms - adjustments\n\n\nOverlay boxplotHalf-violin half-dot plot\n\n\nOverlaying a box plot inside a violin plot can be helpful in providing your audience with summary stats in a compact form:\n\nggplot(mko_clean, aes(x = month_name, y = Temp_bot)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1, color = \"gray\", alpha = 0.5, \n               outlier.color = \"red\") +\n  scale_x_discrete(limits = rev(month.name)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nThe {see} package provides geom_violindot(), which is useful for simultaneously visualizing distribution and sample size. Because it can quickly get overcrowded with large sample sizes (like Temp_bot), we’ll use palmerpenguins::penguins to demo here:\n\nggplot(penguins, aes(x = species, y = bill_length_mm, fill = species)) +\n  see::geom_violindot(size_dots = 5, alpha = 0.5) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/week3.2-distributions-slides.html#end-break",
    "href": "slides/week3.2-distributions-slides.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "Take a Break\n\n\n~ This is the end of Lesson 2 (of 3) ~\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#title-slide",
    "href": "slides/week5.3-choropleth.html#title-slide",
    "title": "EDS 240",
    "section": "",
    "text": "EDS 240: Lecture 5.3\nColors & Choropleths\n\nWeek 5 | February 5th, 2024"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#making-map",
    "href": "slides/week5.3-choropleth.html#making-map",
    "title": "EDS 240",
    "section": "",
    "text": "Let’s explore county-level precipitation data using a choropleth map. Importantly, we’ll decide on a color palette / scale type and make any necessary adjustments."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#choropleth",
    "href": "slides/week5.3-choropleth.html#choropleth",
    "title": "EDS 240",
    "section": "",
    "text": "What’s a choropleth?\n\n\nChoropleths are maps that display the spatial distribution of a variable across divided geographical areas / regions, where variable is encoded by color.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChoropleth by Ramiro Gómez using GeoPandas (blog post)\n\n\n\n\n\n\n\n\n\n\n\n\nChoropleth by Hanna & Farnsworth (2013)\n\n\n\n\n\nChoosing the right color palette and scale type are critically important. Oftentimes, you’ll need to adjust the default mapping of colors to accurately tell your story."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#data",
    "href": "slides/week5.3-choropleth.html#data",
    "title": "EDS 240",
    "section": "",
    "text": "The Data\n\nNOAA National Centers for Environmental Information (NCEI) is responsible for preserving, monitoring, assessing, and providing public access to the Nation’s geophysical data and information.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind public access to a massive inventory of climate data on their Climate Monitoring page. Today’s lesson will use the Climate at a Glance collection. Specifically, we’ll be exploring how precipitation across the continental US over the past 5 years compares to the 20th century average. To do so, we’ll work with county-level precipitation data, accessed via the County Mapping portal."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#tigris",
    "href": "slides/week5.3-choropleth.html#tigris",
    "title": "EDS 240",
    "section": "",
    "text": "Use {tigris} to download shapefiles\n\nWe can use the {tigris} package to download and use Census TIGER/Line shapefiles in R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA shapefile is a vector data file format commonly used for geospatial analysis.\nShapefiles contain information for spatially describing features (e.g. points, lines, polygons), as well as any associated attribute information.\nYou can find / download shapefiles online (e.g. from the US Census Bureau), or depending on the tools available, access them via packages (like we’re doing today).\n\n\n\n\nCheck out Ch. 5 of Analyzing US Census Data: Methods, Mpas, and Models in R by Kyle E. Walker for a great intro to {tigris}"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#sf",
    "href": "slides/week5.3-choropleth.html#sf",
    "title": "EDS 240",
    "section": "",
    "text": "Simple features in R\n\n\nSpatial data can take many forms – simple features is a standard that allows different types of software to specify spatial data in a common way.\n\n\n\nSimple features are comprised of:\n1. a geometry object (e.g. a point, line, polygon) that describes where on Earth the feature is located\n2. attribute data associated with the geometry object (e.g. the precipitation across a county during the last 5 years)\n\n\n\nBecause of how simple feature (sf) objects are represented in R (they look like data frames!), simple features can be maniupulated and plotted by other well-known packages like {dplyr} and {ggplot2}. Packages like {sf} provide tools for working with simple features (sf objects), but we’ll only need to rely on {ggplot2}s built-in geom_sf() geometry to plot our data.\n\n\n\nWhen we download our shapefile using {tigris}, it’ll be loaded as a simple features (sf) object with geometries that allow us to plot county lines. We’ll join our county-level precipitation data to our sf object so that we can color counties by precipitation."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#data-wrangling",
    "href": "slides/week5.3-choropleth.html#data-wrangling",
    "title": "EDS 240",
    "section": "",
    "text": "Data Wrangling\n\nHere, we’ll use the {tigris} package to import geometries for our US counties, then join it with our precipitation data:\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(tigris)\n\n#.........................get shape data.........................\ncounty_geo &lt;- tigris::counties(class = \"sf\", cb = TRUE) |&gt; # cb = TRUE to use cartographic boundary files\n  \n  # shift US to fit AK, HI, PR (we'll be filtering these out though) and transform CRS to USA Contiguous Albers Equal Area Conic (ESRI:102003) ----\n  shift_geometry()\n\n#....................import precipitation data...................\nprecip_data &lt;- read_csv(here::here(\"week5\", \"data\", \"county-jan19-dec23-precip.csv\"), skip = 4)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                               data wrangling                             ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n     \n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##  ~ wrangle geometries  ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ncounty_geo_wrangled &lt;- county_geo |&gt;\n  \n  # clean up col names ----\n  janitor::clean_names() |&gt;\n  \n  # rename county & state cols ----\n  rename(county = namelsad, state = state_name) |&gt;\n  \n  # remove states / territories that we don't have precip data for ----\n  filter(!state %in% c(\"Alaska\", \"Hawaii\", \"District of Columbia\",\n                       \"United States Virgin Islands\", \"Puerto Rico\", \"American Samoa\",\n                       \"Commonwealth of the Northern Mariana Islands\", \"Guam\")) |&gt;\n  \n  # capitalize \"city\" (VA) ----\n  mutate(county = str_replace(string = county, pattern = \" city\", replacement = \" City\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##  ~ wrangle precipitation data  ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nprecip_wrangled &lt;- precip_data |&gt;\n  \n  # clean up col names ----\n  janitor::clean_names() |&gt;\n  \n  # rename county col ----\n  rename(county = name) |&gt;\n  \n  # filter out DC ----\n  filter(!county %in% c(\"Washington, D.C.\")) |&gt;\n  \n  # update name to match that in county_geo df ----\n  mutate(county = str_replace(string = county, pattern = \"Dona Ana County\", replacement = \"Doña Ana County\")) |&gt;\n  \n  # coerce precip & 20th centruy avg from chr to numeric ----\n  mutate(value = as.numeric(value),\n         x1901_2000_mean = as.numeric(x1901_2000_mean)) |&gt;\n  \n  # calculate % change ----\n  mutate(perc_change = ((value - x1901_2000_mean)/x1901_2000_mean)*100) |&gt;\n  \n  # select, rename, reorder cols ----\n  select(id, state, county, mean_1901_2000 = x1901_2000_mean, precip = value, perc_change, anomaly_1901_2000_base_period)\n\n##~~~~~~~~~~~~~~~~~~\n##  ~ join dfs  ----\n##~~~~~~~~~~~~~~~~~~\n\n# join dfs (be sure to join precip TO sf object, not the other way around) -------\njoined_precip_geom &lt;- full_join(county_geo_wrangled, precip_wrangled)"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#base-map",
    "href": "slides/week5.3-choropleth.html#base-map",
    "title": "EDS 240",
    "section": "",
    "text": "Start by creating a base map\n\n\n\nbase_map &lt;- ggplot(joined_precip_geom) +\n  geom_sf(aes(fill = perc_change), linewidth = 0.1) +\n  labs(title = \"5-year precipitation compared with the 20th century average\",\n       subtitle = \"January 2019 - December 2023\",\n       caption = \"Source: National Centers for Environmental Information\") +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    plot.caption = element_text(face = \"italic\",\n                                margin = margin(t = 2, r = 0.5, b = 0, l = 0, \"lines\"))\n  )\n\nbase_map\n\n\n\n\n\n\n\n\n\nBecause we want to map precipitation relative to the 20th century average (e.g. has precipitation for a given region over the last 5 years been above or below the average), a divering color palette makes a lot of sense.\n\n\nYou may notice that Connecticut is missing most of its data. After some digging, I learned that CT recently (2022) replaced its eight counties with nine planning regions as county-equivalents (read more in the UC Census Bureau Notice on 06/06/2022). I couldn’t quite make sense of how to match old county names to new planning regions, as there’s a decent amount of geographic overlap, soooo I gave up (for now) ."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#decide-on-scale-type",
    "href": "slides/week5.3-choropleth.html#decide-on-scale-type",
    "title": "EDS 240",
    "section": "",
    "text": "Classed or unclassed color scale?\n\nWe’ve landed on a diverging color palette, but should we use a classed (aka binned) or unclassed (aka continuous) palette?\n\n\nUse a classed color scale if you want to communicate statistical brackets: \n\nthe focus is on which data units fall into pre-defined classes, rather than overall pattern\nbest if you want you audience to read values (gets more difficult with more classes; easier with interactive visualizations)\nthe more classes you have, the more nuanced your map becomes\n\n\n\nUse an unclassed color scale if you want to show general patterns: \n\nthe focus is on general patterns, rather than which statistical brackets regions fall into\nbest if you don’t want to interpret for your reader – it makes it easier to see outliers, transitions to and comparisons with neighboring regions\n\n\nAdapted from When to use classed and when to use unclassed color scales, by Lisa Charlotte Muth\nFor another great read on building color scales for choropleth maps, check out this article in Axis Map’s Cartography Guide."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#start-unclassed",
    "href": "slides/week5.3-choropleth.html#start-unclassed",
    "title": "EDS 240",
    "section": "",
    "text": "Start with an unclassed scale\n\n\n\n“The unclassed choropleth is the most exact representation of the data model possible,”\n\n\n-Judith A. Tyner, in Priciples of Map Design\n\n\n\n\n“No matter if you decide for a classed map at the end, you should start your process by looking at an unclassed map. This will help you see subtle differences between regions and make a conscious decision if and how you should simplify them.”\n\n\n-Lisa Charlotte Muth, in When to use classed and when to use unclassed color scales\n\n\n\n\n\nWe’ll heed this advice and start with an unclassed map!"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#decide-on-palette",
    "href": "slides/week5.3-choropleth.html#decide-on-palette",
    "title": "EDS 240",
    "section": "",
    "text": "Pick a color palette!\n\nRecall from earlier that precipitation data is often encoded using a brown / blue color scheme (with drier conditions falling on the brown side and wetter conditions falling on the blue side).\nLucky for us, RColorBrewer has this exact palette. Let’s use all 11 hues for our unclassed map:\n\n\n\n\nPreview the palette using display.brewer.pal() with our desired number of hues:\n\n\nRColorBrewer::display.brewer.pal(n = 11, name = 'BrBG')\n\n\n\n\n\n\n\n\n\n\nSave the HEX codes to a named object using brewer.pal() (we’ll call this in our plot later):\n\n\nmy_brew_palette11 &lt;- RColorBrewer::brewer.pal(n = 11, name = 'BrBG')\nmy_brew_palette11\n\n [1] \"#543005\" \"#8C510A\" \"#BF812D\" \"#DFC27D\" \"#F6E8C3\" \"#F5F5F5\" \"#C7EAE5\"\n [8] \"#80CDC1\" \"#35978F\" \"#01665E\" \"#003C30\""
  },
  {
    "objectID": "slides/week5.3-choropleth.html#apply-palette-unclassed",
    "href": "slides/week5.3-choropleth.html#apply-palette-unclassed",
    "title": "EDS 240",
    "section": "",
    "text": "Apply our palette & adjust colorbar\n\nHere, we leverage the awesome {scales} package to add %s to the colorbar labels and set our breaks. We also use guides() + guide_colorbar() to update label positioning and colorbar size:\n\nbase_map + \n  scale_fill_gradientn(colors = my_brew_palette11,\n                       labels = scales::label_percent(scale = 1),\n                       breaks = scales::breaks_width(width = 10)) +\n  guides(fill = guide_colorbar(barwidth = 15, barheight = 0.75))"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#inspect-color-scale1",
    "href": "slides/week5.3-choropleth.html#inspect-color-scale1",
    "title": "EDS 240",
    "section": "",
    "text": "Inspect the color scale – anything off?"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#misleading",
    "href": "slides/week5.3-choropleth.html#misleading",
    "title": "EDS 240",
    "section": "",
    "text": "Our color mapping may be misleading\n\n\n\n\n0% (i.e. no change between 5-year precipitation and 20th century average) is currently on the bluer side of our color scale, rather than on the off-white color that’s at the center of our palette.\nAs a result, our map may be misleading – it would appear as if more counties received higher-than-average precipitation than in actuality."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#rescale-colorbar",
    "href": "slides/week5.3-choropleth.html#rescale-colorbar",
    "title": "EDS 240",
    "section": "",
    "text": "Rescale the colorbar so that 0 is at the center\n\n\nbase_map + \n  scale_fill_gradientn(colors = my_brew_palette11,\n                       labels = scales::label_percent(scale = 1),\n                       breaks = scales::breaks_width(width = 10),\n                       values = scales::rescale(x = c(\n                         min(na.omit(joined_precip_geom)$perc_change),\n                         0,\n                         max(na.omit(joined_precip_geom)$perc_change)))) +\n  guides(fill = guide_colorbar(barwidth = 15, barheight = 0.75))"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#final-unclassed",
    "href": "slides/week5.3-choropleth.html#final-unclassed",
    "title": "EDS 240",
    "section": "",
    "text": "Our final unclassed map"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#classed-palette",
    "href": "slides/week5.3-choropleth.html#classed-palette",
    "title": "EDS 240",
    "section": "",
    "text": "Modify our palette for our classed map\n\nWe’ll be using the same color palette for our classed map, but this time, let’s keep 10 hues (this will drop the middle-most off-white hue):\n\n\n\nPreview the palette using display.brewer.pal() with our desired number of hues:\n\n\nRColorBrewer::display.brewer.pal(n = 10, name = 'BrBG')\n\n\n\n\n\n\n\n\n\n\nSave the HEX codes to a named object using brewer.pal() (we’ll call this in our plot later):\n\n\nmy_brew_palette10 &lt;- RColorBrewer::brewer.pal(n = 10, name = 'BrBG')\nmy_brew_palette10\n\n [1] \"#543005\" \"#8C510A\" \"#BF812D\" \"#DFC27D\" \"#F6E8C3\" \"#C7EAE5\" \"#80CDC1\"\n [8] \"#35978F\" \"#01665E\" \"#003C30\"\n\n\n\n\nBy dropping the off-white hue, we can construct our scale so that 0% sits at the break point between brown and blue shades – any county that received more than the historical average will be a shade of blue, and any that received less will be a shade of brown."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#apply-palette-classed",
    "href": "slides/week5.3-choropleth.html#apply-palette-classed",
    "title": "EDS 240",
    "section": "",
    "text": "By default, our resolution is pretty low\n\nWe only get 4 bins by default, which means we lose a lot of detail in our map:\n\nbase_map + \n  scale_fill_stepsn(colors = my_brew_palette10,\n                    labels = scales::label_percent(scale = 1)) +\n  guides(fill = guide_colorsteps(barwidth = 25, barheight = 0.75))"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#increase-classes",
    "href": "slides/week5.3-choropleth.html#increase-classes",
    "title": "EDS 240",
    "section": "",
    "text": "More classes = more nuance\n\n\n\n\nBreaks set to a width of 10\n\n\nbase_map + \n  scale_fill_stepsn(colors = my_brew_palette10,\n                    labels = scales::label_percent(scale = 1),\n                    breaks = scales::breaks_width(width = 10)) +\n  guides(fill = guide_colorsteps(barwidth = 25, barheight = 0.75))\n\n\n\n\n\n\n\n\n\n\nBreaks set to a width of 5 & rescaled with 0 at center\n\n\nbase_map + \n  scale_fill_stepsn(colors = my_brew_palette10,\n                    labels = scales::label_percent(scale = 1),\n                    values = scales::rescale(x = c(\n                         min(na.omit(joined_precip_geom)$perc_change),\n                         0,\n                         max(na.omit(joined_precip_geom)$perc_change))), \n                    breaks = scales::breaks_width(width = 5)) +\n  guides(fill = guide_colorsteps(barwidth = 25, barheight = 0.75))\n\n\n\n\n\n\n\n\n\n\n\nBut the more classes you have, the longer it will (likely) take a reader to interpret values."
  },
  {
    "objectID": "slides/week5.3-choropleth.html#unclassed-classed",
    "href": "slides/week5.3-choropleth.html#unclassed-classed",
    "title": "EDS 240",
    "section": "",
    "text": "Unclassed vs. classed maps\n\nWhat stories to each of these maps tell? When might you choose one over the other? What additional modifications might you make?\n\n\n\n\nUnclassed map:\n\n\n\n\n\n\n\n\n\n\n\n\nClassed map:"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#multiple-maps",
    "href": "slides/week5.3-choropleth.html#multiple-maps",
    "title": "EDS 240",
    "section": "",
    "text": "Choropleths are powerful in multiples\n\nSeveral maps side-by-side can help you better spot important patterns and tell a more complete story.\n\n\nWhat’s Going On in This Graph? | New Normal U.S. Precipitation (New York Times)"
  },
  {
    "objectID": "slides/week5.3-choropleth.html#end-break",
    "href": "slides/week5.3-choropleth.html#end-break",
    "title": "EDS 240",
    "section": "",
    "text": "See you next week!\n\n\n~ This is the end of Lesson 3 (of 3) ~"
  },
  {
    "objectID": "course-materials/week9.html#pre-class-prep",
    "href": "course-materials/week9.html#pre-class-prep",
    "title": "Data visualization in JavaScript, with Dr. Allison Horst",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nThere’s no required prep for this week’s lecture. You will be able to make temporary edits to Allison’s Observable Notebook while in Tinker mode. If you’d like to save your changes, you may optionally create a free starter account (I chose to sign up using my GitHub credentials, but multiple options are provided), then fork the notebook."
  },
  {
    "objectID": "course-materials/week9.html#lecture-materials",
    "href": "course-materials/week9.html#lecture-materials",
    "title": "Data visualization in JavaScript, with Dr. Allison Horst",
    "section": "Lecture Materials",
    "text": "Lecture Materials\n\nWhat is Observable JS?\nFrom the Quarto documentation:\n\n“Observable JS is a set of enhancements to vanilla1 JavaScript created by Mike Bostock (also the author of D3). Observable JS is distinguished by its reactive runtime, which is especially well suited for interactive data exploration and analysis.”\n\n1vanilla JavaScript is JavaScript code that is written without the aid of any external libraries or frameworks (comparable to using only base R without additional packages, e.g. like those in the {tidyverse})\n\n\nObservable Notebook\nTinker or fork (if you have an account) Allison’s notebook, EDS 240: Data visualization in JavaScript (Follow-along version).\n\n\nAdditional resources\n\nAdd JavaScript to your dataviz toolkit with Observable Plot: Learner Version, by Allison Horst & Ananya Roy – materials from R-Ladies Santa Barbara meetup (2023-05-24)\nIntro to Observable Plot: Exploring Taylor Swift Songs with Observable Plot, by Tanya Shapiro – materials from R-Ladies Philly workshop (2023-11-09)"
  },
  {
    "objectID": "course-materials/week9.html#discussion-materials",
    "href": "course-materials/week9.html#discussion-materials",
    "title": "Data visualization in JavaScript, with Dr. Allison Horst",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nNo discussion section this week!"
  },
  {
    "objectID": "course-materials/week9.html#assignment-reminders",
    "href": "course-materials/week9.html#assignment-reminders",
    "title": "Data visualization in JavaScript, with Dr. Allison Horst",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 9)\nMon 03/04/2024\nMon 03/04/2024, 11:55pm PT\n\n\nHW\nHomework Assignment #4\nMon 02/26/2024\nSat 03/09/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week2.html#pre-class-prep",
    "href": "course-materials/week2.html#pre-class-prep",
    "title": "[No Lecture]",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nNA"
  },
  {
    "objectID": "course-materials/week2.html#lecture-materials",
    "href": "course-materials/week2.html#lecture-materials",
    "title": "[No Lecture]",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nThere is no lecture this week!"
  },
  {
    "objectID": "course-materials/week2.html#discussion-materials",
    "href": "course-materials/week2.html#discussion-materials",
    "title": "[No Lecture]",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nAlternative text, aka alt text, makes our data visualizations accessible to a broader community. Today’s section will focus crafting effective alt text, as well as how to include it when rendering visualizations in reproducible reports, websites, etc. using publishing tools like Quarto.\n\n Week 2 discussion slides"
  },
  {
    "objectID": "course-materials/week2.html#assignment-reminders",
    "href": "course-materials/week2.html#assignment-reminders",
    "title": "[No Lecture]",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nHW\nHomework Assignment #1\nMon 01/08/2024\nSat 01/20/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week7.html#pre-class-prep",
    "href": "course-materials/week7.html#pre-class-prep",
    "title": "[No Lecture]",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nNA"
  },
  {
    "objectID": "course-materials/week7.html#lecture-materials",
    "href": "course-materials/week7.html#lecture-materials",
    "title": "[No Lecture]",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nThere is no lecture this week!"
  },
  {
    "objectID": "course-materials/week7.html#discussion-materials",
    "href": "course-materials/week7.html#discussion-materials",
    "title": "[No Lecture]",
    "section": "Discussion Materials",
    "text": "Discussion Materials\n\nPre-discussion Prep\nHW #3 has you working on your visualizations for your final project (HW #4). Please plan to bring the following to discussion:\n\none of your three visualizations (i.e. one of the three required viz for option 1, or one of the three viz that will make up your infographic for option 2)\n\nthe question that you’re trying to answer with your visualization\n\nAdd your visualization and your question to the appropriate Google slide deck (each slide is labeled with a name) before section begins:\n\n10am section slides\n11am section slides\n\nThe viz you bring should meet the HW #3 requirements (see the section that begins with “Mock up your visualizations using code…”) – this should be a well-constructed, carefully thought-through and polished plot (any one of the panels in the Hollywood Age Gaps visualization that you saw in discussion last week is a great example of the level of “polish” we’d expect to see). You should be prepared to discuss your design choices and receive constructive feedback from your peers.\n\n\nHow to give / receive feedback\nGiving, receiving and implementing feedback is an important part of any creative process (including building data visualizations!). There are two “levels” of feedback:\n\nhigh-level: where the focus is on whether a data visualization is accurate, relevant and understandable for the intended audience\ndetail-oriented: where the focus is on aesthetics choices (e.g. colors, typefaces, layout, themes, white space, etc.) and how those choices help to enhance / tell the story\n\nThis week, you should focus largely on providing high-level feedback (though suggestions on how to tweak the details of a visualization are welcome).\n\n\n\n\n\n\nImportant tips for giving / receiving / implementing feedback (adapted from this LinkedIn article):\n\n\n\n\n\nFor giving feedback:\n\nfocus on the strengths / weakness of the visualization itself, not the person who created it\nbalance positive and negative feedback, and start with the positives!\nstay objective when suggesting improvements (e.g. “This part might benefit from some clarity…”)\nsuggest actionable solutions and / or alternatives, rather than only problems or criticisms\n\nFor receiving feedback:\n\nreceiving feedback can be stressful – this is a very normal feeling!\nlisten carefully without disrupting / defending yourself\ntake notes, ask questions, and thank your feedback giver(s)\nevaluate your feedback objectively to decide what to keep / reject / modify\n\nFor applying feedback:\n\nprioritize feedback based on relevance, importance, and feasibility\ncreate a plan and a timeline to implement\ncritically evaluate / compare your before and after versions\nseek new feedback!\n\n\n\n\n\n\nSupplementary resources\n\nDesign and Redesign, by Fernanda Viégas & Martin Wattenberg\nA Better Path Toward Criticizing Data Visualizations, by Colin Mcnamara\nThe beauty of data visualization, a TED Talk by David McCandless (founder of information is beautiful) – this is a fun watch!"
  },
  {
    "objectID": "course-materials/week7.html#assignment-reminders",
    "href": "course-materials/week7.html#assignment-reminders",
    "title": "[No Lecture]",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nHW\nHomework Assignment #3\nMon 02/12/2024\nSat 02/24/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/week4.html#pre-class-prep",
    "href": "course-materials/week4.html#pre-class-prep",
    "title": "Fundamental chart types (part II)",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nPlease be sure to complete the following before class:\n\nInstall required packages\n\ninstall.packages(\"ggalt\") # extra coordinate systems, geoms, statistical transformations, scales and fonts for 'ggplot2' (includes `geom_lollipop()`)\ninstall.packages(\"ggExtra\") # {ggplot2} extension2222 which can be used to add marginal histograms/boxplots/density plots to ggplot2 scatterplots\ninstall.packages(\"ggdensity\") # {ggplot2} extension providing more interpretable visualizations of density estimates based on highest density regions (HDRs)\n\n\n\nReview data wrangling code\nIn lecture 4.1, we’ll be exploring income data from the Bureau of Labor Statistics and the Census Bureau, which has been moderately pre-processed by TidyTuesday organizers for the March 5, 2021 data set.\nPlease review the necessary background information (see slide 4) and walk through the data wrangling code on slide 5 ahead of class. Come prepared with any questions you may have about the code – we’ll set aside ~10 minutes to discuss before jumping into building our data visualizations."
  },
  {
    "objectID": "course-materials/week4.html#lecture-materials",
    "href": "course-materials/week4.html#lecture-materials",
    "title": "Fundamental chart types (part II)",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nWeek 4 instruction is broken down into two lessons:\n\n\n\n\n\n\n\n\n\nVisualizing rankings\n lecture 4.1 slides\n\n\n\n\nVisualizing relationships\n lecture 4.2 slides"
  },
  {
    "objectID": "course-materials/week4.html#discussion-materials",
    "href": "course-materials/week4.html#discussion-materials",
    "title": "Fundamental chart types (part II)",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nLast week’s discussion focused on recreating the data layers of the U.S. Drought Monitor’s visualization of CA drought conditions through time. This week, you’ll focus on refining the theme (non-data plot elements) to match the original visualization as closely as possible.\n\n Week 4 discussion slides\n\n\nBackground\nThemes are used to modify the non-data components of plots (e.g. titles, labels, fonts, background, gridlines, legend). In addition to using pre-built themes (available via the {ggplot2} package and also from extension packages), you can fine-tune the appearance of your plots theme by making adjustments using the theme() function.\n\n\nApplying pre-built themes:\n{ggplot2} comes with eight complete themes, which can be applied as-is, or further modified using theme() (see next section, below). There are also many additional themes which can be applied via ggplot extension packages. A small handful of packages are listed in the expandable note, below:\n\n\n\n\n\n\nA non-exhaustive list of ggplot theme extension packages\n\n\n\n\n\n\n{ggthemes}: a collection of popular themes, some of which also come with corresponding color scales\n{hrbrthemes}: typographic-centric themes and theme components\n{ggthemr}: a collection of color palettes and plot layouts for quickly setting a ggplot theme\n{ggtech}: themes based off large tech company color palettes\n{ggdark}: dark mode for ggplot complete themes\n{firatheme}: a ggplot theme with Fira font\n{urbnthemes}: tools for creating Urban Institute-themed plots and maps in R (also check out the Urban Institute Data Visualization Style Guide for a really great example of how an organization enforces a cohesive style across all published data viz content)\n{bbplot}: tools for creating ggplots in the style used by the BBC News data team\n{ggpomological}: a ggplot2 theme based on the USDA Pomological Watercolor Collection\n{tvthemes}: a collection of ggplot themes and color / fill palettes based on everybody’s favorite TV shows\n\nKeep your eye out for extension packages that supply both a geom(s) and a pre-build theme(s) designed specifically to work with that geom. For example, the {ggridges} package provides both a few different ridgeline plot geoms and a pre-built theme_ridges() theme to pair with them.\n\n\n\n\n\nUsing ggplot2::theme() to control plot elements:\nUse this (non-exhaustive) list to start tweaking elements of your plot’s appearance. It’s most common to start with a pre-built theme (see above) and modify from there. For a complete list of elements, explore the documentation for ggplot::theme().\n\n\n\n\n\n\n\n\n\n\nAdapted from Reproducible Science for Busy Researchers: How to Save Time using Literate Programming, by Andrew P. Lapointe\n\n\n\n\nSolution\nYou’ll get the most out of discussion section if you physically type out the code yourself (rather than copying / pasting)!\nNote: Much of the following code (data wrangling and ggplot code) was copied over from last week’s discussion materials. Newly added theme code begins below the comment, NEWLY ADDED THEME CODE!.\n\n\n\n\n\n\n\n\n\n\nComplete code for week 4 discussion\n\n\n\n\n\n\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\ntuesdata &lt;- tidytuesdayR::tt_load('2021-07-20')\ndrought &lt;- tuesdata$drought\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            wrangle drought data                          ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean &lt;- drought |&gt;\n\n  # select cols of interest & update names as needed ----\n  select(date = valid_start, state_abb, drought_lvl, area_pct) |&gt; \n\n  # add year, month & day cols using {lubridate} fxns ----\n  # NOTE: this step isn't necessary for our plot, but I'm including as examples of how to extract different date elements from a object of class Date using {lubridate}~ ----\n  mutate(year = year(date),\n         month = month(date, label = TRUE, abbr = TRUE),\n         day = day(date)) |&gt;\n\n  # add drought level conditions names ----\n  mutate(drought_lvl_long = factor(drought_lvl,\n                            levels = c(\"D4\", \"D3\", \"D2\", \"D1\",\"D0\", \"None\"),\n                            labels = c(\"(D4) Exceptional\", \"(D3) Extreme\",\n                                       \"(D2) Severe\", \"(D1) Moderate\", \"(D0) Abnormally Dry\", \n                                       \"No Drought\"))) |&gt;\n  \n  # reorder cols ----\n  select(date, year, month, day, state_abb, drought_lvl, drought_lvl_long, area_pct)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##       create stacked area plot of CA drought conditions through time     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean |&gt; \n  \n  # remove drought_lvl \"None\" & filter for just CA ----\n  filter(drought_lvl != \"None\",\n         state_abb == \"CA\") |&gt; \n  \n  # create ggplot ----\n  ggplot(mapping = aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  \n  # reverse order of groups so level D4 is closest to x-axis ----\n  geom_area(position = position_stack(reverse = TRUE)) +\n  \n  # update colors to match US Drought Monitor (colors selected using ColorPick Eyedropper from original USDM data viz) ----\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\")) +\n  \n  # set x-axis breaks & remove padding between data and x-axis ----\n  scale_x_date(breaks = scales::breaks_pretty(n = 10),\n               expand = c(0, 0)) +\n\n  # set y-axis breaks & convert values to percentages & & remove padding between data and y-axis----\n  scale_y_continuous(breaks = seq(0, 100, by = 10),\n                     labels = scales::label_percent(scale = 1),\n                     expand = c(0, 0)) +\n  \n  # add title ----\n  labs(title = \"Drought area in California\") +\n  \n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                                                            --\n##------------------------- NEWLY ADDED THEME CODE!-----------------------------\n##                                                                            --\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n  # set theme minimal (includes major/minor grid lines, no axes) ----\n  theme_minimal() +\n  \n  # fine-tune adjustments to plot theme ----\n  theme(\n    \n    # update axis lines & ticks color ----\n    axis.line = element_line(color = \"#5A9CD6\"),\n    axis.ticks = element_line(color = \"#5A9CD6\"),\n    \n    # adjust length of axis ticks ----\n    axis.ticks.length = unit(.2, \"cm\"),\n    \n    # center plot title ----\n    plot.title = element_text(hjust = 0.5, color = \"#686868\", size = 25,\n                              margin = margin(t = 10, r = 0, b = 15, l = 0)),\n    \n    # remove axis & legend titles ----\n    axis.title = element_blank(),\n    legend.title = element_blank(),\n    \n    # axis text color & size ----\n    axis.text = element_text(color = \"#686868\", size = 15),\n    legend.text = element_text(color = \"#686868\", size = 15),\n    \n    # move legend below plot ----\n    legend.position = \"bottom\",\n  )"
  },
  {
    "objectID": "course-materials/week4.html#assignment-reminders",
    "href": "course-materials/week4.html#assignment-reminders",
    "title": "Fundamental chart types (part II)",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 4)\nMon 01/29/2024\nMon 01/29/2024, 11:55pm PT\n\n\nHW\nHomework Assignment #2\nMon 01/22/2024\nSat 02/03/2024, 11:59pm PT"
  },
  {
    "objectID": "course-materials/discussion/week1/tidy-fracking.html",
    "href": "course-materials/discussion/week1/tidy-fracking.html",
    "title": "EDS 240",
    "section": "",
    "text": "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(usdata)\n\n#......................import fracking data......................\nfracking &lt;- read_csv(here::here(\"week1\", \"data\", \"fracking.csv\"))\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                        clean/wrangle fracking data                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nfracking_clean &lt;- fracking |&gt; \n  \n  # clean column names ----\n  janitor::clean_names() |&gt; \n  \n  # clean up dates ----\n  mutate(job_start_date = str_remove(job_start_date, \" AM\")) |&gt; # remove 'AM' from string\n  mutate(datetime_start = mdy_hms(job_start_date)) |&gt; # convert from string to date (save to new col)\n  mutate(year = year(datetime_start)) |&gt; # create 'year' col from date\n\n  # select relevant cols ----\n  select(datetime_start, year, state_name, county_name, well_name, total_base_water_volume) |&gt; \n  \n  # filter out non-state names ----\n  filter(!state_name %in% c(\"Beaver\", \"Beckham\", \"Harper\", \"Hemphill\", \"Midland\", \"Red River\", \"Roosevelt\", \"Rusk\", \"State\", \"WARD\")) |&gt; \n  \n  # rename state_name to something shorter for typing out when using case_when (not necessary) ----\n  rename(sn = state_name) |&gt; \n  \n  # make all words title case ----\n  mutate(sn = str_to_title(sn)) |&gt; \n  \n  # fix misspelled state names ----\n  mutate(sn = case_when(\n    sn == \"Colordao\" ~ \"Colorado\",\n    sn == \"Loiusiana\" ~ \"Louisiana\",\n    sn == \"Louisianna\" ~ \"Louisiana\",\n    sn == \"Lousiana\" ~ \"Louisiana\",\n    sn == \"New Mexcio\" ~ \"New Mexico\",\n    sn == \"Norh Dakota\" ~ \"North Dakota\",\n    sn == \"Norht Dakota\" ~ \"North Dakota\",\n    sn == \"North  Dakota\" ~ \"North Dakota\",\n    sn == \"North Dakata\" ~ \"North Dakota\",\n    sn == \"North Dakotta\" ~ \"North Dakota\",\n    sn == \"Noth Dakota\" ~ \"North Dakota\",\n    sn == \"Pennslvania\" ~ \"Pennsylvania\",\n    sn == \"Pennsylavania\" ~ \"Pennsylvania\",\n    sn == \"Pennsylvanya\" ~ \"Pennsylvania\",\n    sn == \"Penssylvania\" ~ \"Pennsylvania\",\n    sn == \"Texasa\" ~ \"Texas\",\n    sn == \"Texs\" ~ \"Texas\", \n    sn == \"West Viginia\" ~ \"West Virginia\",\n    sn == \"Wyominng\" ~ \"Wyoming\", \n    TRUE ~ sn # copy over rest of state names from as-is\n  )) |&gt; \n  \n  # remove rows that have a '?' mark ----\n  filter(!str_detect(string = sn, pattern = \"\\\\?\")) |&gt; # `?` is a special chr; escape with `\\\\` prefix\n  \n  # make all uppercase (so that we can covert abbreviation to state names) ----\n  mutate(sn = str_to_upper(sn)) |&gt; \n  \n  # mutate abbreviations to full state names ----\n  mutate(sn = ifelse(test = str_length(sn) == 2, # if string in 'sn' col is 2 chrs long\n                     yes = usdata::abbr2state(sn), # replace abbreviation with full state name \n                     no = sn)) |&gt; # if string in 'sn' col is not 2 chrs long, keep state name as-is\n  \n  # make all words title case again ----\n  mutate(sn = str_to_title(sn)) |&gt; \n  \n  # create a column of just state abbreviations ----\n  mutate(state_abb = usdata::state2abbr(sn)) |&gt; \n  \n  # rename 'sn' to 'state_name' again for clarity ----\n  rename(state_name = sn, total_base_water_volume_gal = total_base_water_volume) |&gt; \n  \n  # move 'state_abb' col after state_name col ----\n  relocate(state_abb, .after = state_name) |&gt; \n  \n  # convert 'state_name' & 'state_abb' from string to factor ----\n  mutate(state_name = as.factor(state_name),\n         state_abb = as.factor(state_abb)) |&gt; \n  \n  # remove obs that don't have a measurement for 'total_base_water_volume' (NA) ----\n  drop_na(total_base_water_volume_gal)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##          some exploratory data viz + a few plot mods for practice        ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nfracking_clean |&gt; \n  filter(state_name %in% c(\"Texas\", \"Colorado\", \"North Dakota\")) |&gt; \n  filter(year == 2015) |&gt; \n  group_by(state_name) |&gt; # pipe directly into ggplot\n  ggplot(aes(x = fct_rev(fct_infreq(state_name)), y = total_base_water_volume_gal)) + # need to reverse fct order for coord_flip() (plots lowest freq at top by default)\n  geom_jitter(width = 0.3, alpha = 0.5, color = \"gray15\") +\n  geom_violin(color = \"red4\", alpha = 0.3) +\n  scale_y_continuous(labels = scales::label_comma()) +\n  labs(y = \"Total base water volumn (gal)\") +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank()\n    )"
  },
  {
    "objectID": "course-materials/discussion/week4/CA-drought-theme.html",
    "href": "course-materials/discussion/week4/CA-drought-theme.html",
    "title": "EDS 240",
    "section": "",
    "text": "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                    setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n#..........................load packages.........................\nlibrary(tidyverse)\n\n#..........................import data...........................\ntuesdata &lt;- tidytuesdayR::tt_load('2021-07-20')\ndrought &lt;- tuesdata$drought\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                            wrangle drought data                          ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean &lt;- drought |&gt;\n\n  # select cols of interest & update names as needed ----\n  select(date = valid_start, state_abb, drought_lvl, area_pct) |&gt; \n\n  # add year, month & day cols using {lubridate} fxns ----\n  # NOTE: this step isn't necessary for our plot, but I'm including as examples of how to extract different date elements from a object of class Date using {lubridate}~ ----\n  mutate(year = year(date),\n         month = month(date, label = TRUE, abbr = TRUE),\n         day = day(date)) |&gt;\n\n  # add drought level conditions names ----\n  mutate(drought_lvl_long = factor(drought_lvl,\n                            levels = c(\"D4\", \"D3\", \"D2\", \"D1\",\"D0\", \"None\"),\n                            labels = c(\"(D4) Exceptional\", \"(D3) Extreme\",\n                                       \"(D2) Severe\", \"(D1) Moderate\", \"(D0) Abnormally Dry\", \n                                       \"No Drought\"))) |&gt;\n  \n  # reorder cols ----\n  select(date, year, month, day, state_abb, drought_lvl, drought_lvl_long, area_pct)\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##       create stacked area plot of CA drought conditions through time     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndrought_clean |&gt; \n  \n  # remove drought_lvl \"None\" & filter for just CA ----\n  filter(drought_lvl != \"None\",\n         state_abb == \"CA\") |&gt; \n  \n  # create ggplot ----\n  ggplot(mapping = aes(x = date, y = area_pct, fill = drought_lvl_long)) +\n  \n  # reverse order of groups so level D4 is closest to x-axis ----\n  geom_area(position = position_stack(reverse = TRUE)) +\n  \n  # update colors to match US Drought Monitor (colors selected using ColorPick Eyedropper from original USDM data viz) ----\n  scale_fill_manual(values = c(\"#853904\", \"#FF0000\", \"#FFC100\", \"#FFD965\", \"#FFFF00\")) +\n  \n  # set x-axis breaks & remove padding between data and x-axis ----\n  scale_x_date(breaks = scales::breaks_pretty(n = 10),\n               expand = c(0, 0)) +\n\n  # set y-axis breaks & convert values to percentages & & remove padding between data and y-axis----\n  scale_y_continuous(breaks = seq(0, 100, by = 10),\n                     labels = scales::label_percent(scale = 1),\n                     expand = c(0, 0)) +\n  \n  # add title ----\n  labs(title = \"Drought area in California\") +\n  \n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                                                            --\n##------------------------- NEWLY ADDED THEME CODE!-----------------------------\n##                                                                            --\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n  # set theme minimal (includes major/minor grid lines, no axes) ----\n  theme_minimal() +\n  \n  # fine-tune adjustments to plot theme ----\n  theme(\n    \n    # update axis lines & ticks color ----\n    axis.line = element_line(color = \"#5A9CD6\"),\n    axis.ticks = element_line(color = \"#5A9CD6\"),\n    \n    # adjust length of axis ticks ----\n    axis.ticks.length = unit(.2, \"cm\"),\n    \n    # center plot title ----\n    plot.title = element_text(hjust = 0.5, color = \"#686868\", size = 25,\n                              margin = margin(t = 10, r = 0, b = 15, l = 0)),\n    \n    # remove axis & legend titles ----\n    axis.title = element_blank(),\n    legend.title = element_blank(),\n    \n    # axis text color & size ----\n    axis.text = element_text(color = \"#686868\", size = 15),\n    legend.text = element_text(color = \"#686868\", size = 15),\n    \n    # move legend below plot ----\n    legend.position = \"bottom\",\n  )"
  },
  {
    "objectID": "course-materials/week10.html#pre-class-prep",
    "href": "course-materials/week10.html#pre-class-prep",
    "title": "Grab Bag & Catch up",
    "section": "Pre-class Prep",
    "text": "Pre-class Prep\nComing soon"
  },
  {
    "objectID": "course-materials/week10.html#lecture-materials",
    "href": "course-materials/week10.html#lecture-materials",
    "title": "Grab Bag & Catch up",
    "section": "Lecture Materials",
    "text": "Lecture Materials\nComing soon!"
  },
  {
    "objectID": "course-materials/week10.html#discussion-materials",
    "href": "course-materials/week10.html#discussion-materials",
    "title": "Grab Bag & Catch up",
    "section": "Discussion Materials",
    "text": "Discussion Materials\nComing soon!"
  },
  {
    "objectID": "course-materials/week10.html#assignment-reminders",
    "href": "course-materials/week10.html#assignment-reminders",
    "title": "Grab Bag & Catch up",
    "section": "Assignment Reminders",
    "text": "Assignment Reminders\n\n\n\n\n\n\n\n\n\nAssignment Type\nAssignment Title\nDate Assigned\nDate Due\n\n\n\n\nEOC\nEOC (week 10)\nMon 03/11/2024\nMon 03/11/2024, 11:55pm PT\n\n\nSR\nEnd-of-course reflection (SR #3)\nMon 03/11/2024\nSat 03/16/2024, 11:59pm PT\n\n\nHW\nHomework Assignment #4\nMon 02/26/2024\nSat 03/16/2024, 11:59pm PT"
  }
]